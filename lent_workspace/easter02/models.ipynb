{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list of models\n",
    "- Full GRU\n",
    "- Simple GRU\n",
    "- CB-GRU\n",
    "- CB-RNN-tied\n",
    "- Dale-CB\n",
    "- CB-RNN-tied-STP /\n",
    "- Dale-CB-STP /\n",
    "- Vanilla RNN\n",
    "\n",
    "### Variants\n",
    "With 24 neurons / with 48 neurons (let's do 48 first)\n",
    "\n",
    "### Check Features\n",
    "Input/ Ouput neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 8\n",
    "sequence_length = 28*28//input_size\n",
    "hidden_size = 48\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 40\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "stride_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "0\n",
      "1\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i, (images, labels) in enumerate(loaders['train']):\\n    images = images.reshape(-1, sequence_length, input_size).to(device)\\n    images = stride(images, stride_number).to(device)\\n    print(images.shape)\\n    print(labels.shape)\\n    print(len(loaders['train']))\\n    break\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Data Preprocessing'\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# get index of currently selected device\n",
    "print(torch.cuda.current_device()) # returns 0 in my case\n",
    "\n",
    "# get number of GPUs available\n",
    "print(torch.cuda.device_count()) # returns 1 in my case\n",
    "\n",
    "# get the name of the device\n",
    "print(torch.cuda.get_device_name(0)) # good old Tesla K80\n",
    "\n",
    "def snake_scan(img):\n",
    "    'Converts a 32x32 image to a 32x96 array with snake-like row ordering'\n",
    "    if len(img.shape) != 3:\n",
    "        raise ValueError('Input image must be a 3D array')\n",
    "    \n",
    "    channels, rows, cols = img.shape\n",
    "    snake = np.zeros((rows, cols * channels), dtype=img.dtype)\n",
    "    for r in range(rows):\n",
    "        row_data = img[:, r, :].flatten()  # Flattening each row into a 1D array of 96 elements\n",
    "        if r % 2 == 1:\n",
    "            row_data = row_data[::-1]  # Reversing the order for alternate rows\n",
    "        snake[r] = row_data\n",
    "    return snake\n",
    "\n",
    "def stride(input_data, stride):\n",
    "    'turn [batch_size, sequence_length, input_size] into [batch_size, sequence_length*input_size/stride, input_size]'\n",
    "    batch_size, sequence_length, input_size = input_data.shape\n",
    "    # flatten the input data to put sequence and input size together\n",
    "    input_data = input_data.reshape(batch_size, -1)\n",
    "    # append zeros to make sure the last pixel can be fed as the first pixel of the next sequence\n",
    "    n = input_size - (sequence_length*input_size)%stride\n",
    "\n",
    "    input_data = input_data.cpu()\n",
    "    input_data = input_data.numpy()\n",
    "    input_data = np.append(input_data, np.zeros((batch_size, n)), axis=1)\n",
    "    input_data = torch.tensor(input_data)\n",
    "    #print(input_data.shape)\n",
    "    output_data = torch.zeros(batch_size, sequence_length*input_size//stride, input_size)\n",
    "    for i in range(sequence_length*input_size//stride):\n",
    "        # if stride = input size, then the output data is the same as input data\n",
    "        #print(i)\n",
    "\n",
    "        output_data[:,i,:] = input_data[:,i*stride:i*stride+input_size]\n",
    "        #print(output_data[batch,i,:])\n",
    "\n",
    "    return output_data\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: torch.tensor(snake_scan(x.numpy())))\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    download = True,\n",
    "    transform = transform     \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    download = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "'Hyperparameters'\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=0),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False, \n",
    "                                          num_workers=0),\n",
    "}\n",
    "loaders\n",
    "'''\n",
    "for i, (images, labels) in enumerate(loaders['train']):\n",
    "    images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "    images = stride(images, stride_number).to(device)\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    print(len(loaders['train']))\n",
    "    break\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class simple_GRU_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(simple_GRU_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # Wz is defined in the forward function\n",
    "        self.W_z = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))         \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.uniform_(param, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = self.Sigmoid(torch.matmul(self.W_z, self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class simple_GRU_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(simple_GRU_batch, self).__init__()\n",
    "        self.rnncell = simple_GRU_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class simple_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(simple_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = simple_GRU_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = simple_GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_GRU(\n",
      "  (lstm): simple_GRU_batch(\n",
      "    (rnncell): simple_GRU_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 80.70\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 79.70\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 88.70\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 89.20\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 91.10\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 89.10\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 89.70\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:91.62%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "W_z = model.lstm.rnncell.W_z.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/02_simple_GRU_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/02_simple_GRU_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Timescale RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonlinearity: Sigmoid\n",
    "\n",
    "$z_t = \\sigma (W_z r_t + P_zx_t + b_z)$ with $W_z = P_z = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class multiscale_RNN_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(multiscale_RNN_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # Wz is defined in the forward function\n",
    "        self.W_z = torch.nn.Parameter(torch.zeros(self.hidden_size, self.hidden_size), requires_grad=False)\n",
    "        self.P_z = torch.nn.Parameter(torch.zeros(self.hidden_size, input_size), requires_grad=False)\n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))         \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = self.Sigmoid(torch.matmul(self.W_z, self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class multiscale_RNN_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(multiscale_RNN_batch, self).__init__()\n",
    "        self.rnncell = multiscale_RNN_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class multiscale_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(multiscale_RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = multiscale_RNN_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = multiscale_RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiscale_RNN(\n",
      "  (lstm): multiscale_RNN_batch(\n",
      "    (rnncell): multiscale_RNN_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 22.80\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 40.70\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 61.20\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 70.80\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 75.40\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 77.80\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 79.10\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 78.80\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 81.70\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 81.90\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 83.30\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 84.00\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 84.90\n",
      "Epoch [7/10], Step [1500/1500], Training Accuracy: 86.20\n",
      "Epoch [8/10], Step [750/1500], Training Accuracy: 86.00\n",
      "Epoch [8/10], Step [1500/1500], Training Accuracy: 85.70\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:87.12%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "W_z = model.lstm.rnncell.W_z.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/multiscale_RNN_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/multiscale_RNN_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_1_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_1_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(1.0)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_1_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_1_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_1_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_1(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_1, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_1_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_1(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_1(\n",
      "  (lstm): vanilla_RNN_1_batch(\n",
      "    (rnncell): vanilla_RNN_1_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 11.40\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 10.30\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 11.40\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:11.35%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "W_z = model.lstm.rnncell.W_z.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/multiscale_RNN_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/multiscale_RNN_48.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_2_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_2_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(0.5)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_2_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_2_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_2_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_2(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_2_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_2(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_2(\n",
      "  (lstm): vanilla_RNN_2_batch(\n",
      "    (rnncell): vanilla_RNN_2_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 11.40\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 11.40\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 11.40\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:11.35%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "W_z = model.lstm.rnncell.W_z.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/multiscale_RNN_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/multiscale_RNN_48.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_3_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_3_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(0.1)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_3_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_3_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_3_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_3(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_3_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_3(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_3(\n",
      "  (lstm): vanilla_RNN_3_batch(\n",
      "    (rnncell): vanilla_RNN_3_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 9.80\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 47.40\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 64.40\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 72.00\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 75.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 77.00\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 75.70\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 78.80\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 78.60\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 80.90\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 80.60\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 81.30\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 82.10\n",
      "Epoch [7/10], Step [1500/1500], Training Accuracy: 81.70\n",
      "Epoch [8/10], Step [750/1500], Training Accuracy: 84.50\n",
      "Epoch [8/10], Step [1500/1500], Training Accuracy: 84.80\n",
      "Epoch [9/10], Step [750/1500], Training Accuracy: 83.70\n",
      "Epoch [9/10], Step [1500/1500], Training Accuracy: 85.30\n",
      "Epoch [10/10], Step [750/1500], Training Accuracy: 85.50\n",
      "Epoch [10/10], Step [1500/1500], Training Accuracy: 85.50\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:86.61%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/multiscale_RNN_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/multiscale_RNN_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "\n",
    "class CB_GRU_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_GRU_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K is always positive            \n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))     \n",
    "        self.K = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(0.1), requires_grad = False)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.uniform_(param, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.Sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "        # No sign constraint on K and W\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "        \n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.dt * self.Sigmoid(torch.matmul(self.K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)                \n",
    "\n",
    "class CB_GRU_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_GRU_batch, self).__init__()\n",
    "        self.rnncell = CB_GRU_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_GRU_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = CB_GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_GRU(\n",
      "  (lstm): CB_GRU_batch(\n",
      "    (rnncell): CB_GRU_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 58.10\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 72.90\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 77.30\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 77.90\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 80.60\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 82.60\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 81.30\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 81.90\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:83.39%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n",
    "\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/03_CB_GRU_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/03_CB_GRU_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-RNN-tied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CB_RNN_tiedcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_RNN_tiedcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.W = torch.nn.Parameter(torch.empty(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and P_z become tied          \n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # initialise e as a random float between 0 and 1\n",
    "        self.e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_p = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "        # Voltage rate\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(0.1), requires_grad = False)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        for w in self.W, self.P:\n",
    "            glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        e = self.softplus(self.e)\n",
    "        e_p = self.softplus(self.e_p)\n",
    "        K = e * self.softplus(self.W)\n",
    "        P_z = e_p * self.softplus(self.P)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.dt * self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)                \n",
    "\n",
    "class CB_RNN_tied_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_RNN_tied_batch, self).__init__()\n",
    "        self.rnncell = CB_RNN_tiedcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_RNN_tied(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_RNN_tied, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_RNN_tied_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = CB_RNN_tied(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_RNN_tied(\n",
      "  (lstm): CB_RNN_tied_batch(\n",
      "    (rnncell): CB_RNN_tiedcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 53.90\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 57.20\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 65.70\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 70.40\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 74.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 77.40\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 77.20\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 80.10\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 78.00\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 80.70\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 85.10\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 84.50\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 82.30\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:83.95%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "e = model.lstm.rnncell.e\n",
    "e_p = model.lstm.rnncell.e_p\n",
    "K = e * nn.Softplus()(model.lstm.rnncell.W)\n",
    "P_z = e_p * nn.Softplus()(model.lstm.rnncell.P)\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "e = model.lstm.rnncell.e.detach().cpu().numpy()\n",
    "e_p = model.lstm.rnncell.e_p.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/04_CB-RNN-tied_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, P_z, b_v, e, e_p], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/04_CB-RNN-tied_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dale-CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dale_CBcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Dale_CBcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "        self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(0.1), requires_grad = False)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        #values, _ = torch.linalg.eig(weights @ weights.T)\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.dt * self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)   \n",
    "\n",
    "class Dale_CB_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(Dale_CB_batch, self).__init__()\n",
    "        self.rnncell = Dale_CBcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class Dale_CB(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(Dale_CB, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = Dale_CB_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = Dale_CB(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dale_CB(\n",
      "  (lstm): Dale_CB_batch(\n",
      "    (rnncell): Dale_CBcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 46.90\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 58.50\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 66.60\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 70.70\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 78.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 76.80\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 79.80\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 78.60\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 80.90\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 78.00\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 78.50\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:80.93%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "C = model.lstm.rnncell.C.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "e_e = model.lstm.rnncell.e_e.detach().cpu().numpy()\n",
    "e_i = model.lstm.rnncell.e_i.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/05_Dale-CB_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, C, P_z, b_z, e_e, e_i, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/05_Dale-CB_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-RNN-tied-STP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "\n",
    "class CB_RNN_tiedcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_RNN_tiedcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.W = torch.nn.Parameter(torch.empty(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and P_z become tied          \n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # initialise e as a random float between 0 and 1\n",
    "        self.e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_p = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "        # Voltage rate\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(1.0), requires_grad = False)\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        for w in self.W, self.P:\n",
    "            glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.full((self.hidden_size, 1), 0.9, dtype=torch.float32).to(device)\n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        ### Constraints###\n",
    "        e = self.softplus(self.e)\n",
    "        e_p = self.softplus(self.e_p)\n",
    "        K = e * self.softplus(self.W)\n",
    "        P_z = e_p * self.softplus(self.P)\n",
    "\n",
    "        ### STP model ###\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)*self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(P_z, x) + self.b_z)\n",
    "        # mask p with second half of the neuron not receiving input\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(self.W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())       \n",
    "\n",
    "class CB_RNN_tied_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_RNN_tied_batch, self).__init__()\n",
    "        self.rnncell = CB_RNN_tiedcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_RNN_tied(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_RNN_tied, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_RNN_tied_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        # mask only the second half giving output\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = CB_RNN_tied(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_RNN_tied(\n",
      "  (lstm): CB_RNN_tied_batch(\n",
      "    (rnncell): CB_RNN_tiedcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 29.20\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 44.90\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 51.60\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 62.90\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 68.40\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 74.80\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 73.20\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 74.90\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 77.70\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 77.60\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 76.70\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:77.93%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "# Retrieve weights\n",
    "K = model.lstm.rnncell.e * nn.Softplus()(model.lstm.rnncell.W)\n",
    "P_z = model.lstm.rnncell.e_p * nn.Softplus()(model.lstm.rnncell.P)\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "Ucap = model.lstm.rnncell.Ucap.detach().cpu().numpy()\n",
    "c_U = model.lstm.rnncell.c_U.detach().cpu().numpy()\n",
    "c_u = model.lstm.rnncell.c_u.detach().cpu().numpy()\n",
    "c_x = model.lstm.rnncell.c_x.detach().cpu().numpy()\n",
    "e = model.lstm.rnncell.e.detach().cpu().numpy()\n",
    "e_p = model.lstm.rnncell.e_p.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/06_CB-RNN-tied-STP_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, P_z, b_v, Ucap, c_U, c_u, c_x, e, e_p], f)\n",
    "    #pickle.dump([X_history, U_history, v_t_history, z_t_history, labelslist], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/06_CB-RNN-tied-STP_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dale-CB-STP\n",
    "Accuracy of the model:55.56% (doubled neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9006, grad_fn=<MulBackward0>)\n",
      "tensor(0.9000, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Dale_CB_STPcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Dale_CB_STPcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        while True:\n",
    "            self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            nse_K = self.NSE(self.K)\n",
    "            nse_C = self.NSE(self.C)\n",
    "            if nse_K > 0.87 and nse_C > 0.87:\n",
    "                break\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(1.0), requires_grad = False)\n",
    "        self.z_high = nn.Parameter(torch.repeat_interleave(torch.tensor(0.2), self.hidden_size).reshape(self.hidden_size,1), requires_grad = False)\n",
    "        self.z_low = torch.nn.Parameter(torch.zeros(self.hidden_size, 1, dtype=torch.float32), requires_grad = False)\n",
    "        self.z_low[self.hidden_size//2:,:] = 0.1\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.full((self.hidden_size, 1), 0.9, dtype=torch.float32).to(device)\n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        values= torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "    \n",
    "    def NSE(self, weights):\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        normalised_v = values/sum(values)\n",
    "        H = -1/torch.log(torch.tensor(self.hidden_size)) * torch.sum(normalised_v * torch.log(normalised_v))\n",
    "        print(H)\n",
    "        return H\n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        # first half of neurons are excitatory and second half are inhibitory\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### STP model ###\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.dt*self.z_low + self.dt * (self.z_high - self.z_low)*self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        \n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)    \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())   \n",
    "\n",
    "\n",
    "class Dale_CB_STP_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(Dale_CB_STP_batch, self).__init__()\n",
    "        self.rnncell = Dale_CB_STPcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class Dale_CB_STP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(Dale_CB_STP, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = Dale_CB_STP_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = Dale_CB_STP(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dale_CB_STP(\n",
      "  (lstm): Dale_CB_STP_batch(\n",
      "    (rnncell): Dale_CB_STPcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 21.10\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 36.20\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 39.90\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 53.30\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 58.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 60.40\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 65.50\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 65.90\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 67.00\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 68.00\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 69.60\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 67.90\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 69.10\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:71.63%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "C = model.lstm.rnncell.C.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "e_e = model.lstm.rnncell.e_e.detach().cpu().numpy()\n",
    "e_i = model.lstm.rnncell.e_i.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "Ucap = model.lstm.rnncell.Ucap.detach().cpu().numpy()\n",
    "c_U = model.lstm.rnncell.c_U.detach().cpu().numpy()\n",
    "c_u = model.lstm.rnncell.c_u.detach().cpu().numpy()\n",
    "c_x = model.lstm.rnncell.c_x.detach().cpu().numpy()\n",
    "\n",
    "import pickle\n",
    "with open('weights/07_Dale-CB-STP_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap, c_U, c_u, c_x], f)\n",
    "    pickle.dump([X_history, U_history, v_t_history, z_t_history, labelslist], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/07_Dale-CB-STP_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting STP features after Dale-CB is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from Dale-CB\n",
    "import pickle\n",
    "with open('weights/05_Dale-CB_48.pkl', 'rb') as f:\n",
    "    P, W, read_out, K, C, P_z, b_z, e_e, e_i, b_v = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9013, grad_fn=<MulBackward0>)\n",
      "tensor(0.9003, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class new_Dale_CB_STPcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(new_Dale_CB_STPcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        while True:\n",
    "            self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            nse_K = self.NSE(self.K)\n",
    "            nse_C = self.NSE(self.C)\n",
    "            if nse_K > 0.87 and nse_C > 0.87:\n",
    "                break\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(1.0), requires_grad = False)\n",
    "        self.z_high = nn.Parameter(torch.repeat_interleave(torch.tensor(0.2), self.hidden_size).reshape(self.hidden_size,1), requires_grad = False)\n",
    "        self.z_low = torch.nn.Parameter(torch.zeros(self.hidden_size, 1, dtype=torch.float32), requires_grad = False)\n",
    "        self.z_low[self.hidden_size//2:,:] = 0.1\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.Ucap = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "        self.A = torch.tensor(0.0, dtype=torch.float32).to(device)\n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        values= torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "    \n",
    "    def NSE(self, weights):\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        normalised_v = values/sum(values)\n",
    "        H = -1/torch.log(torch.tensor(self.hidden_size)) * torch.sum(normalised_v * torch.log(normalised_v))\n",
    "        print(H)\n",
    "        return H\n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        # first half of neurons are excitatory and second half are inhibitory\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### STP model ###\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.A * self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.dt*self.z_low + self.dt * (self.z_high - self.z_low)*self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        \n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)    \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())   \n",
    "\n",
    "\n",
    "class new_Dale_CB_STP_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(new_Dale_CB_STP_batch, self).__init__()\n",
    "        self.rnncell = new_Dale_CB_STPcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class new_Dale_CB_STP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(new_Dale_CB_STP, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = new_Dale_CB_STP_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = new_Dale_CB_STP(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_Dale_CB_STP(\n",
       "  (lstm): new_Dale_CB_STP_batch(\n",
       "    (rnncell): new_Dale_CB_STPcell(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.lstm.rnncell.P = torch.nn.Parameter(torch.tensor(P))\n",
    "model.fc.weight = torch.nn.Parameter(torch.tensor(read_out))\n",
    "model.lstm.rnncell.K = torch.nn.Parameter(torch.tensor(K))\n",
    "model.lstm.rnncell.C = torch.nn.Parameter(torch.tensor(C))\n",
    "model.lstm.rnncell.P_z = torch.nn.Parameter(torch.tensor(P_z))\n",
    "model.lstm.rnncell.b_z = torch.nn.Parameter(torch.tensor(b_z))\n",
    "model.lstm.rnncell.e_e = torch.nn.Parameter(torch.tensor(e_e))\n",
    "model.lstm.rnncell.e_i = torch.nn.Parameter(torch.tensor(e_i))\n",
    "model.lstm.rnncell.b_v = torch.nn.Parameter(torch.tensor(b_v))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_Dale_CB_STP(\n",
      "  (lstm): new_Dale_CB_STP_batch(\n",
      "    (rnncell): new_Dale_CB_STPcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 44.00\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 49.50\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 51.60\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 53.40\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 66.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 65.10\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 68.50\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 71.40\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 72.90\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 74.50\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 75.30\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 73.40\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 74.30\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            if model.lstm.rnncell.A != 1.0:\n",
    "                model.lstm.rnncell.A += 0.2\n",
    "            #print(model.lstm.rnncell.A)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:77.46%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "C = model.lstm.rnncell.C.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "e_e = model.lstm.rnncell.e_e.detach().cpu().numpy()\n",
    "e_i = model.lstm.rnncell.e_i.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "Ucap = model.lstm.rnncell.Ucap.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/pretrained_Dale-CB-STP.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap], f)\n",
    "    #pickle.dump([X_history, U_history, v_t_history, z_t_history, labelslist], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/pretrained_Dale-CB-STP.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# W1 is the weight from Dale-CB\n",
    "# W2 is the weight from Dale-CB-STP after pretraining\n",
    "# W3 is the weight from Dale-CB-STP without pretraining\n",
    "with open('weights/05_Dale-CB_48.pkl', 'rb') as f:\n",
    "    P, W1, read_out, K, C, P_z, b_z, e_e, e_i, b_v = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "with open('weights/pretrained_Dale-CB-STP.pkl', 'rb') as f:\n",
    "    P, W2, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap= pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "with open('weights/07_Dale-CB-STP_48.pkl', 'rb') as f:\n",
    "    P, W3, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap, c_U, c_u, c_x= pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "# plot heatmap of W1 and W2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 3, figsize=(25, 6))\n",
    "sns.heatmap(W1, ax=ax[0])\n",
    "ax[0].set_title('Dale-CB')\n",
    "sns.heatmap(W2, ax=ax[1])\n",
    "ax[1].set_title('Dale-CB-STP after pretraining')\n",
    "sns.heatmap(W3, ax=ax[2])\n",
    "ax[2].set_title('Dale-CB-STP without pretraining')\n",
    "\n",
    "# compare their performance\n",
    "perf = [80.93 ,77.46, 71.63]\n",
    "labels = ['Dale-CB', 'pretrained Dale-CB-STP', 'Dale-CB-STP']\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(labels, perf)\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Performance of different models')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Performance bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# rotate model name\n",
    "\n",
    "model_name = ['simple GRU', 'CB-GRU', 'CB-RNN-tied', 'Dale-CB', 'CB-RNN-tied STP', 'Dale-CB STP', 'multiscale-Vanilla RNN', 'Vanilla RNN $z=1.0$', 'Vanilla RNN $z=0.5$', 'Vanilla RNN $z=0.1$']\n",
    "perf1 = [91.62, 83.39, 83.95, 82.48, 75.0, 77.46, 87.12, 11.35, 11.35, 86.61]\n",
    "perf2 = [90.03, 64.96, 82.07, 85.13, 79.76, 68.31, 80.10, 11.35, 34.29, 71.71]\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.bar(model_name, perf1, bar_width, label='24 Neurons')\n",
    "index = np.arange(len(model_name))\n",
    "plt.bar(index + bar_width, perf2, bar_width, label='48 Neurons')\n",
    "# text bar to show input size, stride number, and hidden size\n",
    "plt.text(4.5, 80, f'Input size: {input_size}\\nStride number: {stride_number}'.format(input_size=input_size, stride_number=stride_number, hidden_size=hidden_size), ha='center', va='bottom')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Performance of different models')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
