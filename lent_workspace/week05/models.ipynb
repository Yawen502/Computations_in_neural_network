{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list of models\n",
    "- Full GRU\n",
    "- Simple GRU\n",
    "- CB-GRU\n",
    "- CB-RNN-tied\n",
    "- Dale-CB\n",
    "- CB-RNN-tied-STP /\n",
    "- Dale-CB-STP /\n",
    "- Vanilla RNN\n",
    "\n",
    "### Variants\n",
    "With 24 neurons / with 48 neurons (let's do 48 first)\n",
    "\n",
    "### Check Features\n",
    "Input/ Ouput neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 8\n",
    "sequence_length = 28*28//input_size\n",
    "hidden_size = 24\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 40\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "stride_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "0\n",
      "1\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i, (images, labels) in enumerate(loaders['train']):\\n    images = images.reshape(-1, sequence_length, input_size).to(device)\\n    images = stride(images, stride_number).to(device)\\n    print(images.shape)\\n    print(labels.shape)\\n    print(len(loaders['train']))\\n    break\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Data Preprocessing'\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# get index of currently selected device\n",
    "print(torch.cuda.current_device()) # returns 0 in my case\n",
    "\n",
    "# get number of GPUs available\n",
    "print(torch.cuda.device_count()) # returns 1 in my case\n",
    "\n",
    "# get the name of the device\n",
    "print(torch.cuda.get_device_name(0)) # good old Tesla K80\n",
    "\n",
    "def snake_scan(img):\n",
    "    'Converts a 32x32 image to a 32x96 array with snake-like row ordering'\n",
    "    if len(img.shape) != 3:\n",
    "        raise ValueError('Input image must be a 3D array')\n",
    "    \n",
    "    channels, rows, cols = img.shape\n",
    "    snake = np.zeros((rows, cols * channels), dtype=img.dtype)\n",
    "    for r in range(rows):\n",
    "        row_data = img[:, r, :].flatten()  # Flattening each row into a 1D array of 96 elements\n",
    "        if r % 2 == 1:\n",
    "            row_data = row_data[::-1]  # Reversing the order for alternate rows\n",
    "        snake[r] = row_data\n",
    "    return snake\n",
    "\n",
    "def stride(input_data, stride):\n",
    "    'turn [batch_size, sequence_length, input_size] into [batch_size, sequence_length*input_size/stride, input_size]'\n",
    "    batch_size, sequence_length, input_size = input_data.shape\n",
    "    # flatten the input data to put sequence and input size together\n",
    "    input_data = input_data.reshape(batch_size, -1)\n",
    "    # append zeros to make sure the last pixel can be fed as the first pixel of the next sequence\n",
    "    n = input_size - (sequence_length*input_size)%stride\n",
    "\n",
    "    input_data = input_data.cpu()\n",
    "    input_data = input_data.numpy()\n",
    "    input_data = np.append(input_data, np.zeros((batch_size, n)), axis=1)\n",
    "    input_data = torch.tensor(input_data)\n",
    "    #print(input_data.shape)\n",
    "    output_data = torch.zeros(batch_size, sequence_length*input_size//stride, input_size)\n",
    "    for i in range(sequence_length*input_size//stride):\n",
    "        # if stride = input size, then the output data is the same as input data\n",
    "        #print(i)\n",
    "\n",
    "        output_data[:,i,:] = input_data[:,i*stride:i*stride+input_size]\n",
    "        #print(output_data[batch,i,:])\n",
    "\n",
    "    return output_data\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: torch.tensor(snake_scan(x.numpy())))\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    download = True,\n",
    "    transform = transform     \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    download = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "'Hyperparameters'\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=0),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False, \n",
    "                                          num_workers=0),\n",
    "}\n",
    "loaders\n",
    "'''\n",
    "for i, (images, labels) in enumerate(loaders['train']):\n",
    "    images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "    images = stride(images, stride_number).to(device)\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    print(len(loaders['train']))\n",
    "    break\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class simple_GRU_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(simple_GRU_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # Wz is defined in the forward function\n",
    "        self.W_z = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))         \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.uniform_(param, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = self.Sigmoid(torch.matmul(self.W_z, self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class simple_GRU_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(simple_GRU_batch, self).__init__()\n",
    "        self.rnncell = simple_GRU_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class simple_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(simple_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = simple_GRU_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = simple_GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_GRU(\n",
      "  (lstm): simple_GRU_batch(\n",
      "    (rnncell): simple_GRU_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 80.70\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 79.70\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 88.70\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 89.20\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 91.10\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 89.10\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 89.70\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:91.62%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "W_z = model.lstm.rnncell.W_z.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/02_simple_GRU_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/02_simple_GRU_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Timescale RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonlinearity: Sigmoid\n",
    "\n",
    "$z_t = \\sigma (W_z r_t + P_zx_t + b_z)$ with $W_z = P_z = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class multiscale_RNN_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(multiscale_RNN_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # Wz is defined in the forward function\n",
    "        self.W_z = torch.nn.Parameter(torch.zeros(self.hidden_size, self.hidden_size), requires_grad=False)\n",
    "        self.P_z = torch.nn.Parameter(torch.zeros(self.hidden_size, input_size), requires_grad=False)\n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))         \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)*self.Sigmoid(self.b_z)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class multiscale_RNN_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(multiscale_RNN_batch, self).__init__()\n",
    "        self.rnncell = multiscale_RNN_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class multiscale_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(multiscale_RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = multiscale_RNN_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = multiscale_RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiscale_RNN(\n",
      "  (lstm): multiscale_RNN_batch(\n",
      "    (rnncell): multiscale_RNN_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=24, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 27.40\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 40.90\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 59.10\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 66.70\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 69.90\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 71.90\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 74.10\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 75.80\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 78.30\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 77.90\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 82.10\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 81.10\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 81.80\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:83.33%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "W_z = model.lstm.rnncell.W_z.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/multiscale_RNN_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/multiscale_RNN_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_1_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_1_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(1.0)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_1_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_1_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_1_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_1(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_1, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_1_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_1(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_1(\n",
      "  (lstm): vanilla_RNN_1_batch(\n",
      "    (rnncell): vanilla_RNN_1_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 11.40\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 10.30\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 11.40\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:11.35%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "W_z = model.lstm.rnncell.W_z.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/multiscale_RNN_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/multiscale_RNN_48.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_2_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_2_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(0.5)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_2_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_2_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_2_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_2(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_2_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_2(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_2(\n",
      "  (lstm): vanilla_RNN_2_batch(\n",
      "    (rnncell): vanilla_RNN_2_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 11.40\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 11.40\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 11.40\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:11.35%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "W_z = model.lstm.rnncell.W_z.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/multiscale_RNN_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/multiscale_RNN_48.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_3_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_3_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(0.1)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_3_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_3_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_3_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_3(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_3_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_3(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_3(\n",
      "  (lstm): vanilla_RNN_3_batch(\n",
      "    (rnncell): vanilla_RNN_3_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 9.80\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 47.40\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 64.40\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 72.00\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 75.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 77.00\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 75.70\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 78.80\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 78.60\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 80.90\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 80.60\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 81.30\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 82.10\n",
      "Epoch [7/10], Step [1500/1500], Training Accuracy: 81.70\n",
      "Epoch [8/10], Step [750/1500], Training Accuracy: 84.50\n",
      "Epoch [8/10], Step [1500/1500], Training Accuracy: 84.80\n",
      "Epoch [9/10], Step [750/1500], Training Accuracy: 83.70\n",
      "Epoch [9/10], Step [1500/1500], Training Accuracy: 85.30\n",
      "Epoch [10/10], Step [750/1500], Training Accuracy: 85.50\n",
      "Epoch [10/10], Step [1500/1500], Training Accuracy: 85.50\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:86.61%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/multiscale_RNN_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/multiscale_RNN_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "\n",
    "class CB_GRU_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_GRU_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K is always positive            \n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))     \n",
    "        self.K = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(0.1), requires_grad = False)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.uniform_(param, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.Sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "        # No sign constraint on K and W\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "        \n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.dt * self.Sigmoid(torch.matmul(self.K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)                \n",
    "\n",
    "class CB_GRU_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_GRU_batch, self).__init__()\n",
    "        self.rnncell = CB_GRU_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_GRU_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = CB_GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_GRU(\n",
      "  (lstm): CB_GRU_batch(\n",
      "    (rnncell): CB_GRU_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 58.10\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 72.90\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 77.30\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 77.90\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 80.60\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 82.60\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 81.30\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 81.90\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:83.39%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n",
    "\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/03_CB_GRU_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/03_CB_GRU_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-RNN-tied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CB_RNN_tiedcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_RNN_tiedcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.W = torch.nn.Parameter(torch.empty(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and P_z become tied          \n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # initialise e as a random float between 0 and 1\n",
    "        self.e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_p = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "        # Voltage rate\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(0.1), requires_grad = False)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        for w in self.W, self.P:\n",
    "            glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        e = self.softplus(self.e)\n",
    "        e_p = self.softplus(self.e_p)\n",
    "        K = e * self.softplus(self.W)\n",
    "        P_z = e_p * self.softplus(self.P)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.dt * self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)                \n",
    "\n",
    "class CB_RNN_tied_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_RNN_tied_batch, self).__init__()\n",
    "        self.rnncell = CB_RNN_tiedcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_RNN_tied(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_RNN_tied, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_RNN_tied_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = CB_RNN_tied(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_RNN_tied(\n",
      "  (lstm): CB_RNN_tied_batch(\n",
      "    (rnncell): CB_RNN_tiedcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 53.90\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 57.20\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 65.70\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 70.40\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 74.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 77.40\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 77.20\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 80.10\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 78.00\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 80.70\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 85.10\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 84.50\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 82.30\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:83.95%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "e = model.lstm.rnncell.e\n",
    "e_p = model.lstm.rnncell.e_p\n",
    "K = e * nn.Softplus()(model.lstm.rnncell.W)\n",
    "P_z = e_p * nn.Softplus()(model.lstm.rnncell.P)\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "e = model.lstm.rnncell.e.detach().cpu().numpy()\n",
    "e_p = model.lstm.rnncell.e_p.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/04_CB-RNN-tied_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, P_z, b_v, e, e_p], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/04_CB-RNN-tied_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dale-CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dale_CBcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Dale_CBcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "        self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(0.1), requires_grad = False)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        #values, _ = torch.linalg.eig(weights @ weights.T)\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.dt * self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)   \n",
    "\n",
    "class Dale_CB_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(Dale_CB_batch, self).__init__()\n",
    "        self.rnncell = Dale_CBcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class Dale_CB(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(Dale_CB, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = Dale_CB_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = Dale_CB(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dale_CB(\n",
      "  (lstm): Dale_CB_batch(\n",
      "    (rnncell): Dale_CBcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 46.90\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 58.50\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 66.60\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 70.70\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 78.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 76.80\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 79.80\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 78.60\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 80.90\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 78.00\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 78.50\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:80.93%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "C = model.lstm.rnncell.C.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "e_e = model.lstm.rnncell.e_e.detach().cpu().numpy()\n",
    "e_i = model.lstm.rnncell.e_i.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/05_Dale-CB_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, C, P_z, b_z, e_e, e_i, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/05_Dale-CB_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-RNN-tied-STP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "\n",
    "class CB_RNN_tiedcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_RNN_tiedcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.W = torch.nn.Parameter(torch.empty(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and P_z become tied          \n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # initialise e as a random float between 0 and 1\n",
    "        self.e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_p = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "        # Voltage rate\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(1.0), requires_grad = False)\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        for w in self.W, self.P:\n",
    "            glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.full((self.hidden_size, 1), 0.9, dtype=torch.float32).to(device)\n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        ### Constraints###\n",
    "        e = self.softplus(self.e)\n",
    "        e_p = self.softplus(self.e_p)\n",
    "        K = e * self.softplus(self.W)\n",
    "        P_z = e_p * self.softplus(self.P)\n",
    "\n",
    "        ### STP model ###\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)*self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(P_z, x) + self.b_z)\n",
    "        # mask p with second half of the neuron not receiving input\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(self.W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())       \n",
    "\n",
    "class CB_RNN_tied_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_RNN_tied_batch, self).__init__()\n",
    "        self.rnncell = CB_RNN_tiedcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_RNN_tied(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_RNN_tied, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_RNN_tied_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        # mask only the second half giving output\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = CB_RNN_tied(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_RNN_tied(\n",
      "  (lstm): CB_RNN_tied_batch(\n",
      "    (rnncell): CB_RNN_tiedcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 29.20\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 44.90\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 51.60\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 62.90\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 68.40\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 74.80\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 73.20\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 74.90\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 77.70\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 77.60\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 76.70\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:77.93%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "# Retrieve weights\n",
    "K = model.lstm.rnncell.e * nn.Softplus()(model.lstm.rnncell.W)\n",
    "P_z = model.lstm.rnncell.e_p * nn.Softplus()(model.lstm.rnncell.P)\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "Ucap = model.lstm.rnncell.Ucap.detach().cpu().numpy()\n",
    "c_U = model.lstm.rnncell.c_U.detach().cpu().numpy()\n",
    "c_u = model.lstm.rnncell.c_u.detach().cpu().numpy()\n",
    "c_x = model.lstm.rnncell.c_x.detach().cpu().numpy()\n",
    "e = model.lstm.rnncell.e.detach().cpu().numpy()\n",
    "e_p = model.lstm.rnncell.e_p.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/06_CB-RNN-tied-STP_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, P_z, b_v, Ucap, c_U, c_u, c_x, e, e_p], f)\n",
    "    #pickle.dump([X_history, U_history, v_t_history, z_t_history, labelslist], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/06_CB-RNN-tied-STP_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dale-CB-STP\n",
    "Accuracy of the model:55.56% (doubled neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9006, grad_fn=<MulBackward0>)\n",
      "tensor(0.9000, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Dale_CB_STPcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Dale_CB_STPcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        while True:\n",
    "            self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            nse_K = self.NSE(self.K)\n",
    "            nse_C = self.NSE(self.C)\n",
    "            if nse_K > 0.87 and nse_C > 0.87:\n",
    "                break\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(1.0), requires_grad = False)\n",
    "        self.z_high = nn.Parameter(torch.repeat_interleave(torch.tensor(0.2), self.hidden_size).reshape(self.hidden_size,1), requires_grad = False)\n",
    "        self.z_low = torch.nn.Parameter(torch.zeros(self.hidden_size, 1, dtype=torch.float32), requires_grad = False)\n",
    "        self.z_low[self.hidden_size//2:,:] = 0.1\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.full((self.hidden_size, 1), 0.9, dtype=torch.float32).to(device)\n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        values= torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "    \n",
    "    def NSE(self, weights):\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        normalised_v = values/sum(values)\n",
    "        H = -1/torch.log(torch.tensor(self.hidden_size)) * torch.sum(normalised_v * torch.log(normalised_v))\n",
    "        print(H)\n",
    "        return H\n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        # first half of neurons are excitatory and second half are inhibitory\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### STP model ###\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.dt*self.z_low + self.dt * (self.z_high - self.z_low)*self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        \n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)    \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())   \n",
    "\n",
    "\n",
    "class Dale_CB_STP_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(Dale_CB_STP_batch, self).__init__()\n",
    "        self.rnncell = Dale_CB_STPcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class Dale_CB_STP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(Dale_CB_STP, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = Dale_CB_STP_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = Dale_CB_STP(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dale_CB_STP(\n",
      "  (lstm): Dale_CB_STP_batch(\n",
      "    (rnncell): Dale_CB_STPcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 21.10\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 36.20\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 39.90\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 53.30\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 58.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 60.40\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 65.50\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 65.90\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 67.00\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 68.00\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 69.60\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 67.90\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 69.10\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:71.63%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "C = model.lstm.rnncell.C.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "e_e = model.lstm.rnncell.e_e.detach().cpu().numpy()\n",
    "e_i = model.lstm.rnncell.e_i.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "Ucap = model.lstm.rnncell.Ucap.detach().cpu().numpy()\n",
    "c_U = model.lstm.rnncell.c_U.detach().cpu().numpy()\n",
    "c_u = model.lstm.rnncell.c_u.detach().cpu().numpy()\n",
    "c_x = model.lstm.rnncell.c_x.detach().cpu().numpy()\n",
    "\n",
    "import pickle\n",
    "with open('weights/07_Dale-CB-STP_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap, c_U, c_u, c_x], f)\n",
    "    pickle.dump([X_history, U_history, v_t_history, z_t_history, labelslist], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/07_Dale-CB-STP_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting STP features after Dale-CB is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from Dale-CB\n",
    "import pickle\n",
    "with open('weights/05_Dale-CB_48.pkl', 'rb') as f:\n",
    "    P, W, read_out, K, C, P_z, b_z, e_e, e_i, b_v = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9013, grad_fn=<MulBackward0>)\n",
      "tensor(0.9003, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class new_Dale_CB_STPcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(new_Dale_CB_STPcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        while True:\n",
    "            self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            nse_K = self.NSE(self.K)\n",
    "            nse_C = self.NSE(self.C)\n",
    "            if nse_K > 0.87 and nse_C > 0.87:\n",
    "                break\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # dt is a constant\n",
    "        self.dt = nn.Parameter(torch.tensor(1.0), requires_grad = False)\n",
    "        self.z_high = nn.Parameter(torch.repeat_interleave(torch.tensor(0.2), self.hidden_size).reshape(self.hidden_size,1), requires_grad = False)\n",
    "        self.z_low = torch.nn.Parameter(torch.zeros(self.hidden_size, 1, dtype=torch.float32), requires_grad = False)\n",
    "        self.z_low[self.hidden_size//2:,:] = 0.1\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.Ucap = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "        self.A = torch.tensor(0.0, dtype=torch.float32).to(device)\n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        values= torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "    \n",
    "    def NSE(self, weights):\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        normalised_v = values/sum(values)\n",
    "        H = -1/torch.log(torch.tensor(self.hidden_size)) * torch.sum(normalised_v * torch.log(normalised_v))\n",
    "        print(H)\n",
    "        return H\n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        # first half of neurons are excitatory and second half are inhibitory\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### STP model ###\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.A * self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.dt*self.z_low + self.dt * (self.z_high - self.z_low)*self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        \n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + self.dt * (torch.matmul(W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)    \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())   \n",
    "\n",
    "\n",
    "class new_Dale_CB_STP_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(new_Dale_CB_STP_batch, self).__init__()\n",
    "        self.rnncell = new_Dale_CB_STPcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class new_Dale_CB_STP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(new_Dale_CB_STP, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = new_Dale_CB_STP_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = new_Dale_CB_STP(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_Dale_CB_STP(\n",
       "  (lstm): new_Dale_CB_STP_batch(\n",
       "    (rnncell): new_Dale_CB_STPcell(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.lstm.rnncell.P = torch.nn.Parameter(torch.tensor(P))\n",
    "model.fc.weight = torch.nn.Parameter(torch.tensor(read_out))\n",
    "model.lstm.rnncell.K = torch.nn.Parameter(torch.tensor(K))\n",
    "model.lstm.rnncell.C = torch.nn.Parameter(torch.tensor(C))\n",
    "model.lstm.rnncell.P_z = torch.nn.Parameter(torch.tensor(P_z))\n",
    "model.lstm.rnncell.b_z = torch.nn.Parameter(torch.tensor(b_z))\n",
    "model.lstm.rnncell.e_e = torch.nn.Parameter(torch.tensor(e_e))\n",
    "model.lstm.rnncell.e_i = torch.nn.Parameter(torch.tensor(e_i))\n",
    "model.lstm.rnncell.b_v = torch.nn.Parameter(torch.tensor(b_v))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_Dale_CB_STP(\n",
      "  (lstm): new_Dale_CB_STP_batch(\n",
      "    (rnncell): new_Dale_CB_STPcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 44.00\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 49.50\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 51.60\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 53.40\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 66.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 65.10\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 68.50\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 71.40\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 72.90\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 74.50\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 75.30\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 73.40\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 74.30\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            if model.lstm.rnncell.A != 1.0:\n",
    "                model.lstm.rnncell.A += 0.2\n",
    "            #print(model.lstm.rnncell.A)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:77.46%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "C = model.lstm.rnncell.C.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "e_e = model.lstm.rnncell.e_e.detach().cpu().numpy()\n",
    "e_i = model.lstm.rnncell.e_i.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "Ucap = model.lstm.rnncell.Ucap.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/pretrained_Dale-CB-STP.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap], f)\n",
    "    #pickle.dump([X_history, U_history, v_t_history, z_t_history, labelslist], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/pretrained_Dale-CB-STP.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# W1 is the weight from Dale-CB\n",
    "# W2 is the weight from Dale-CB-STP after pretraining\n",
    "# W3 is the weight from Dale-CB-STP without pretraining\n",
    "with open('weights/05_Dale-CB_48.pkl', 'rb') as f:\n",
    "    P, W1, read_out, K, C, P_z, b_z, e_e, e_i, b_v = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "with open('weights/pretrained_Dale-CB-STP.pkl', 'rb') as f:\n",
    "    P, W2, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap= pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "with open('weights/07_Dale-CB-STP_48.pkl', 'rb') as f:\n",
    "    P, W3, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap, c_U, c_u, c_x= pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "# plot heatmap of W1 and W2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 3, figsize=(25, 6))\n",
    "sns.heatmap(W1, ax=ax[0])\n",
    "ax[0].set_title('Dale-CB')\n",
    "sns.heatmap(W2, ax=ax[1])\n",
    "ax[1].set_title('Dale-CB-STP after pretraining')\n",
    "sns.heatmap(W3, ax=ax[2])\n",
    "ax[2].set_title('Dale-CB-STP without pretraining')\n",
    "\n",
    "# compare their performance\n",
    "perf = [80.93 ,77.46, 71.63]\n",
    "labels = ['Dale-CB', 'pretrained Dale-CB-STP', 'Dale-CB-STP']\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(labels, perf)\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Performance of different models')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Performance bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# rotate model name\n",
    "\n",
    "model_name = ['simple GRU', 'CB-GRU', 'CB-RNN-tied', 'Dale-CB', 'CB-RNN-tied STP', 'Dale-CB STP', 'multiscale-Vanilla RNN', 'Vanilla RNN $z=1.0$', 'Vanilla RNN $z=0.5$', 'Vanilla RNN $z=0.1$']\n",
    "perf1 = [91.62, 83.39, 83.95, 82.48, 75.0, 77.46, 82.4, 11.35, 11.35, 86.61]\n",
    "perf2 = [90.03, 64.96, 82.07, 85.13, 79.76, 68.31, 83.33, 11.35, 34.29, 71.71]\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.bar(model_name, perf1, bar_width, label='24 Neurons')\n",
    "index = np.arange(len(model_name))\n",
    "plt.bar(index + bar_width, perf2, bar_width, label='48 Neurons')\n",
    "# text bar to show input size, stride number, and hidden size\n",
    "plt.text(4.5, 80, f'Input size: {input_size}\\nStride number: {stride_number}'.format(input_size=input_size, stride_number=stride_number, hidden_size=hidden_size), ha='center', va='bottom')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Performance of different models')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
