{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list of models\n",
    "- Full GRU\n",
    "- Simple GRU\n",
    "- CB-GRU\n",
    "- CB-RNN-tied\n",
    "- Dale-CB\n",
    "- CB-RNN-tied-STP /\n",
    "- Dale-CB-STP /\n",
    "- Vanilla RNN\n",
    "\n",
    "### Variants\n",
    "With 24 neurons / with 48 neurons (let's do 48 first)\n",
    "\n",
    "### Check Features\n",
    "Input/ Ouput neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  98,  66,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  99,  99,  66],\n",
      "        [ 69,  97,  98,  ...,  97,  66,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 2, 0, 0, 3, 0, 2, 1, 3, 0, 3, 3, 0, 3, 0, 3, 2, 0, 0, 0, 3, 3, 0,\n",
      "        1, 2, 0, 1, 2, 2, 3, 3, 2, 3, 2, 1, 0, 2, 3, 3])\n",
      "\n",
      "Batch 2\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  98,  66,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 1, 2, 2, 3, 2, 2, 1, 3, 1, 2, 2, 3, 0, 0, 0, 3, 2, 0, 2, 2, 1, 2,\n",
      "        1, 1, 3, 3, 1, 0, 2, 2, 2, 3, 1, 3, 1, 1, 3, 3])\n",
      "\n",
      "Batch 3\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,  97,  66,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  98,  66,   0],\n",
      "        [ 69,  97,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 3, 1, 0, 3, 0, 2, 0, 0, 1, 0, 3, 2, 1, 2, 3, 3, 1, 2, 0, 1, 2, 1,\n",
      "        2, 1, 0, 2, 3, 2, 3, 0, 2, 2, 1, 2, 2, 2, 1, 2])\n",
      "\n",
      "Batch 4\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  98,  99,  66],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 2, 3, 2, 1, 3, 2, 1, 1, 2, 3, 0, 3, 1, 0, 3, 3, 3, 1, 3, 1, 0, 3,\n",
      "        1, 1, 2, 0, 0, 3, 1, 3, 3, 0, 1, 3, 3, 3, 0, 2])\n",
      "\n",
      "Batch 5\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  98,  99,  66],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 2, 2, 3, 0, 1, 1, 2, 2, 1, 0, 3, 0, 3, 0, 2, 3, 2, 3, 3, 0, 0, 1,\n",
      "        0, 2, 2, 2, 2, 0, 0, 1, 2, 2, 1, 1, 1, 2, 0, 1])\n",
      "\n",
      "Batch 6\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  99,  ..., 100, 100,  66],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 3, 0, 2, 2, 2, 2, 1, 0, 3, 0, 2, 1, 1, 1, 3, 3, 2, 0, 0, 3, 0, 3,\n",
      "        3, 2, 0, 1, 2, 0, 2, 2, 0, 3, 1, 2, 2, 1, 3, 2])\n",
      "\n",
      "Batch 7\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  99,  ...,  97,  66,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 2, 0, 3, 1, 2, 1, 1, 1, 3, 2, 1, 0, 2, 3, 3, 0, 2, 0, 3, 0, 3, 3,\n",
      "        3, 0, 3, 2, 0, 3, 0, 3, 3, 0, 0, 3, 2, 3, 3, 2])\n",
      "\n",
      "Batch 8\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  98,  99,  66],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 2, 3, 1, 3, 1, 3, 1, 2, 3, 0, 1, 2, 0, 3, 2, 1, 0, 2, 0, 2, 3, 1,\n",
      "        0, 3, 1, 3, 3, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 3])\n",
      "\n",
      "Batch 9\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 3, 1, 2, 3, 3, 1, 3, 3, 3, 2, 2, 3, 2, 0, 2, 0, 1, 1, 1, 3, 0, 0,\n",
      "        0, 1, 1, 3, 1, 1, 0, 1, 1, 2, 3, 1, 1, 3, 2, 3])\n",
      "\n",
      "Batch 10\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 3, 3, 0, 0, 3, 1, 0, 3, 0, 1, 1, 2, 2, 2, 3, 0, 3, 2, 1, 1, 3, 1,\n",
      "        0, 1, 3, 0, 0, 0, 1, 2, 1, 3, 2, 1, 3, 2, 3, 0])\n",
      "\n",
      "Batch 11\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ..., 100,  66,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 1, 0, 1, 1, 3, 3, 1, 1, 0, 3, 0, 0, 1, 3, 2, 3, 2, 1, 0, 3, 2, 2,\n",
      "        2, 2, 3, 2, 3, 1, 2, 2, 0, 2, 1, 3, 1, 1, 2, 1])\n",
      "\n",
      "Batch 12\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  97,  99,  66],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 1, 1, 3, 1, 0, 2, 1, 0, 1, 1, 3, 1, 2, 1, 2, 3, 1, 3, 1, 3, 3, 2,\n",
      "        0, 0, 2, 0, 1, 0, 1, 3, 1, 2, 2, 2, 1, 0, 1, 2])\n",
      "\n",
      "Batch 13\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  98,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  97,  66,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 0, 0, 1, 0, 0, 3, 0, 2, 0, 3, 0, 2, 0, 1, 2, 0, 0, 1, 1, 1, 3, 0,\n",
      "        2, 3, 3, 0, 3, 2, 3, 3, 1, 1, 3, 2, 3, 0, 1, 0])\n",
      "\n",
      "Batch 14\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  99, 100,  66],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,  98,  97,  66],\n",
      "        [ 69,  98, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 0, 2, 0, 0, 1, 3, 2, 3, 1, 2, 3, 2, 2, 3, 0, 0, 1, 0, 2, 1, 3, 1,\n",
      "        0, 0, 1, 2, 1, 3, 0, 1, 0, 1, 3, 2, 1, 2, 1, 3])\n",
      "\n",
      "Batch 15\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 1, 0, 2, 1, 0, 3, 0, 3, 1, 0, 1, 2,\n",
      "        2, 0, 0, 0, 3, 3, 0, 2, 1, 2, 0, 0, 2, 0, 1, 2])\n",
      "\n",
      "Batch 16\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 0, 0, 0, 2, 3, 3, 0, 3, 0, 1, 3, 0, 1, 2, 3, 2, 2, 0, 3, 0, 3, 0,\n",
      "        0, 0, 3, 1, 3, 0, 2, 0, 0, 3, 2, 0, 1, 0, 2, 2])\n",
      "\n",
      "Batch 17\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,  99,  99,  66],\n",
      "        [ 69,  98,  99,  ...,  97,  66,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  99, 100,  66],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 3, 2, 2, 0, 1, 3, 3, 1, 2, 3, 0, 3, 1, 1, 0, 3, 0, 3, 3, 0, 1, 2,\n",
      "        2, 0, 0, 1, 2, 1, 1, 0, 1, 3, 0, 0, 3, 3, 2, 3])\n",
      "\n",
      "Batch 18\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 3, 1, 3, 0, 0, 1, 3, 1, 0, 2, 3, 0, 3, 3, 3, 1, 2, 2, 2, 1, 1, 3,\n",
      "        3, 3, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 0, 0, 0, 3])\n",
      "\n",
      "Batch 19\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 3, 0, 1, 1, 1, 0, 0, 2, 2, 3, 1, 1, 0, 2, 1, 2, 0, 1, 1, 2, 3, 2,\n",
      "        3, 2, 2, 2, 2, 2, 3, 0, 3, 1, 3, 0, 1, 0, 0, 1])\n",
      "\n",
      "Batch 20\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,  99,  66,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 1, 1, 2, 0, 2, 2, 2, 0, 3, 3, 2, 3, 1, 2, 1, 3, 2, 3, 2, 0, 3, 2,\n",
      "        1, 3, 1, 0, 2, 1, 3, 0, 0, 2, 1, 1, 1, 1, 2, 2])\n",
      "\n",
      "Batch 21\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 1, 1, 2, 0, 3, 0, 3, 3, 0, 2, 1, 3, 0, 3, 0, 2, 3, 2, 1, 0, 1, 2,\n",
      "        0, 3, 1, 2, 3, 3, 1, 0, 3, 1, 3, 1, 1, 0, 2, 3])\n",
      "\n",
      "Batch 22\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ..., 100,  99,  66],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  99,  99,  66]])\n",
      "Targets:\n",
      "tensor([3, 1, 2, 2, 1, 3, 2, 1, 2, 0, 3, 2, 1, 1, 3, 3, 1, 0, 3, 0, 2, 2, 1, 0,\n",
      "        3, 3, 3, 1, 3, 3, 3, 3, 0, 1, 0, 1, 0, 1, 3, 0])\n",
      "\n",
      "Batch 23\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  98,  ..., 100,  66,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  97,  99,  66]])\n",
      "Targets:\n",
      "tensor([0, 1, 0, 3, 0, 2, 1, 2, 3, 3, 0, 0, 0, 0, 2, 1, 3, 1, 2, 3, 3, 1, 2, 1,\n",
      "        0, 0, 2, 0, 2, 0, 0, 1, 1, 1, 3, 1, 2, 1, 0, 2])\n",
      "\n",
      "Batch 24\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,  98,  66,   0],\n",
      "        [ 69, 100, 100,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 1, 0, 3, 1, 1, 3, 0, 2, 1, 0, 1, 2, 2, 2, 0, 1, 0, 3, 3, 0, 0,\n",
      "        2, 3, 3, 2, 0, 3, 3, 2, 3, 1, 3, 1, 1, 3, 3, 1])\n",
      "\n",
      "Batch 25\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,  98,  66,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  97,  97,  66]])\n",
      "Targets:\n",
      "tensor([0, 1, 0, 1, 0, 2, 0, 1, 2, 1, 0, 2, 3, 2, 3, 3, 3, 0, 0, 1, 2, 3, 2, 2,\n",
      "        2, 3, 0, 2, 1, 3, 3, 3, 2, 0, 0, 2, 2, 2, 3, 2])\n",
      "\n",
      "Batch 26\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 3, 0, 0, 3, 2, 3, 0, 0, 1, 3, 3, 1, 3, 0, 0, 1, 2, 0, 1, 1, 3, 3,\n",
      "        3, 3, 2, 3, 1, 2, 1, 3, 1, 3, 3, 0, 0, 0, 3, 0])\n",
      "\n",
      "Batch 27\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,  98,  98,  66],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 3, 0, 2, 0, 3, 3, 3, 2, 2, 3, 2, 0, 0, 0, 2, 2, 2, 1, 1, 0, 3, 0,\n",
      "        1, 1, 2, 0, 2, 2, 0, 3, 0, 1, 3, 0, 3, 0, 3, 0])\n",
      "\n",
      "Batch 28\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 1, 1, 3, 2, 0, 0, 0, 0, 3, 1, 0, 3, 3, 1, 1, 3, 0, 1, 3, 1, 2, 0,\n",
      "        0, 2, 3, 3, 0, 0, 2, 3, 0, 0, 2, 3, 1, 1, 0, 2])\n",
      "\n",
      "Batch 29\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  97,  66,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 1, 3, 1, 3, 1, 3, 3, 3, 1, 3, 1, 1, 2, 1, 1, 3, 0, 1, 1, 0, 0, 3,\n",
      "        1, 0, 3, 3, 2, 0, 0, 1, 0, 3, 1, 1, 0, 3, 2, 2])\n",
      "\n",
      "Batch 30\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,  99, 100,  66],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,  99, 100,  66]])\n",
      "Targets:\n",
      "tensor([2, 2, 0, 1, 2, 1, 1, 1, 3, 3, 3, 0, 2, 3, 3, 2, 2, 3, 3, 2, 2, 1, 3, 3,\n",
      "        1, 0, 1, 0, 2, 3, 2, 1, 3, 2, 0, 0, 0, 2, 0, 3])\n",
      "\n",
      "Batch 31\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,  97,  66,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 1, 2, 1, 3, 1, 2, 1, 0, 3, 1, 3, 0, 0, 0, 2, 2, 2, 1, 2, 3, 3, 1,\n",
      "        3, 2, 2, 0, 1, 1, 0, 1, 0, 1, 3, 3, 1, 2, 0, 1])\n",
      "\n",
      "Batch 32\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ..., 100,  66,   0],\n",
      "        [ 69,  97,  98,  ..., 100,  98,  66]])\n",
      "Targets:\n",
      "tensor([2, 1, 1, 1, 3, 0, 3, 2, 0, 3, 0, 2, 2, 0, 3, 2, 2, 3, 1, 2, 3, 3, 3, 3,\n",
      "        3, 2, 0, 1, 0, 0, 3, 0, 1, 3, 2, 2, 2, 1, 1, 3])\n",
      "\n",
      "Batch 33\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 1, 0, 3, 2, 2, 1, 2, 3, 2, 1, 1, 0, 3, 2, 2, 2, 3, 3, 1, 0, 0, 1,\n",
      "        0, 2, 0, 3, 3, 2, 1, 3, 3, 3, 1, 2, 3, 1, 1, 0])\n",
      "\n",
      "Batch 34\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  97,  98,  66],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 3, 2, 3, 2, 0, 2, 3, 3, 0, 2, 3, 2, 1, 0, 2, 0, 3, 2, 3, 3, 3, 3,\n",
      "        2, 1, 0, 1, 3, 2, 3, 2, 1, 0, 1, 1, 2, 2, 0, 3])\n",
      "\n",
      "Batch 35\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 1, 2, 3, 3, 0, 0, 3, 3, 2, 2, 2, 0, 1, 1, 1, 1, 1, 2, 1, 2, 1, 3,\n",
      "        2, 2, 2, 2, 2, 0, 2, 1, 1, 3, 2, 1, 3, 2, 0, 2])\n",
      "\n",
      "Batch 36\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,  97,  66,   0],\n",
      "        [ 69,  97,  97,  ..., 100, 100,  66],\n",
      "        [ 69,  99,  99,  ..., 100,  66,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 2, 3, 0, 0, 1, 2, 3, 2, 3, 3, 2, 0, 1, 0, 1, 2, 1, 3, 0, 2, 0, 3,\n",
      "        3, 0, 2, 1, 3, 3, 3, 3, 2, 1, 1, 3, 3, 3, 0, 3])\n",
      "\n",
      "Batch 37\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 3, 0, 1, 3, 2, 1, 3, 1, 1, 2, 1, 1, 1, 0, 3, 3, 2, 2, 1, 0, 1, 3,\n",
      "        2, 2, 1, 1, 3, 1, 2, 0, 1, 1, 0, 0, 2, 2, 1, 0])\n",
      "\n",
      "Batch 38\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ..., 100,  66,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  98,  66,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  97,  66,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 1, 2, 1, 2, 0, 3, 1, 0, 1, 1, 1, 2, 2, 1, 0, 1, 2, 2, 0, 2, 0,\n",
      "        3, 1, 0, 2, 1, 1, 3, 0, 0, 3, 2, 3, 1, 0, 0, 1])\n",
      "\n",
      "Batch 39\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,  97,  99,  66],\n",
      "        [ 69, 100,  98,  ...,  97,  66,   0],\n",
      "        [ 69,  98,  97,  ...,  98,  97,  66],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 2, 1, 3, 1, 0, 1, 3, 0, 1, 2, 0, 1, 0, 2, 2, 3, 2, 3, 3, 0, 3, 1,\n",
      "        1, 0, 2, 2, 2, 1, 1, 0, 2, 1, 0, 2, 2, 3, 1, 1])\n",
      "\n",
      "Batch 40\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,  97,  66,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 0, 0, 3, 0, 1, 3, 3, 3, 1, 2, 2, 2, 1, 3, 1, 3, 3, 3, 0, 2, 0, 1,\n",
      "        3, 1, 1, 2, 0, 1, 3, 0, 3, 3, 2, 1, 2, 3, 3, 2])\n",
      "\n",
      "Batch 41\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ..., 100,  66,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ..., 100, 100,  66],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 0, 0, 1, 0, 1, 0, 1, 2, 3, 3, 3, 1, 2, 2, 0, 1, 2, 1, 3, 1, 2, 0,\n",
      "        3, 0, 0, 1, 3, 2, 3, 0, 2, 2, 2, 0, 2, 3, 1, 1])\n",
      "\n",
      "Batch 42\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 2, 2, 2, 1, 3, 1, 3, 3, 2, 2, 3, 0, 3, 0, 1, 1, 2, 2, 1, 1, 3, 1,\n",
      "        2, 3, 1, 2, 0, 0, 3, 1, 1, 1, 1, 3, 2, 2, 1, 2])\n",
      "\n",
      "Batch 43\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 2, 3, 0, 1, 1, 1, 2, 2, 3, 2, 2, 0, 3, 0, 1, 1, 3, 3, 1, 3, 3, 2,\n",
      "        1, 0, 2, 1, 0, 2, 1, 2, 1, 0, 2, 1, 0, 1, 0, 1])\n",
      "\n",
      "Batch 44\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ..., 100,  66,   0],\n",
      "        [ 69,  98,  98,  ...,  98,  66,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  99,  97,  66]])\n",
      "Targets:\n",
      "tensor([1, 0, 2, 1, 1, 0, 3, 3, 3, 3, 0, 2, 1, 0, 2, 3, 0, 2, 0, 0, 1, 3, 0, 3,\n",
      "        0, 2, 0, 1, 3, 2, 3, 1, 0, 0, 2, 2, 2, 3, 0, 1])\n",
      "\n",
      "Batch 45\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  97,  97,  66],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 1, 2, 0, 3, 2, 2, 1, 3, 2, 1, 2, 1, 2, 3, 0, 1, 3, 2, 0, 2, 3, 0,\n",
      "        0, 3, 1, 1, 3, 2, 3, 3, 1, 2, 1, 2, 3, 0, 3, 2])\n",
      "\n",
      "Batch 46\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,  97,  97,  66],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 2, 2, 2, 1, 3, 1, 0, 2, 0, 3, 3, 3, 1, 0, 0, 3, 0, 0, 0, 0, 1, 0,\n",
      "        3, 1, 2, 0, 0, 3, 1, 2, 1, 3, 3, 0, 0, 1, 0, 1])\n",
      "\n",
      "Batch 47\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  98,  98,  66],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 0, 3, 3, 2, 1, 3, 1, 0, 3, 1, 0, 0, 2, 3, 3, 0, 2, 2, 1, 0, 1, 2,\n",
      "        1, 1, 3, 3, 1, 2, 0, 3, 0, 2, 2, 0, 3, 2, 2, 0])\n",
      "\n",
      "Batch 48\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 0, 0, 0, 2, 2, 1, 2, 0, 1, 0, 2, 3, 1, 3, 0, 3, 1, 3, 3, 0, 1, 1,\n",
      "        1, 2, 1, 2, 3, 1, 1, 0, 3, 2, 3, 0, 1, 3, 0, 1])\n",
      "\n",
      "Batch 49\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 1, 3, 2, 0, 1, 1, 1, 2, 0, 0, 2, 1, 1, 1, 2, 3, 3, 3, 3, 0, 3, 1,\n",
      "        0, 1, 2, 2, 0, 1, 3, 1, 0, 2, 0, 0, 0, 0, 1, 0])\n",
      "\n",
      "Batch 50\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 3, 2, 1, 3, 3, 2, 3, 2, 3, 0, 0, 1, 0, 3, 3, 1, 1, 0, 2, 1, 2, 1,\n",
      "        2, 1, 0, 1, 2, 2, 0, 2, 3, 3, 1, 1, 3, 2, 2, 1])\n",
      "\n",
      "Batch 51\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,  97,  66,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 3, 3, 2, 0, 1, 3, 0, 3, 0, 0, 1, 1, 2, 1, 2, 0, 3, 2, 1, 3, 2, 3,\n",
      "        0, 1, 1, 0, 3, 0, 2, 3, 3, 1, 2, 3, 3, 1, 3, 1])\n",
      "\n",
      "Batch 52\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,  98,  66,   0],\n",
      "        [ 69,  99, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        2, 3, 2, 2, 1, 1, 1, 3, 2, 3, 0, 2, 3, 0, 1, 1])\n",
      "\n",
      "Batch 53\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ..., 100,  66,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 0, 3, 0, 2, 1, 3, 2, 1, 1, 2, 1, 1, 0, 1, 3, 1, 1, 0, 0, 1, 2, 0,\n",
      "        3, 1, 0, 3, 0, 3, 3, 1, 2, 3, 0, 3, 1, 3, 2, 1])\n",
      "\n",
      "Batch 54\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ..., 100,  97,  66],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,  99,  98,  66],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  99,  99,  66]])\n",
      "Targets:\n",
      "tensor([3, 2, 2, 2, 3, 1, 0, 2, 0, 0, 2, 2, 0, 1, 3, 0, 2, 0, 3, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 2, 1, 3, 1, 3, 3, 3, 1, 0, 1, 1, 1, 3])\n",
      "\n",
      "Batch 55\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ..., 100,  97,  66]])\n",
      "Targets:\n",
      "tensor([2, 0, 2, 2, 3, 1, 2, 1, 3, 0, 3, 3, 1, 0, 2, 3, 2, 2, 1, 3, 0, 3, 1, 1,\n",
      "        0, 2, 2, 1, 3, 2, 2, 0, 3, 1, 0, 0, 1, 2, 3, 2])\n",
      "\n",
      "Batch 56\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,  99,  66,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ..., 100,  66,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 0, 3, 3, 2, 3, 1, 1, 3, 1, 1, 2, 2, 0, 2, 1, 1, 2, 1, 0, 1, 1, 2,\n",
      "        2, 1, 3, 0, 0, 1, 2, 1, 1, 0, 1, 1, 2, 1, 2, 2])\n",
      "\n",
      "Batch 57\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,  97,  66,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 0, 2, 2, 2, 3, 1, 1, 3, 0, 0, 0, 2, 1, 1, 1, 3, 1, 3, 0, 1, 1, 2,\n",
      "        0, 0, 0, 3, 2, 0, 0, 3, 0, 3, 1, 0, 3, 0, 3, 2])\n",
      "\n",
      "Batch 58\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  97,  66,   0],\n",
      "        [ 69, 100,  97,  ...,  99,  98,  66],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 1, 1, 0, 3, 1, 2, 0, 3, 2, 3, 0, 0, 2, 0, 1, 0, 1, 2, 0, 3, 1, 1,\n",
      "        2, 1, 1, 0, 0, 3, 2, 2, 1, 1, 0, 2, 3, 0, 1, 0])\n",
      "\n",
      "Batch 59\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,  99,  66,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 1, 3, 1, 3, 0, 1, 0, 0, 3, 2, 0, 1,\n",
      "        1, 0, 1, 2, 2, 3, 1, 2, 1, 3, 0, 3, 1, 0, 2, 0])\n",
      "\n",
      "Batch 60\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,  98,  97,  66],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  98,  97,  66]])\n",
      "Targets:\n",
      "tensor([1, 2, 0, 3, 3, 1, 1, 1, 3, 3, 3, 2, 1, 2, 3, 3, 3, 0, 1, 0, 3, 2, 2, 2,\n",
      "        3, 3, 1, 3, 2, 1, 2, 0, 2, 1, 0, 3, 1, 3, 2, 2])\n",
      "\n",
      "Batch 61\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ..., 100,  99,  66],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,  99,  99,  66],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 0, 0, 0, 2, 3, 1, 2, 2, 3, 0, 2, 1, 2, 2, 1, 0, 3, 2, 3, 1, 3, 1,\n",
      "        3, 0, 3, 1, 2, 1, 0, 0, 1, 3, 1, 0, 1, 2, 3, 3])\n",
      "\n",
      "Batch 62\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 3, 1, 3, 1, 2, 3, 0, 2, 1, 1, 1, 3, 3, 2, 0, 2, 2, 3, 2, 0, 2, 1,\n",
      "        0, 1, 1, 2, 3, 2, 2, 3, 0, 3, 0, 0, 0, 3, 2, 3])\n",
      "\n",
      "Batch 63\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  97,  99,  66],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 3, 2, 1, 3, 1, 3, 2, 3, 0, 1, 0, 0, 0, 1, 3, 2, 1, 1, 2, 3, 1, 0,\n",
      "        3, 2, 3, 3, 0, 1, 0, 3, 3, 1, 0, 2, 1, 3, 3, 0])\n",
      "\n",
      "Batch 64\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,  97,  66,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 1, 2, 0, 0, 0, 0, 0, 0, 3, 0, 2, 3, 2, 3, 2, 1, 3, 3, 1, 2, 1, 3,\n",
      "        3, 0, 0, 3, 1, 0, 2, 0, 0, 1, 1, 0, 2, 3, 2, 1])\n",
      "\n",
      "Batch 65\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  97,  66,   0],\n",
      "        [ 69,  99, 100,  ...,  97,  98,  66],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,  98,  98,  66],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 2, 3, 1, 0, 0, 3, 1, 2, 2, 2, 1, 3, 0, 2, 1, 3, 0, 2, 2, 3, 3, 1,\n",
      "        3, 3, 1, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 1, 0, 0])\n",
      "\n",
      "Batch 66\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  99,  98,  66],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 2, 2, 2, 3, 1, 1, 3, 1, 2, 3, 0, 3, 0, 3, 0, 1, 2, 0, 1, 0, 0, 0,\n",
      "        1, 2, 1, 3, 0, 2, 1, 1, 3, 2, 1, 2, 3, 2, 2, 3])\n",
      "\n",
      "Batch 67\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,  97,  66,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  97, 100,  66],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 3, 3, 2, 2, 0, 3, 1, 0, 2, 1, 1, 2, 2, 0, 0, 0, 1, 0, 1, 1, 2, 0,\n",
      "        2, 1, 2, 2, 0, 2, 2, 2, 1, 2, 3, 3, 3, 1, 0, 2])\n",
      "\n",
      "Batch 68\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  97,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,  98, 100,  66],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  98,  66,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 0, 3, 2, 3, 0, 2, 3, 2, 2, 0, 3, 1, 3, 1, 2, 1, 0, 3, 1, 1, 3, 1,\n",
      "        0, 3, 0, 0, 3, 1, 3, 1, 2, 3, 0, 1, 2, 1, 1, 1])\n",
      "\n",
      "Batch 69\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,  98,  99,  66],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  99,  66,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 1, 3, 2, 3, 2, 0, 1, 3, 1, 0, 0, 2, 2, 3, 1, 1, 3, 3, 2, 0, 0, 1,\n",
      "        3, 2, 1, 0, 2, 1, 0, 1, 3, 1, 1, 2, 0, 1, 1, 0])\n",
      "\n",
      "Batch 70\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,  97,  66,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 2, 0, 1, 0, 1, 0, 0, 3, 2, 1, 3, 3, 2, 1, 0, 1, 2, 2, 3, 1, 0, 2,\n",
      "        2, 1, 0, 3, 2, 1, 3, 3, 1, 0, 2, 0, 1, 3, 2, 0])\n",
      "\n",
      "Batch 71\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  98,  ..., 100,  66,   0],\n",
      "        [ 69,  99,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 3, 0, 0, 3,\n",
      "        2, 0, 0, 2, 0, 0, 2, 2, 1, 3, 3, 0, 2, 3, 2, 3])\n",
      "\n",
      "Batch 72\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 1, 0, 1, 1, 1, 2, 0, 1, 3, 0, 3, 1, 2,\n",
      "        2, 3, 1, 0, 3, 0, 3, 2, 3, 1, 1, 0, 0, 3, 3, 1])\n",
      "\n",
      "Batch 73\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,  98,  66,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 2, 0, 3, 0, 2, 0, 0, 0, 2, 0, 3, 3, 2, 2, 1, 2, 3, 3, 2, 1, 2, 2,\n",
      "        1, 0, 3, 1, 3, 2, 1, 1, 2, 0, 3, 2, 3, 2, 2, 3])\n",
      "\n",
      "Batch 74\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 0, 0, 3, 1, 0, 3, 0, 3, 1, 3, 1, 1, 3, 1, 1, 1, 3, 2, 1, 3, 1, 1,\n",
      "        0, 1, 3, 0, 2, 0, 0, 0, 1, 3, 3, 3, 1, 1, 0, 0])\n",
      "\n",
      "Batch 75\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 2, 2, 1, 0, 0, 2, 1, 0, 1, 0, 2, 0, 2, 3, 0, 3, 2, 1, 1, 0, 3, 1,\n",
      "        3, 0, 2, 3, 2, 0, 3, 1, 2, 3, 1, 3, 1, 0, 0, 0])\n",
      "\n",
      "Batch 76\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 0, 2, 2, 0, 3, 0, 3, 1, 1, 3, 3, 0, 3, 3, 2, 3, 0, 2, 2, 2, 3, 1,\n",
      "        2, 3, 1, 3, 3, 3, 3, 0, 0, 3, 0, 3, 0, 0, 1, 3])\n",
      "\n",
      "Batch 77\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  98, 100,  66],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,  98, 100,  66],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 2, 0, 0, 2, 1, 2, 3, 2, 2, 2, 3, 1, 0, 0, 2, 0, 1, 1, 2, 0, 1, 1,\n",
      "        2, 3, 1, 2, 0, 0, 0, 3, 1, 3, 1, 1, 0, 1, 1, 0])\n",
      "\n",
      "Batch 78\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,  98,  66,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 0, 0, 1, 2, 2, 0, 2, 3, 1, 3, 1, 3, 1, 2, 3, 2, 3, 3, 1, 3, 3, 0,\n",
      "        2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 3, 2])\n",
      "\n",
      "Batch 79\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 3, 3, 3, 0, 1, 1, 2, 0, 3, 2, 2, 2, 0, 0, 0, 3, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 1, 1, 3, 2, 0, 1, 0, 0, 3, 3, 2, 0, 1])\n",
      "\n",
      "Batch 80\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ..., 100,  99,  66],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ..., 100,  97,  66],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 1, 1, 3, 0, 1, 1, 1, 0, 3, 0, 2, 0, 3, 1, 0, 3, 0, 3, 0, 2, 2, 3,\n",
      "        2, 3, 0, 3, 3, 3, 2, 1, 2, 1, 2, 0, 3, 0, 0, 1])\n",
      "\n",
      "Batch 81\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 2, 1, 1, 3, 0, 2, 0, 3, 0, 0, 2, 0, 2, 2, 3, 1, 2, 3, 3, 2, 2, 2,\n",
      "        1, 2, 2, 3, 3, 3, 0, 2, 2, 3, 3, 3, 0, 0, 1, 0])\n",
      "\n",
      "Batch 82\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,  98,  99,  66],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 1, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 3, 0, 1, 1, 2, 0, 0, 0, 1, 3, 2,\n",
      "        0, 1, 2, 0, 1, 1, 3, 2, 2, 2, 3, 3, 0, 0, 3, 0])\n",
      "\n",
      "Batch 83\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ..., 100, 100,  66],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 0, 1, 1, 3, 0, 3, 0, 1, 1, 1, 2, 3, 3, 1, 1, 0, 3, 3, 2, 3, 2, 0,\n",
      "        0, 2, 0, 3, 0, 0, 2, 1, 3, 1, 3, 3, 1, 1, 3, 2])\n",
      "\n",
      "Batch 84\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ..., 100,  66,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 1, 3, 3, 1, 1, 3, 3, 1, 1, 0, 3, 3, 1, 3, 2, 3, 0, 3, 0, 1, 0, 0,\n",
      "        2, 0, 3, 0, 1, 3, 0, 1, 1, 1, 1, 0, 0, 3, 3, 3])\n",
      "\n",
      "Batch 85\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,  97,  66,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 0, 3, 2, 1, 1, 1, 0, 1, 3, 0, 2, 1, 3, 1, 2, 0, 3, 3, 0, 3, 2, 1,\n",
      "        1, 0, 1, 0, 3, 3, 2, 1, 3, 2, 1, 3, 2, 1, 0, 0])\n",
      "\n",
      "Batch 86\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  99,  97,  66],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  99,  66,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 3, 3, 0, 0, 1, 1, 2, 2, 1, 0, 1, 3, 1, 2, 2, 0, 3, 0, 3, 2, 1, 0,\n",
      "        3, 1, 3, 2, 2, 1, 1, 1, 0, 1, 0, 2, 3, 1, 0, 1])\n",
      "\n",
      "Batch 87\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 1, 1, 2, 0, 1, 2, 0, 1, 1, 2, 3, 2, 1, 2, 0, 2, 0, 3, 1, 1, 2, 1,\n",
      "        3, 2, 1, 3, 3, 1, 2, 2, 2, 2, 0, 1, 3, 3, 2, 3])\n",
      "\n",
      "Batch 88\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,  98,  66,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  99,  66,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 3, 1, 1, 3, 1, 0, 2, 0, 3, 3, 3, 0, 3, 3, 2, 1, 2, 2, 2, 3, 3, 2,\n",
      "        0, 3, 2, 2, 3, 2, 3, 0, 3, 1, 1, 3, 3, 2, 1, 0])\n",
      "\n",
      "Batch 89\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,  97, 100,  66],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 3, 3, 1, 3, 2, 1, 2, 3, 3, 1, 3, 2, 2, 2, 3, 3, 1, 3, 3, 0, 1,\n",
      "        3, 0, 2, 2, 2, 0, 0, 3, 2, 3, 1, 1, 2, 2, 1, 1])\n",
      "\n",
      "Batch 90\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ..., 100,  66,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 2, 0, 1, 1, 1, 0, 3, 1, 2, 0, 2, 0, 3, 3, 1, 2, 0, 0, 3, 3, 2, 3,\n",
      "        2, 0, 2, 0, 0, 1, 1, 3, 0, 3, 3, 3, 2, 0, 0, 2])\n",
      "\n",
      "Batch 91\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  97,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 3, 3, 0, 1, 1, 3, 2, 2, 2, 1, 1, 2, 0, 0, 0, 3, 2, 2, 1, 2, 3, 1,\n",
      "        0, 1, 3, 0, 0, 1, 0, 3, 3, 3, 0, 3, 2, 0, 3, 1])\n",
      "\n",
      "Batch 92\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 2, 2, 0, 1, 3, 0, 3, 3, 0, 2, 0, 0, 3, 1, 3, 2, 3, 0, 1, 3, 1, 2,\n",
      "        0, 3, 3, 0, 3, 3, 3, 3, 2, 3, 3, 3, 0, 2, 3, 3])\n",
      "\n",
      "Batch 93\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  99,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  98,  66,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 1, 3, 2, 0, 1, 2, 0, 0, 3, 0, 1, 1, 1, 0, 3, 1, 1, 2, 2, 1, 0, 1,\n",
      "        1, 3, 1, 1, 0, 2, 2, 3, 0, 3, 2, 0, 2, 1, 1, 2])\n",
      "\n",
      "Batch 94\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 3, 2, 0, 1, 3, 0, 0, 1, 3, 0, 2, 1, 3, 3, 1, 3, 2, 3, 3, 3, 1, 2,\n",
      "        1, 0, 2, 0, 3, 1, 3, 0, 3, 0, 0, 2, 0, 1, 1, 3])\n",
      "\n",
      "Batch 95\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  99,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 2, 0, 3, 2, 1, 0, 0, 0, 0, 3, 2, 2, 1, 3, 1, 1, 0, 3, 2, 1, 0, 0,\n",
      "        2, 1, 2, 3, 2, 0, 2, 1, 3, 3, 1, 2, 1, 3, 1, 3])\n",
      "\n",
      "Batch 96\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  99,  98,  66],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  99,  66,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 2, 0, 0, 1, 3, 3, 3, 2, 2, 2, 2, 3, 1, 0, 3, 0, 0, 3, 3, 2, 2, 2,\n",
      "        2, 2, 0, 1, 1, 1, 0, 0, 3, 0, 1, 2, 3, 2, 3, 0])\n",
      "\n",
      "Batch 97\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  97,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  99, 100,  ..., 100,  66,   0],\n",
      "        [ 69,  98,  98,  ..., 100,  66,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 2, 1, 1, 2, 1, 3, 3, 0, 0, 1, 2, 2, 2, 3, 0, 1, 3, 1, 1, 1, 1, 2,\n",
      "        0, 0, 1, 2, 3, 3, 2, 0, 2, 1, 1, 1, 0, 2, 2, 2])\n",
      "\n",
      "Batch 98\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  98,  99,  66],\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ..., 100,  97,  66],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 3, 1, 0, 1, 2, 2, 3, 2, 1, 0, 3, 3, 0, 1, 1, 0, 2, 1, 2, 1, 2, 2,\n",
      "        0, 2, 3, 1, 2, 0, 2, 2, 3, 2, 1, 1, 2, 2, 2, 3])\n",
      "\n",
      "Batch 99\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  97,  97,  66],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,  97,  97,  66]])\n",
      "Targets:\n",
      "tensor([3, 2, 0, 2, 1, 3, 2, 3, 2, 2, 2, 3, 3, 0, 1, 3, 2, 2, 3, 1, 0, 3, 1, 0,\n",
      "        3, 3, 2, 2, 1, 0, 0, 2, 3, 1, 0, 2, 3, 0, 2, 0])\n",
      "\n",
      "Batch 100\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 3, 1, 2, 0, 1, 0, 2, 1, 3, 0, 1, 2, 0, 3, 0, 2, 1, 2, 3, 2, 3, 2,\n",
      "        0, 0, 2, 0, 1, 3, 3, 0, 1, 0, 0, 1, 1, 0, 0, 0])\n",
      "\n",
      "Batch 101\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,  97,  97,  66],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 2, 3, 0, 3, 0, 2, 3, 3, 2, 0, 1, 1, 0, 0, 3, 0, 1, 1, 3, 3, 3, 3,\n",
      "        3, 2, 1, 1, 2, 1, 2, 0, 2, 3, 0, 0, 3, 0, 3, 0])\n",
      "\n",
      "Batch 102\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 0, 3, 0, 1, 1, 2, 1, 0, 1, 1, 2, 1, 2, 0, 2, 1, 3, 0, 2, 2, 2, 0,\n",
      "        0, 0, 2, 0, 2, 0, 3, 1, 1, 0, 3, 3, 1, 2, 3, 1])\n",
      "\n",
      "Batch 103\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 0, 1, 2, 2, 0, 2, 0, 2, 2, 3, 3, 1, 1, 3, 3, 1, 1, 2, 1, 2, 3,\n",
      "        2, 1, 1, 0, 2, 3, 2, 2, 3, 2, 1, 1, 1, 0, 1, 0])\n",
      "\n",
      "Batch 104\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,  98,  97,  66],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,  97,  66,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 2, 0, 2, 1, 2, 2, 2, 3, 3, 3, 2, 1, 2, 2, 3, 3, 3, 0, 3, 1, 0, 0,\n",
      "        3, 0, 2, 2, 1, 2, 0, 0, 0, 2, 1, 3, 1, 3, 0, 2])\n",
      "\n",
      "Batch 105\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 1, 2, 0, 3, 2, 0, 3, 0, 2, 2, 0, 2, 2, 1, 2, 2, 0, 2, 2, 3, 0, 3,\n",
      "        2, 0, 1, 0, 1, 2, 2, 2, 1, 3, 3, 2, 2, 0, 1, 0])\n",
      "\n",
      "Batch 106\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,  98,  66,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 3, 0, 2, 2, 3, 1, 3, 1, 0, 1, 2, 0, 1, 3, 1, 3, 3, 0, 1, 3, 0, 1,\n",
      "        3, 2, 3, 0, 0, 0, 1, 0, 3, 0, 2, 1, 2, 1, 2, 2])\n",
      "\n",
      "Batch 107\n",
      "Sequences:\n",
      "tensor([[69, 98, 98,  ...,  0,  0,  0],\n",
      "        [69, 98, 98,  ...,  0,  0,  0],\n",
      "        [69, 98, 97,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [69, 97, 98,  ..., 99, 97, 66],\n",
      "        [69, 97, 98,  ...,  0,  0,  0],\n",
      "        [69, 99, 98,  ...,  0,  0,  0]])\n",
      "Targets:\n",
      "tensor([3, 2, 0, 1, 0, 3, 0, 1, 2, 2, 3, 1, 0, 3, 0, 3, 1, 0, 1, 0, 0, 1, 0, 2,\n",
      "        2, 0, 3, 1, 3, 0, 1, 0, 1, 3, 0, 3, 1, 2, 1, 2])\n",
      "\n",
      "Batch 108\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  98,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  99,  99,  66],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 1, 1, 0, 0, 2, 3, 3, 2, 1, 0, 2, 1, 0, 0, 3, 2, 0, 2, 2, 1, 2, 2,\n",
      "        3, 1, 3, 1, 2, 2, 0, 2, 0, 1, 0, 3, 3, 3, 0, 2])\n",
      "\n",
      "Batch 109\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,  98,  99,  66],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ..., 100,  98,  66]])\n",
      "Targets:\n",
      "tensor([2, 2, 1, 3, 3, 0, 0, 2, 2, 0, 2, 1, 3, 0, 0, 3, 3, 1, 3, 2, 1, 2, 1, 1,\n",
      "        1, 3, 2, 1, 2, 3, 2, 0, 0, 3, 2, 0, 3, 0, 3, 3])\n",
      "\n",
      "Batch 110\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,  97,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ..., 100,  66,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 1, 0, 2, 2, 3, 1, 3, 2, 0, 3, 1, 1, 2, 0, 1, 3, 2, 1, 1, 2, 1, 0,\n",
      "        2, 1, 0, 0, 2, 3, 2, 1, 3, 3, 2, 0, 3, 3, 1, 0])\n",
      "\n",
      "Batch 111\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 0, 3, 0, 3, 3, 0, 0, 3, 2, 3, 1, 3, 2, 3, 0, 3, 0, 1, 2, 3, 0, 3,\n",
      "        2, 3, 1, 2, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 1, 2])\n",
      "\n",
      "Batch 112\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,  99,  66,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  97,  66,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 0, 1, 2, 0, 2, 1, 3, 1, 2, 1, 3, 1, 2, 3, 1, 1, 1, 3, 1, 0, 1, 1,\n",
      "        0, 2, 0, 1, 1, 2, 2, 3, 0, 0, 0, 1, 3, 3, 2, 1])\n",
      "\n",
      "Batch 113\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  98, 100,  66],\n",
      "        [ 69, 100, 100,  ..., 100,  66,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 0, 0, 3, 2, 0, 0, 1, 1, 1, 3, 2, 2, 3, 3, 1, 1, 1, 2, 0, 3, 3, 3,\n",
      "        1, 0, 3, 1, 2, 0, 1, 3, 1, 2, 3, 0, 2, 0, 0, 3])\n",
      "\n",
      "Batch 114\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,  98, 100,  66]])\n",
      "Targets:\n",
      "tensor([0, 1, 0, 3, 0, 0, 1, 1, 1, 0, 3, 1, 2, 1, 2, 3, 1, 1, 1, 1, 0, 2, 0, 1,\n",
      "        2, 1, 0, 0, 0, 2, 1, 1, 0, 3, 2, 3, 2, 1, 1, 0])\n",
      "\n",
      "Batch 115\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 3, 3, 2, 2, 0, 2, 2, 3, 1, 0, 3, 2, 2, 1, 2, 2, 3, 2, 0, 2, 3, 0,\n",
      "        0, 3, 2, 2, 1, 2, 2, 3, 0, 3, 1, 1, 1, 0, 3, 3])\n",
      "\n",
      "Batch 116\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,  99,  66,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,  98,  66,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 2, 0, 2, 2, 1, 0, 3, 0, 0, 3, 1, 2, 1, 1, 0, 3, 2, 2, 2, 1, 0, 3,\n",
      "        1, 1, 3, 0, 3, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1, 2])\n",
      "\n",
      "Batch 117\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ..., 100,  66,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 2, 3, 1, 1, 1, 2, 2, 1, 1, 2, 3, 2, 3, 3, 0, 3, 1, 2, 1, 2, 0, 0,\n",
      "        3, 2, 3, 2, 2, 2, 0, 2, 3, 2, 3, 3, 1, 1, 1, 1])\n",
      "\n",
      "Batch 118\n",
      "Sequences:\n",
      "tensor([[69, 97, 98,  ...,  0,  0,  0],\n",
      "        [69, 97, 98,  ...,  0,  0,  0],\n",
      "        [69, 99, 99,  ..., 99, 97, 66],\n",
      "        ...,\n",
      "        [69, 98, 98,  ...,  0,  0,  0],\n",
      "        [69, 97, 97,  ...,  0,  0,  0],\n",
      "        [69, 97, 98,  ...,  0,  0,  0]])\n",
      "Targets:\n",
      "tensor([0, 3, 3, 1, 0, 0, 1, 2, 3, 1, 1, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0, 3, 3, 2,\n",
      "        3, 0, 0, 2, 2, 3, 3, 1, 1, 2, 0, 3, 0, 3, 0, 2])\n",
      "\n",
      "Batch 119\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  98, 100,  66],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ..., 100,  66,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 2, 2, 1, 1, 1, 0, 0, 0, 0, 1, 2, 1, 3, 0, 1, 2, 0, 3, 2, 2, 0, 3,\n",
      "        1, 1, 3, 0, 2, 2, 2, 3, 3, 1, 0, 3, 3, 2, 3, 2])\n",
      "\n",
      "Batch 120\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,  98,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 2, 3, 3, 0, 0, 3, 3, 2, 1, 3, 0, 1, 0, 1, 1, 2, 0, 0, 0, 0, 3, 0,\n",
      "        1, 0, 0, 3, 2, 0, 2, 3, 3, 2, 2, 1, 3, 1, 3, 0])\n",
      "\n",
      "Batch 121\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 3, 0, 3, 2, 2, 1, 1, 3, 2, 0, 0, 0, 1, 1, 2, 0, 0, 3, 3, 2, 1, 0,\n",
      "        2, 2, 2, 1, 3, 1, 3, 1, 0, 3, 2, 2, 2, 1, 1, 2])\n",
      "\n",
      "Batch 122\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 1, 0, 0, 3, 2, 0, 3, 1, 0, 1, 3, 3, 0, 2, 3, 0, 3, 1, 1, 0, 3, 3,\n",
      "        0, 2, 0, 2, 1, 3, 1, 1, 2, 3, 2, 1, 0, 3, 0, 2])\n",
      "\n",
      "Batch 123\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,  97,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 1, 0, 3, 2, 3, 2, 2, 3, 2, 0, 0, 1, 3, 0, 3, 2, 2, 0, 1, 0, 3, 0,\n",
      "        3, 3, 0, 3, 1, 2, 1, 0, 2, 2, 2, 1, 0, 3, 3, 1])\n",
      "\n",
      "Batch 124\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 1, 1, 2, 2, 3, 3, 2, 2, 0, 3, 3, 0, 3, 3, 2, 3, 0, 2, 2, 0, 0, 3,\n",
      "        0, 0, 3, 3, 1, 3, 0, 0, 2, 2, 2, 2, 2, 3, 3, 3])\n",
      "\n",
      "Batch 125\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  99,  99,  66],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 3, 0, 3, 2, 3, 3, 1, 1, 3, 0, 0, 2, 2, 3, 3, 2, 2, 3, 2, 0, 3, 3,\n",
      "        1, 0, 3, 1, 0, 1, 1, 1, 3, 0, 0, 2, 3, 2, 1, 2])\n",
      "\n",
      "Batch 126\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,  98,  98,  66],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 1, 0, 0, 3, 0, 0, 2, 2, 1, 2, 2, 0, 0, 2, 0, 1, 0, 3, 2, 1, 2, 3,\n",
      "        3, 0, 0, 3, 3, 2, 0, 0, 3, 0, 3, 0, 2, 0, 1, 3])\n",
      "\n",
      "Batch 127\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,  99, 100,  66],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ..., 100,  66,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 1, 0, 2, 2, 3, 0, 1, 1, 0, 1, 1, 2, 2, 3, 0, 3, 2, 2, 0, 0, 2, 3,\n",
      "        3, 2, 1, 1, 2, 0, 3, 1, 0, 2, 0, 1, 2, 3, 0, 2])\n",
      "\n",
      "Batch 128\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  99, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 3, 2, 3, 0, 3, 3, 2, 1, 2, 1, 3, 0, 2, 2, 3, 2, 2, 2, 3, 1, 0, 0,\n",
      "        2, 2, 3, 3, 1, 3, 0, 1, 0, 1, 0, 2, 2, 3, 2, 1])\n",
      "\n",
      "Batch 129\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  99,  66,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 2, 3, 3, 3, 1, 0, 0, 0, 3, 1, 0, 0, 3, 3, 0, 2, 1, 1, 2, 2, 2, 1,\n",
      "        3, 2, 0, 0, 0, 2, 1, 0, 1, 1, 1, 1, 2, 1, 1, 3])\n",
      "\n",
      "Batch 130\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,  99,  66,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 3, 2, 2, 3, 0, 1, 0, 3, 3, 2, 2, 1, 3, 0, 3, 1, 2, 1, 3, 1, 2, 1,\n",
      "        3, 2, 3, 0, 3, 0, 1, 3, 2, 3, 0, 1, 1, 1, 3, 2])\n",
      "\n",
      "Batch 131\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,  98,  66,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,  98,  98,  66],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,  97,  98,  66],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 3, 3, 3, 2, 2, 1, 3, 1, 1, 2, 3, 2, 1, 3, 3, 2, 1, 0, 3, 1, 1, 3,\n",
      "        2, 3, 0, 2, 0, 3, 3, 1, 2, 2, 3, 1, 0, 1, 3, 2])\n",
      "\n",
      "Batch 132\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  97, 100,  66],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ..., 100, 100,  66],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 1, 0, 0, 2, 0, 2, 3, 2, 2, 2, 3, 1, 0, 1, 1, 2, 1, 3, 1, 2, 2, 3,\n",
      "        2, 2, 2, 1, 2, 3, 1, 1, 1, 0, 0, 2, 0, 1, 3, 3])\n",
      "\n",
      "Batch 133\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  98,  99,  66],\n",
      "        [ 69,  97,  99,  ..., 100,  97,  66],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 1, 0, 0, 1, 1, 3, 2, 1, 2, 0, 1, 1, 0, 3, 1, 0, 1, 3, 0, 2, 2, 1,\n",
      "        2, 2, 3, 1, 0, 2, 0, 1, 1, 2, 3, 0, 0, 2, 1, 3])\n",
      "\n",
      "Batch 134\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,  98, 100,  66],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 3, 2, 3, 3, 3, 1, 3, 3, 1, 1, 1, 2, 3, 3, 3, 3, 0, 1, 2, 2, 2, 2,\n",
      "        3, 1, 0, 2, 0, 3, 2, 0, 2, 1, 1, 2, 1, 0, 1, 3])\n",
      "\n",
      "Batch 135\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  98,  98,  66],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 2, 3, 2, 2, 3, 2, 2, 2, 1, 1, 1, 3, 0, 3, 3, 1, 0, 3, 3, 0, 2, 1,\n",
      "        0, 2, 3, 1, 0, 0, 1, 2, 2, 0, 0, 3, 2, 0, 1, 3])\n",
      "\n",
      "Batch 136\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,  98,  66,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ..., 100,  97,  66],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ..., 100,  66,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 0, 3, 3, 2, 2, 1, 0, 2, 0, 0, 0, 0, 3, 1, 2, 3, 3, 0, 3, 1, 3, 1,\n",
      "        1, 1, 2, 0, 3, 2, 2, 3, 3, 2, 1, 0, 3, 1, 1, 0])\n",
      "\n",
      "Batch 137\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99, 100,  ..., 100,  66,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 0, 0, 0, 0, 3, 1, 0, 2, 0, 2, 2, 1, 2, 3, 3, 1, 3, 0, 0, 3, 0, 2,\n",
      "        1, 1, 3, 2, 1, 0, 3, 0, 3, 0, 0, 0, 2, 0, 1, 0])\n",
      "\n",
      "Batch 138\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  97,  97,  66],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 1, 1, 0, 3, 3, 1, 2, 1, 1, 1, 1, 0, 0, 2, 0, 3, 1, 3, 3, 0, 3, 2,\n",
      "        2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 3, 2, 1, 2, 1, 2])\n",
      "\n",
      "Batch 139\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ..., 100,  99,  66],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,  99,  99,  66],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  97, 100,  66]])\n",
      "Targets:\n",
      "tensor([3, 1, 1, 0, 2, 3, 3, 1, 1, 3, 1, 2, 0, 3, 2, 1, 2, 0, 3, 3, 0, 0, 0, 2,\n",
      "        0, 0, 0, 0, 2, 0, 2, 3, 3, 2, 2, 1, 0, 1, 2, 0])\n",
      "\n",
      "Batch 140\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,  99, 100,  66],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  97,  98,  66],\n",
      "        ...,\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 0, 0, 0, 1, 0, 3, 1, 0, 2, 1, 1, 1, 0, 3, 2, 1, 1, 2, 3, 1, 3,\n",
      "        0, 0, 0, 3, 1, 3, 1, 1, 1, 0, 1, 3, 0, 1, 1, 3])\n",
      "\n",
      "Batch 141\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,  97,  98,  66],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 1, 1, 2, 2, 2, 3, 2, 1, 2, 1, 1, 3, 1, 2, 0, 3, 1, 0, 0, 3, 3, 0,\n",
      "        2, 3, 2, 3, 1, 2, 1, 0, 2, 0, 3, 1, 0, 3, 2, 0])\n",
      "\n",
      "Batch 142\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ..., 100, 100,  66],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 2, 3, 3, 3, 1, 3, 2, 2, 2, 3, 3, 1, 3, 3, 2, 1, 2, 2, 1, 2, 2, 1,\n",
      "        2, 3, 3, 1, 3, 1, 2, 3, 2, 0, 0, 0, 1, 0, 2, 3])\n",
      "\n",
      "Batch 143\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  98,  98,  66]])\n",
      "Targets:\n",
      "tensor([0, 2, 1, 3, 0, 3, 3, 3, 2, 1, 2, 2, 2, 2, 3, 2, 0, 2, 2, 3, 3, 3, 1, 3,\n",
      "        2, 1, 0, 3, 1, 1, 3, 3, 1, 0, 0, 3, 1, 1, 3, 3])\n",
      "\n",
      "Batch 144\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 0, 0, 1, 3, 0, 2, 3, 2, 1, 2, 2, 0, 2, 2, 3, 0, 1, 0, 1, 0, 2, 1,\n",
      "        1, 2, 3, 1, 1, 0, 2, 2, 0, 1, 0, 2, 1, 1, 2, 1])\n",
      "\n",
      "Batch 145\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,  99,  98,  66],\n",
      "        [ 69,  98,  97,  ...,  97,  66,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 0, 3, 0, 3, 2, 0, 3, 1, 3, 1, 3, 2, 3, 0, 1, 2, 1, 3, 3, 0, 1, 3,\n",
      "        3, 1, 2, 1, 1, 0, 0, 0, 1, 2, 1, 3, 0, 0, 1, 2])\n",
      "\n",
      "Batch 146\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,  98,  66,   0],\n",
      "        [ 69,  98,  97,  ...,  97,  98,  66],\n",
      "        [ 69, 100,  98,  ...,  97,  66,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 2, 3, 3, 0, 0, 0, 2, 0, 3, 1, 2, 1, 1, 0, 3, 1, 0, 2, 0, 0, 3, 0,\n",
      "        0, 0, 0, 3, 2, 0, 0, 0, 1, 0, 0, 3, 0, 2, 1, 0])\n",
      "\n",
      "Batch 147\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,  98,  66,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 1, 1, 3, 3, 0, 2, 0, 0, 0, 0, 0, 2, 2, 1, 2, 1, 1, 3, 2, 0, 2, 2,\n",
      "        3, 1, 2, 0, 0, 3, 3, 3, 0, 3, 0, 3, 1, 1, 3, 0])\n",
      "\n",
      "Batch 148\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  98,  99,  66],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 0, 3, 3, 0, 3, 0, 2, 3, 0, 1, 2, 1, 3, 0, 3, 1, 3, 1, 2, 3, 1, 2,\n",
      "        2, 0, 0, 1, 1, 0, 3, 3, 0, 0, 3, 0, 3, 3, 2, 3])\n",
      "\n",
      "Batch 149\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ..., 100,  66,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 1, 2, 3, 2, 1, 0, 1, 3, 1, 0, 2, 0, 0, 3, 0, 1, 0, 2, 1, 0, 1, 3,\n",
      "        3, 1, 3, 0, 3, 1, 2, 0, 0, 0, 2, 0, 3, 2, 0, 3])\n",
      "\n",
      "Batch 150\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  98,  99,  66],\n",
      "        [ 69,  97,  98,  ...,  99,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 0, 1, 1, 1, 1, 0, 3, 1, 0, 0, 0, 2, 3, 0, 2, 0, 0, 3, 3, 1, 1, 1,\n",
      "        3, 1, 3, 1, 0, 1, 0, 2, 1, 1, 1, 3, 3, 0, 3, 3])\n",
      "\n",
      "Batch 151\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,  97,  66,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,  97,  98,  66],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 3, 0, 2, 1, 2, 1, 3, 1, 3, 2, 1, 0, 2, 2, 2, 2, 0, 1, 2, 1, 1, 2,\n",
      "        3, 1, 3, 2, 3, 3, 2, 2, 2, 1, 2, 3, 1, 1, 1, 2])\n",
      "\n",
      "Batch 152\n",
      "Sequences:\n",
      "tensor([[69, 98, 99,  ...,  0,  0,  0],\n",
      "        [69, 98, 97,  ...,  0,  0,  0],\n",
      "        [69, 97, 98,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [69, 99, 97,  ...,  0,  0,  0],\n",
      "        [69, 98, 99,  ...,  0,  0,  0],\n",
      "        [69, 97, 99,  ...,  0,  0,  0]])\n",
      "Targets:\n",
      "tensor([0, 3, 3, 2, 2, 3, 2, 2, 2, 1, 2, 0, 2, 3, 3, 2, 3, 0, 2, 0, 1, 0, 2, 1,\n",
      "        2, 1, 3, 0, 0, 3, 3, 0, 2, 0, 3, 0, 0, 3, 1, 0])\n",
      "\n",
      "Batch 153\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,  97,  99,  66],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ..., 100,  99,  66]])\n",
      "Targets:\n",
      "tensor([1, 2, 3, 0, 3, 0, 3, 1, 2, 0, 0, 1, 1, 0, 0, 3, 3, 0, 0, 3, 2, 1, 1, 1,\n",
      "        2, 3, 1, 1, 0, 2, 1, 0, 0, 2, 3, 2, 2, 1, 2, 1])\n",
      "\n",
      "Batch 154\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 3, 0, 2, 1, 3, 2, 3, 0, 1, 2, 3, 2, 0, 3, 1, 2, 0, 2, 1, 2, 3, 2,\n",
      "        1, 1, 2, 2, 0, 2, 2, 1, 2, 3, 2, 0, 3, 1, 3, 2])\n",
      "\n",
      "Batch 155\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ..., 100,  66,   0],\n",
      "        [ 69,  98,  97,  ...,  99,  66,   0],\n",
      "        [ 69, 100, 100,  ...,  99,  99,  66],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,  99,  66,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 3, 2, 0, 3, 0, 3, 0, 0, 1, 2, 1, 0, 3, 2, 1, 1, 2, 3, 3, 3, 1, 1,\n",
      "        2, 0, 2, 2, 2, 0, 3, 1, 3, 2, 3, 0, 1, 2, 3, 0])\n",
      "\n",
      "Batch 156\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  98, 100,  66],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 1, 1, 2, 2, 2, 3, 3, 3, 0, 0, 3, 3, 0, 2, 1, 2, 1, 0, 3, 1, 0, 3,\n",
      "        0, 2, 1, 2, 0, 0, 1, 2, 0, 0, 3, 3, 1, 0, 3, 1])\n",
      "\n",
      "Batch 157\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  97,  99,  66],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 3, 1, 0, 3, 3, 3, 2, 0, 1, 2, 0, 1, 1, 3, 3, 1, 2, 0, 1, 1, 0,\n",
      "        1, 1, 3, 1, 1, 3, 0, 2, 2, 1, 3, 3, 3, 1, 3, 0])\n",
      "\n",
      "Batch 158\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 1, 2, 2, 2, 0, 2, 3, 1, 3, 0, 0, 0, 1, 2, 1, 0, 3, 0, 3, 0, 0, 1,\n",
      "        0, 3, 0, 3, 0, 1, 3, 3, 1, 2, 3, 3, 3, 1, 3, 0])\n",
      "\n",
      "Batch 159\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 0, 0, 1, 3, 1, 0, 2, 1, 0, 2, 2, 3, 2,\n",
      "        2, 3, 2, 1, 3, 2, 0, 2, 0, 1, 3, 2, 1, 2, 1, 1])\n",
      "\n",
      "Batch 160\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 1, 0, 0, 2, 0, 0, 3, 1, 0, 1, 2, 1, 2, 1, 2, 0, 2, 1, 1, 3, 2, 3,\n",
      "        2, 2, 3, 2, 0, 1, 0, 2, 3, 1, 0, 2, 3, 1, 1, 2])\n",
      "\n",
      "Batch 161\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 3, 0, 1, 0, 2, 1, 2, 0, 3, 1, 3, 1, 0, 3, 1, 0, 1, 3, 3, 2, 3, 1,\n",
      "        3, 1, 1, 0, 0, 2, 2, 1, 3, 0, 3, 0, 3, 3, 3, 0])\n",
      "\n",
      "Batch 162\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  98,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 2, 3, 1, 3, 0, 0, 0, 0, 0, 3, 1, 3, 2, 3, 0, 1, 2, 3, 2, 0, 3, 0,\n",
      "        1, 2, 3, 3, 1, 0, 0, 0, 1, 2, 2, 2, 2, 3, 1, 2])\n",
      "\n",
      "Batch 163\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 2, 1, 3, 0, 0, 3, 3, 3, 0, 1, 1, 2, 1, 0, 1, 1, 2, 0, 3, 2, 0, 3,\n",
      "        0, 2, 3, 2, 0, 3, 0, 1, 1, 0, 3, 2, 3, 2, 1, 3])\n",
      "\n",
      "Batch 164\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,  99, 100,  66],\n",
      "        [ 69, 100,  98,  ..., 100,  66,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 2, 1, 0, 2, 1, 1, 3, 3, 0, 3, 0, 1, 1, 2, 2, 0, 0, 2, 0, 0, 3, 1,\n",
      "        1, 2, 3, 1, 0, 3, 3, 0, 0, 0, 3, 0, 1, 2, 3, 3])\n",
      "\n",
      "Batch 165\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  99,  98,  66],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 3, 2, 2, 2, 1, 1, 3, 0, 0, 3, 3, 3, 1, 2, 3, 3, 1, 1, 0, 2, 0, 3,\n",
      "        2, 3, 0, 2, 2, 3, 1, 2, 1, 3, 3, 0, 1, 1, 3, 2])\n",
      "\n",
      "Batch 166\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,  99,  97,  66],\n",
      "        [ 69,  98, 100,  ..., 100, 100,  66],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  98,  66,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 3, 2, 3, 0, 1, 1, 1, 3, 2, 0, 3, 0, 2, 3, 1, 0, 2, 1, 0, 0, 3, 0,\n",
      "        3, 2, 1, 0, 2, 0, 2, 2, 2, 1, 1, 2, 0, 0, 0, 3])\n",
      "\n",
      "Batch 167\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  98,  66,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 2, 3, 0, 3, 1, 3, 0, 0, 1, 3, 1, 1, 0, 0, 3, 0, 0, 1, 1, 1, 3, 0,\n",
      "        1, 0, 3, 0, 2, 0, 3, 2, 1, 1, 1, 3, 3, 3, 3, 1])\n",
      "\n",
      "Batch 168\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,  97,  97,  66],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,  97, 100,  66],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 1, 0, 0, 3, 3, 0, 0, 3, 3, 2, 1, 1, 1, 2, 3, 0, 1, 3, 1, 3, 0, 0,\n",
      "        1, 1, 2, 2, 2, 2, 3, 3, 1, 2, 1, 2, 0, 0, 1, 1])\n",
      "\n",
      "Batch 169\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ..., 100,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 2, 1, 0, 2, 1, 2, 3, 3, 3, 3, 2, 0, 1, 3, 2, 0, 1, 1, 0, 0, 1, 3,\n",
      "        0, 3, 3, 1, 2, 2, 3, 2, 1, 2, 1, 3, 0, 3, 0, 2])\n",
      "\n",
      "Batch 170\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  98,  99,  66]])\n",
      "Targets:\n",
      "tensor([3, 3, 1, 1, 1, 1, 1, 3, 2, 0, 3, 3, 3, 0, 0, 3, 1, 1, 3, 0, 0, 2, 1, 0,\n",
      "        2, 0, 2, 1, 2, 1, 0, 0, 0, 1, 2, 2, 2, 2, 3, 0])\n",
      "\n",
      "Batch 171\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,  99,  98,  66],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 1, 2, 2, 3, 0, 3, 1, 2, 2, 3, 3, 1, 2, 0, 3, 2, 1, 0, 3, 0, 1, 1,\n",
      "        2, 3, 1, 0, 2, 1, 0, 0, 1, 2, 3, 1, 1, 0, 3, 3])\n",
      "\n",
      "Batch 172\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,  97,  99,  66],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 0, 2, 1, 0, 1, 3, 2, 2, 3, 2, 0, 2, 3, 1, 3, 0, 3, 2, 3, 1, 0, 2,\n",
      "        1, 0, 2, 0, 0, 0, 1, 2, 2, 1, 3, 2, 2, 2, 1, 2])\n",
      "\n",
      "Batch 173\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  97,  ..., 100,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 3, 1, 1, 0, 1, 2, 0, 1, 3, 1, 3, 1, 1, 2, 3, 1, 0, 0, 3, 0, 2, 2,\n",
      "        2, 1, 3, 3, 3, 0, 1, 2, 2, 3, 1, 0, 0, 0, 2, 2])\n",
      "\n",
      "Batch 174\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 3, 2, 0, 1, 0, 1, 0, 3, 1, 2, 0, 1, 2, 1, 3, 1, 3, 0, 3, 1, 1, 3,\n",
      "        1, 2, 3, 3, 3, 0, 1, 3, 1, 2, 0, 2, 3, 0, 1, 0])\n",
      "\n",
      "Batch 175\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,  98,  98,  66],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ..., 100,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  99,  66,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 1, 3, 2, 3, 0, 3, 3, 0, 2, 3, 3, 3, 0, 0, 1, 3, 0, 3, 2, 0, 3, 2,\n",
      "        1, 0, 0, 2, 3, 0, 2, 2, 3, 1, 1, 2, 1, 0, 1, 0])\n",
      "\n",
      "Batch 176\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,  97,  66,   0],\n",
      "        [ 69, 100,  99,  ..., 100,  66,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 0, 1, 0, 3, 2, 3, 1, 0, 0, 2, 2, 2, 2, 3, 0, 2, 3, 1, 2, 1, 3, 0,\n",
      "        1, 1, 2, 3, 1, 0, 0, 2, 3, 3, 1, 2, 1, 1, 2, 2])\n",
      "\n",
      "Batch 177\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ..., 100,  98,  66],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  97,  66,   0],\n",
      "        [ 69,  99,  97,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 2, 2, 2, 3, 3, 1, 0, 0, 3, 3, 0, 1, 3, 0, 0, 3, 1, 0, 2, 1, 0, 3,\n",
      "        1, 0, 1, 0, 2, 3, 1, 2, 1, 0, 1, 0, 2, 1, 1, 0])\n",
      "\n",
      "Batch 178\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  98,  66,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 1, 1, 2, 0, 2, 0, 2, 2, 1, 1, 0, 0, 0, 0, 2, 1, 2, 3, 3, 2, 3, 3,\n",
      "        0, 3, 2, 2, 1, 1, 2, 2, 2, 0, 2, 3, 0, 0, 0, 3])\n",
      "\n",
      "Batch 179\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,  98,  66,   0],\n",
      "        [ 69,  97,  98,  ...,  97,  66,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 3, 3, 0, 3, 3, 1, 2, 1, 2, 0, 3, 1, 2, 1, 0, 2, 0, 2, 0, 3, 2, 2,\n",
      "        2, 3, 0, 3, 2, 3, 0, 0, 0, 1, 0, 2, 0, 0, 1, 1])\n",
      "\n",
      "Batch 180\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  98,  99,  66],\n",
      "        [ 69,  99,  97,  ...,  99,  66,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 1, 1, 1, 2, 3, 3, 2, 1, 2, 3, 1, 0, 2, 2, 2, 0, 1, 1, 0, 1, 1, 1,\n",
      "        2, 2, 1, 1, 0, 1, 3, 0, 1, 1, 1, 1, 3, 2, 2, 1])\n",
      "\n",
      "Batch 181\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 3, 2, 2, 0, 0, 0, 3, 2, 2, 0, 0, 0, 0, 1, 1, 1, 0, 2, 3, 0, 2, 3,\n",
      "        3, 3, 1, 2, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0, 3, 1])\n",
      "\n",
      "Batch 182\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  99,  97,  66]])\n",
      "Targets:\n",
      "tensor([2, 2, 0, 3, 2, 3, 1, 3, 1, 0, 0, 2, 3, 3, 3, 3, 1, 1, 1, 0, 0, 2, 1, 2,\n",
      "        0, 1, 3, 0, 3, 1, 2, 3, 0, 3, 2, 3, 2, 1, 3, 2])\n",
      "\n",
      "Batch 183\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 2, 3, 2, 2, 0, 0, 2, 1, 3, 1, 3, 3, 2, 2, 1, 3, 2, 0, 1, 0, 1, 0,\n",
      "        2, 2, 1, 2, 0, 0, 3, 0, 0, 2, 3, 1, 3, 0, 2, 0])\n",
      "\n",
      "Batch 184\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 0, 0, 0, 2, 1, 3, 3, 1, 3, 3, 2, 0, 3, 3, 2, 3, 1, 2, 3, 2, 2,\n",
      "        0, 2, 3, 0, 0, 1, 1, 1, 1, 2, 3, 2, 2, 0, 0, 1])\n",
      "\n",
      "Batch 185\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,  99,  66,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 2, 0, 2, 1, 2, 1, 1, 0, 1, 2, 2, 0, 3, 0, 2, 1, 3, 1, 3, 3, 2, 0,\n",
      "        1, 2, 1, 2, 1, 0, 2, 3, 1, 3, 2, 1, 1, 3, 0, 2])\n",
      "\n",
      "Batch 186\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ..., 100,  66,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  97,  66,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 3, 2, 2, 0, 0, 2, 3, 3, 1, 3, 2, 2, 2, 3, 2, 0, 0, 2, 1, 0, 1, 2,\n",
      "        3, 1, 0, 0, 3, 1, 1, 2, 3, 0, 1, 1, 0, 0, 3, 3])\n",
      "\n",
      "Batch 187\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ..., 100,  66,   0],\n",
      "        [ 69, 100,  98,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  99,  98,  66],\n",
      "        [ 69, 100, 100,  ..., 100,  66,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 3, 0, 0, 3, 1, 2, 2, 0, 0, 3, 1, 2, 2, 0, 0, 3, 2, 3, 2, 2, 2, 2,\n",
      "        2, 0, 1, 1, 2, 2, 2, 0, 2, 3, 1, 0, 0, 0, 2, 2])\n",
      "\n",
      "Batch 188\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98, 100,  ...,  97,  66,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 0, 3, 2, 2, 2, 2, 2, 3, 2, 3, 1, 1, 1, 2, 1, 0, 2, 0, 0, 2, 2, 0,\n",
      "        1, 2, 3, 1, 3, 3, 3, 2, 0, 3, 3, 0, 3, 0, 2, 0])\n",
      "\n",
      "Batch 189\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,  97,  66,   0],\n",
      "        [ 69, 100,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ..., 100,  66,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 3, 3, 3, 2, 1, 1, 1, 1, 3, 1, 1, 0, 3, 3, 0, 1, 0, 1, 1, 2, 0, 2,\n",
      "        1, 2, 3, 0, 3, 2, 0, 0, 0, 0, 3, 3, 3, 3, 1, 1])\n",
      "\n",
      "Batch 190\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 3, 2, 1, 3, 0, 0, 2, 1, 0, 1, 3, 3, 2, 1, 1, 2, 3, 2, 3, 1, 0, 1,\n",
      "        0, 3, 0, 1, 2, 3, 2, 3, 0, 0, 2, 1, 1, 3, 0, 3])\n",
      "\n",
      "Batch 191\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  99,  66,   0],\n",
      "        [ 69,  97,  98,  ..., 100,  98,  66]])\n",
      "Targets:\n",
      "tensor([2, 1, 3, 3, 1, 0, 0, 3, 3, 1, 1, 3, 1, 1, 2, 1, 3, 0, 2, 3, 1, 3, 1, 1,\n",
      "        3, 1, 1, 1, 2, 0, 3, 0, 2, 2, 0, 2, 1, 1, 0, 2])\n",
      "\n",
      "Batch 192\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 3, 2, 2, 1, 3, 0, 1, 1, 3, 1, 0, 1, 1, 3, 1, 0, 0, 2, 3, 0, 3, 3,\n",
      "        1, 0, 3, 1, 2, 3, 0, 1, 1, 2, 2, 2, 0, 1, 1, 1])\n",
      "\n",
      "Batch 193\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 1, 3, 2, 3, 1, 0, 3, 1, 2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 3, 1, 3, 0,\n",
      "        2, 1, 2, 0, 0, 3, 1, 1, 3, 1, 0, 2, 1, 2, 1, 2])\n",
      "\n",
      "Batch 194\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,  99,  66,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  99,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  99,  97,  66],\n",
      "        [ 69,  97,  98,  ...,  97,  99,  66]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 0, 0, 0, 2, 1, 1, 0, 1, 3, 3, 2, 1, 2, 3, 1, 2, 3, 0, 2, 3, 3,\n",
      "        0, 3, 2, 1, 0, 3, 3, 3, 3, 0, 2, 2, 2, 2, 1, 0])\n",
      "\n",
      "Batch 195\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ..., 100,  98,  66],\n",
      "        [ 69,  99,  97,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 2, 0, 1, 2, 3, 1, 0, 0, 2, 1, 0, 3, 3, 1, 0, 2, 2, 0, 1, 1, 2, 0,\n",
      "        1, 0, 1, 0, 2, 0, 2, 2, 2, 0, 0, 3, 2, 1, 0, 1])\n",
      "\n",
      "Batch 196\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  99,  ...,  99,  98,  66],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  99, 100,  66],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 2, 1, 1, 1, 1, 1, 0, 3, 0, 1, 2, 1, 1, 0, 3, 2, 0, 2, 2, 2, 1, 2,\n",
      "        2, 3, 3, 0, 0, 2, 0, 2, 1, 3, 1, 0, 2, 2, 1, 2])\n",
      "\n",
      "Batch 197\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  98, 100,  66],\n",
      "        [ 69, 100,  99,  ..., 100,  98,  66],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,  97,  66,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 2, 2, 3, 1, 0, 0, 1, 0, 3, 3, 3, 2, 1, 3, 0, 1, 0, 3, 2, 3, 1, 1,\n",
      "        3, 0, 0, 1, 3, 0, 2, 0, 1, 3, 3, 2, 1, 2, 2, 1])\n",
      "\n",
      "Batch 198\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  99, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  99, 100,  66],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 3, 2, 2, 3, 1, 2, 0, 2, 3, 2, 1, 1, 1, 0, 3, 1, 2, 2, 3, 2, 1, 0,\n",
      "        1, 2, 3, 1, 2, 3, 2, 1, 2, 0, 0, 3, 3, 2, 0, 2])\n",
      "\n",
      "Batch 199\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,  98,  99,  66],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 2, 0, 2, 0, 2, 1, 3, 3, 3, 3, 1, 1, 0, 0, 3, 0, 1, 1, 2, 0, 0, 3,\n",
      "        3, 3, 3, 2, 2, 0, 1, 1, 3, 1, 3, 3, 0, 2, 0, 2])\n",
      "\n",
      "Batch 200\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,  98,  98,  66],\n",
      "        [ 69,  99,  99,  ..., 100,  66,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,  97,  66,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 3, 1, 2, 2, 2, 2, 2, 0, 1, 0, 3, 3, 2, 0, 2, 0, 0, 1, 0, 3, 3, 0,\n",
      "        0, 0, 1, 3, 0, 3, 2, 0, 1, 3, 3, 1, 0, 3, 1, 1])\n",
      "\n",
      "Batch 201\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99, 100,  ...,  97,  98,  66],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 0, 3, 3, 2, 1, 0, 1, 1, 0, 0, 1, 0, 3, 1, 0, 2, 3, 0, 2, 0, 0, 2,\n",
      "        2, 1, 1, 2, 3, 0, 3, 2, 1, 1, 0, 3, 3, 3, 1, 3])\n",
      "\n",
      "Batch 202\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  97,  98,  66]])\n",
      "Targets:\n",
      "tensor([2, 0, 1, 0, 0, 3, 3, 2, 1, 2, 0, 1, 0, 0, 2, 0, 0, 1, 3, 2, 1, 2, 0, 2,\n",
      "        0, 2, 1, 1, 0, 2, 2, 0, 0, 0, 2, 1, 0, 1, 0, 2])\n",
      "\n",
      "Batch 203\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 2, 3, 2, 1, 0, 3, 0, 3, 1, 3, 3, 1, 3, 3, 3, 3, 0, 0, 3, 0, 1, 2,\n",
      "        2, 3, 1, 3, 1, 3, 2, 1, 3, 0, 3, 1, 3, 2, 2, 3])\n",
      "\n",
      "Batch 204\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,  97,  66,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 3, 1, 2, 1, 1, 2, 0, 2, 2, 3, 0, 3, 3, 3, 1, 1, 1, 2, 0, 2, 1, 1,\n",
      "        1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 2, 1, 2, 2, 1, 1])\n",
      "\n",
      "Batch 205\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 2, 3, 0, 3, 0, 3, 3, 1, 3, 0, 0, 0, 3, 2, 0, 3, 1, 0, 0, 0, 1, 2,\n",
      "        2, 2, 0, 2, 0, 3, 0, 2, 2, 3, 3, 0, 1, 1, 2, 1])\n",
      "\n",
      "Batch 206\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 3, 1, 0, 2, 1, 2, 2, 0, 3, 1,\n",
      "        1, 3, 2, 3, 0, 2, 2, 3, 3, 2, 1, 2, 3, 0, 0, 3])\n",
      "\n",
      "Batch 207\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ..., 100,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 1, 2, 0, 0, 1, 0, 2, 1, 2, 2, 0, 3, 1, 0, 3, 3, 0, 1, 0, 2, 2, 0,\n",
      "        0, 3, 3, 1, 1, 1, 0, 3, 0, 2, 2, 2, 0, 1, 1, 3])\n",
      "\n",
      "Batch 208\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 1, 3, 1, 3, 0, 2, 1, 0, 1, 1, 2, 1, 2, 3, 1, 1, 2, 0, 3, 3, 2, 2,\n",
      "        0, 1, 0, 3, 3, 2, 2, 2, 2, 2, 0, 0, 1, 3, 1, 2])\n",
      "\n",
      "Batch 209\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 1, 2, 0, 2, 3, 3, 0, 2, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 0, 2,\n",
      "        0, 1, 3, 0, 0, 0, 3, 0, 3, 2, 3, 2, 3, 2, 2, 2])\n",
      "\n",
      "Batch 210\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 0, 3, 0, 0, 2, 3, 1, 3, 2, 2, 0, 0, 1, 3, 3, 3, 3, 0, 0, 3, 2, 2,\n",
      "        1, 2, 3, 1, 3, 1, 3, 1, 2, 1, 3, 0, 3, 3, 1, 3])\n",
      "\n",
      "Batch 211\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 0, 3, 2, 0, 0, 2, 0, 0, 3, 3, 2, 3, 1, 3, 0, 2, 1, 2, 3, 3, 1,\n",
      "        0, 0, 1, 3, 0, 1, 2, 1, 1, 2, 0, 3, 3, 1, 1, 0])\n",
      "\n",
      "Batch 212\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ..., 100,  66,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,  99,  66,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 0, 1, 3, 2, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 3, 1, 3, 1, 0, 2, 1, 1,\n",
      "        3, 1, 0, 0, 2, 3, 0, 0, 2, 2, 3, 0, 2, 3, 3, 1])\n",
      "\n",
      "Batch 213\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  98,  66,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 1, 3, 0, 2, 1, 1, 0, 1, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 1, 0, 2,\n",
      "        3, 2, 3, 0, 2, 3, 0, 3, 3, 1, 0, 3, 3, 1, 0, 3])\n",
      "\n",
      "Batch 214\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  99,  98,  66],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 2, 0, 0, 0, 0, 2, 3, 1, 3, 0, 0, 0, 2, 2, 0, 3, 3, 0, 0, 2, 3, 3,\n",
      "        3, 1, 1, 1, 1, 2, 1, 3, 1, 0, 2, 0, 1, 2, 1, 1])\n",
      "\n",
      "Batch 215\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 0, 1, 3, 1, 3, 3, 1, 0, 2, 1, 3, 0, 0, 2, 0, 3, 1, 3, 3, 2, 2, 0,\n",
      "        3, 0, 0, 3, 3, 0, 3, 0, 0, 1, 2, 1, 0, 0, 2, 0])\n",
      "\n",
      "Batch 216\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,  98,  66,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 0, 2, 1, 3, 2, 3, 1, 0, 0, 1, 2, 2, 1, 2, 2, 1, 1, 3, 3, 3, 1, 1,\n",
      "        3, 0, 2, 0, 2, 0, 2, 2, 1, 1, 3, 2, 0, 2, 0, 1])\n",
      "\n",
      "Batch 217\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 3, 0, 1, 3, 0, 1, 3, 0, 1, 3, 2, 2, 0, 0, 2, 2, 3, 0, 1, 0, 3, 3,\n",
      "        1, 1, 2, 3, 0, 0, 0, 3, 0, 3, 1, 0, 1, 3, 3, 0])\n",
      "\n",
      "Batch 218\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 2, 0, 1, 3, 0, 1, 2, 0, 2, 1, 2, 2, 3, 0, 1, 2, 0, 2, 1, 2, 1, 0,\n",
      "        0, 1, 1, 3, 2, 1, 3, 3, 3, 1, 0, 3, 3, 0, 0, 2])\n",
      "\n",
      "Batch 219\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ..., 100,  99,  66],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ..., 100,  97,  66],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 2, 2, 0, 0, 0, 1, 1, 2, 3, 1, 2, 1, 3, 0, 2, 1, 1, 3, 0, 0, 1, 2,\n",
      "        3, 3, 3, 0, 3, 0, 3, 0, 2, 3, 3, 2, 2, 3, 2, 0])\n",
      "\n",
      "Batch 220\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,  98,  99,  66],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ..., 100,  97,  66],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 0, 0, 3, 1, 3, 3, 1, 0, 0, 0, 1, 3, 3, 1, 0, 2, 1, 3, 3, 0, 1, 0,\n",
      "        3, 3, 0, 1, 2, 1, 3, 1, 0, 0, 1, 1, 0, 3, 1, 0])\n",
      "\n",
      "Batch 221\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 0, 3, 3, 2, 0, 0, 1, 3, 1, 2, 0, 2, 1, 1, 3, 0, 2, 1, 0, 3, 1, 0,\n",
      "        3, 1, 2, 3, 0, 2, 1, 1, 2, 0, 3, 1, 2, 2, 2, 1])\n",
      "\n",
      "Batch 222\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  97,  66,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 0, 2, 2, 2, 2, 1, 0, 0, 1, 0, 3, 1, 0, 3, 0, 0, 0, 2, 1, 1, 2, 0,\n",
      "        2, 2, 0, 0, 2, 2, 2, 0, 1, 0, 2, 3, 2, 2, 2, 3])\n",
      "\n",
      "Batch 223\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 0, 2, 0, 0, 3, 2, 2, 2, 1, 0, 2, 1, 3, 3, 3, 1, 2, 3, 3, 3, 2, 2,\n",
      "        1, 1, 0, 1, 1, 3, 2, 3, 3, 3, 3, 1, 0, 0, 2, 1])\n",
      "\n",
      "Batch 224\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 2, 3, 1, 2, 2, 2, 3, 2, 2, 2, 2, 0, 3, 0, 2, 1, 3, 1, 3, 3, 3, 3,\n",
      "        3, 0, 2, 1, 1, 0, 3, 1, 1, 3, 3, 3, 2, 3, 3, 2])\n",
      "\n",
      "Batch 225\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ...,  98, 100,  66],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  98,  66,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 0, 2, 0, 2, 2, 1, 3, 2, 2, 0, 2, 2, 0, 1, 3, 2, 0, 2, 0, 1, 3, 2,\n",
      "        1, 2, 2, 1, 0, 0, 3, 3, 1, 3, 1, 3, 2, 1, 3, 3])\n",
      "\n",
      "Batch 226\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 2, 0, 1, 2, 0, 3, 2, 3, 2, 2, 1, 1, 0, 2, 2, 3, 2, 0, 3, 0, 0, 0,\n",
      "        2, 3, 2, 0, 0, 0, 3, 1, 1, 3, 2, 3, 0, 3, 1, 3])\n",
      "\n",
      "Batch 227\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,  99,  99,  66],\n",
      "        [ 69,  97,  98,  ...,  97,  66,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 0, 1, 3, 1, 1, 2, 2, 0, 3, 3, 2, 0, 1, 3, 3, 1, 3, 3, 3, 2, 3, 0,\n",
      "        0, 1, 3, 2, 3, 1, 1, 0, 0, 1, 2, 2, 3, 2, 0, 2])\n",
      "\n",
      "Batch 228\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,  98,  66,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 0, 3, 2, 0, 0, 1, 3, 1, 2, 1, 1, 1, 0, 3, 1, 1, 3, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 3, 2, 0, 2, 0, 1, 2, 0, 3, 3, 0, 0, 1])\n",
      "\n",
      "Batch 229\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  97,  ..., 100,  66,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 2, 3, 3, 2, 2, 1, 2, 0, 1, 0, 1, 1, 3, 1, 2, 3, 0, 2, 0, 2, 1, 1,\n",
      "        0, 3, 2, 2, 0, 3, 1, 2, 3, 0, 1, 0, 1, 2, 2, 1])\n",
      "\n",
      "Batch 230\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,  97, 100,  66],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 3, 1, 3, 1, 3, 0, 1, 1, 2, 0, 1, 0, 1, 0, 2, 1, 1, 0, 0, 0, 2, 3,\n",
      "        2, 3, 0, 0, 1, 0, 0, 1, 3, 2, 1, 0, 1, 0, 2, 3])\n",
      "\n",
      "Batch 231\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 3, 0, 1, 2, 2, 3, 0, 2, 0, 0, 3, 0, 1, 3, 0, 2, 0, 0, 0, 1, 0, 2,\n",
      "        0, 1, 2, 1, 3, 1, 3, 2, 0, 1, 2, 0, 2, 3, 0, 1])\n",
      "\n",
      "Batch 232\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ..., 100,  66,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 1, 2, 0, 2, 3, 1, 3, 0, 1, 0, 3, 2, 2, 2, 1, 2, 1, 3, 2, 0, 2, 1,\n",
      "        2, 0, 0, 1, 0, 2, 3, 1, 1, 2, 2, 1, 1, 3, 3, 2])\n",
      "\n",
      "Batch 233\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  97, 100,  66],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 0, 1, 0, 1, 3, 2, 3, 3, 0, 3, 3, 3, 1, 2, 3, 1, 1, 1, 0, 0, 0, 3,\n",
      "        3, 2, 2, 2, 3, 2, 0, 1, 2, 0, 3, 3, 3, 3, 2, 1])\n",
      "\n",
      "Batch 234\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 3, 2, 1, 3, 2, 1, 0, 2, 1, 0, 3, 0, 3, 2, 1, 3, 3, 1, 2, 2, 0, 0,\n",
      "        1, 2, 0, 3, 3, 0, 1, 1, 0, 2, 0, 2, 2, 1, 3, 2])\n",
      "\n",
      "Batch 235\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  97,  66,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 1, 1, 2, 1, 1, 0, 0, 1, 3, 1, 2,\n",
      "        2, 0, 0, 3, 0, 3, 0, 2, 0, 3, 0, 2, 3, 3, 1, 2])\n",
      "\n",
      "Batch 236\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 2, 3, 2, 1, 0, 3, 0, 1, 1, 3, 1, 3, 1, 2, 1, 0, 1, 0, 3, 1, 2, 0,\n",
      "        0, 3, 2, 1, 3, 1, 1, 2, 0, 0, 0, 2, 0, 3, 2, 2])\n",
      "\n",
      "Batch 237\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,  98, 100,  66],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  99,  98,  66]])\n",
      "Targets:\n",
      "tensor([3, 3, 3, 1, 3, 3, 2, 2, 0, 2, 0, 2, 3, 3, 3, 3, 2, 0, 1, 1, 1, 2, 0, 1,\n",
      "        2, 0, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 3, 3, 0, 1])\n",
      "\n",
      "Batch 238\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  97,  99,  66],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 2, 0, 0, 2, 0, 1, 0, 1, 3, 3, 0, 2, 3, 1, 1, 3, 3, 1, 2, 1, 3, 0,\n",
      "        3, 3, 1, 3, 0, 2, 3, 2, 2, 3, 2, 3, 2, 2, 2, 3])\n",
      "\n",
      "Batch 239\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ..., 100,  98,  66]])\n",
      "Targets:\n",
      "tensor([2, 1, 0, 1, 1, 1, 1, 3, 3, 0, 0, 2, 1, 2, 1, 1, 1, 3, 0, 1, 1, 3, 1, 0,\n",
      "        1, 0, 1, 3, 2, 0, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2])\n",
      "\n",
      "Batch 240\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 1, 3, 1, 1, 1, 3, 2, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 2, 2, 1, 3, 2,\n",
      "        1, 2, 1, 0, 1, 2, 2, 1, 3, 1, 0, 3, 2, 2, 1, 2])\n",
      "\n",
      "Batch 241\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,  98,  66,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 1, 0, 0, 3, 2, 0, 0, 2, 3, 0, 1, 3, 1, 3, 3, 0, 0, 3, 0, 0, 3,\n",
      "        0, 2, 2, 1, 2, 0, 1, 0, 0, 3, 0, 2, 2, 0, 1, 2])\n",
      "\n",
      "Batch 242\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  97,  66,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 3, 3, 0, 3, 3, 3, 1, 3, 3, 3, 2, 1, 0, 3, 2, 2, 2, 3, 0, 3, 1, 3,\n",
      "        3, 3, 1, 1, 1, 2, 3, 0, 2, 3, 0, 0, 3, 2, 1, 0])\n",
      "\n",
      "Batch 243\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 2, 0, 3, 1, 0, 2, 2, 0, 1, 3, 2, 3, 3, 2, 1, 2, 2, 0, 1, 3, 2, 0,\n",
      "        0, 3, 0, 1, 2, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2])\n",
      "\n",
      "Batch 244\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 0, 2, 3, 3, 0, 1, 0, 0, 3, 1, 1, 2, 2, 3, 3, 0, 0, 3, 1, 2, 2, 2,\n",
      "        0, 2, 3, 2, 3, 2, 0, 0, 0, 2, 2, 3, 2, 2, 3, 1])\n",
      "\n",
      "Batch 245\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,  98, 100,  66],\n",
      "        [ 69,  98,  99,  ..., 100,  99,  66],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 3, 1, 3, 1, 0, 0, 3, 2, 0, 2, 3, 3, 3, 1, 2, 2, 1, 0, 3, 1, 0, 3,\n",
      "        2, 2, 2, 1, 1, 1, 1, 0, 2, 1, 0, 1, 2, 3, 3, 1])\n",
      "\n",
      "Batch 246\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,  98,  98,  66],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 1, 3, 0, 1, 1, 2, 3, 3, 3, 3, 2, 1, 0, 3, 2, 3, 2, 2, 1, 1, 0, 2,\n",
      "        3, 1, 2, 3, 0, 2, 1, 0, 2, 0, 2, 0, 1, 3, 3, 1])\n",
      "\n",
      "Batch 247\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  98,  99,  66],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 0, 1, 0, 2, 0, 3, 3, 2, 1, 1, 1, 1, 2, 3, 3, 0, 1, 0, 2, 0, 2, 0,\n",
      "        1, 0, 3, 3, 0, 2, 2, 1, 0, 1, 0, 2, 3, 3, 1, 2])\n",
      "\n",
      "Batch 248\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 1, 1, 0, 2, 2, 2, 1, 3, 3, 1, 2, 3, 1, 1, 1, 3, 1, 3, 1, 3, 0,\n",
      "        3, 3, 2, 3, 0, 3, 1, 3, 2, 2, 0, 2, 0, 0, 2, 0])\n",
      "\n",
      "Batch 249\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ..., 100,  98,  66],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ..., 100,  99,  66],\n",
      "        [ 69,  98,  98,  ...,  99,  97,  66],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 3, 2, 2, 0, 2, 1, 2, 0, 0, 3, 1, 3, 2, 1, 2, 1, 0, 2, 3, 1, 1, 2,\n",
      "        3, 3, 2, 0, 1, 1, 2, 0, 2, 0, 3, 1, 2, 2, 0, 1])\n",
      "\n",
      "Batch 250\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,  98,  66,   0],\n",
      "        [ 69, 100,  99,  ..., 100,  66,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 3, 2, 0, 1, 1, 2, 1, 1, 2, 3, 0, 3, 1, 2, 0, 3, 0, 3, 3, 3, 2, 1,\n",
      "        3, 2, 0, 0, 0, 0, 1, 1, 3, 1, 0, 3, 3, 3, 0, 2])\n",
      "\n",
      "Batch 1\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 1, 0, 1, 0, 3, 1, 0, 2, 2, 3, 0, 3, 1, 0, 2, 0, 3, 0, 2, 0, 2, 2,\n",
      "        0, 2, 1, 2, 1, 1, 2, 2, 0, 2, 2, 3, 0, 1, 0, 2])\n",
      "\n",
      "Batch 2\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,  98, 100,  66],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 3, 1, 0, 3, 0, 3, 2, 1, 3, 2, 2, 1, 3, 3, 0, 3, 3, 3, 2, 3, 2, 3,\n",
      "        2, 3, 2, 2, 3, 3, 0, 1, 1, 3, 3, 0, 2, 1, 2, 3])\n",
      "\n",
      "Batch 3\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,  97,  66,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  99,  66,   0],\n",
      "        [ 69,  97,  99,  ...,  97,  99,  66]])\n",
      "Targets:\n",
      "tensor([2, 2, 1, 3, 0, 3, 1, 0, 2, 2, 2, 2, 1, 0, 2, 1, 2, 2, 1, 0, 2, 0, 2, 0,\n",
      "        3, 0, 0, 2, 3, 0, 2, 3, 1, 3, 3, 3, 2, 2, 1, 0])\n",
      "\n",
      "Batch 4\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 1, 3, 1, 3, 1, 3, 0, 3, 2, 0, 2, 0, 0, 3, 0, 0, 2, 1, 0, 2, 3, 3,\n",
      "        3, 2, 3, 0, 3, 2, 1, 2, 1, 2, 3, 1, 3, 2, 1, 3])\n",
      "\n",
      "Batch 5\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  99,  ...,  97,  66,   0],\n",
      "        [ 69,  99,  97,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ..., 100, 100,  66],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 1, 0, 2, 0, 0, 3, 2, 2, 0, 2, 3, 3, 2, 3, 3, 3, 0, 0, 0, 2, 3, 3,\n",
      "        1, 1, 3, 0, 0, 2, 1, 2, 2, 3, 3, 1, 3, 2, 1, 0])\n",
      "\n",
      "Batch 6\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  98,  66,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,  98,  98,  66],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 0, 2, 3, 0, 1, 1, 3, 2, 1, 3, 2, 0, 3, 1, 3, 2, 1, 0, 3, 0, 2, 3,\n",
      "        1, 0, 1, 1, 0, 2, 0, 0, 1, 3, 1, 2, 2, 0, 2, 1])\n",
      "\n",
      "Batch 7\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ..., 100,  98,  66],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 1, 0, 1, 0, 3, 3, 1, 1, 3, 3, 3, 1, 3, 2, 0, 1, 1, 2, 1, 3, 2, 1,\n",
      "        2, 3, 3, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 3, 2])\n",
      "\n",
      "Batch 8\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  99,  66,   0]])\n",
      "Targets:\n",
      "tensor([1, 2, 3, 2, 2, 3, 2, 3, 0, 0, 1, 0, 3, 2, 0, 0, 3, 1, 1, 2, 3, 0, 1, 1,\n",
      "        0, 0, 2, 0, 1, 2, 0, 3, 3, 0, 1, 3, 0, 2, 0, 0])\n",
      "\n",
      "Batch 9\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  99,  99,  66],\n",
      "        [ 69,  98,  98,  ...,  97,  99,  66]])\n",
      "Targets:\n",
      "tensor([1, 0, 2, 2, 3, 3, 2, 2, 2, 3, 2, 2, 3, 1, 0, 2, 2, 3, 0, 0, 3, 0, 3, 2,\n",
      "        3, 1, 2, 1, 3, 0, 3, 0, 2, 2, 3, 0, 3, 2, 1, 1])\n",
      "\n",
      "Batch 10\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,  97,  97,  66],\n",
      "        [ 69, 100, 100,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 1, 2, 1, 3, 3, 3, 3, 0, 0, 2, 2, 2, 2, 2, 0, 0, 3, 0, 1, 1, 2, 2, 1,\n",
      "        3, 2, 3, 0, 0, 0, 1, 0, 3, 0, 3, 2, 1, 3, 0, 3])\n",
      "\n",
      "Batch 11\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 0, 2, 0, 3, 3, 1, 0, 1, 2, 0, 0, 2, 0, 3, 2, 1, 0, 2, 3, 3, 0, 0,\n",
      "        2, 3, 2, 2, 0, 3, 2, 2, 1, 0, 2, 2, 1, 0, 1, 2])\n",
      "\n",
      "Batch 12\n",
      "Sequences:\n",
      "tensor([[69, 98, 99,  ...,  0,  0,  0],\n",
      "        [69, 97, 99,  ...,  0,  0,  0],\n",
      "        [69, 99, 98,  ..., 99, 66,  0],\n",
      "        ...,\n",
      "        [69, 97, 97,  ...,  0,  0,  0],\n",
      "        [69, 98, 97,  ..., 66,  0,  0],\n",
      "        [69, 97, 98,  ..., 66,  0,  0]])\n",
      "Targets:\n",
      "tensor([3, 0, 1, 2, 1, 3, 0, 3, 1, 0, 2, 0, 1, 0, 2, 3, 3, 1, 2, 1, 2, 1, 3, 3,\n",
      "        3, 2, 2, 3, 1, 2, 2, 2, 3, 1, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Batch 13\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  98,  99,  66],\n",
      "        [ 69, 100,  97,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 1, 3, 2, 1, 3, 3, 1, 2, 1, 2, 3, 3, 2, 0, 1, 1, 2, 0, 3, 1, 1, 1,\n",
      "        1, 2, 2, 3, 2, 0, 0, 2, 2, 3, 0, 2, 2, 2, 2, 1])\n",
      "\n",
      "Batch 14\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ..., 100,  66,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 3, 0, 3, 3, 1, 3, 3, 1, 1, 0, 1, 2, 1, 2, 3, 3, 2, 3, 3, 2, 2, 3,\n",
      "        2, 0, 0, 0, 3, 3, 0, 3, 3, 0, 2, 3, 1, 3, 1, 0])\n",
      "\n",
      "Batch 15\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  98,  98,  66],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  98,  66,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 3, 2, 3, 0, 0, 0, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 0, 3, 0, 1, 1, 3,\n",
      "        3, 3, 2, 3, 2, 1, 3, 2, 3, 0, 0, 1, 0, 0, 3, 3])\n",
      "\n",
      "Batch 16\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 2, 1, 3, 1, 3, 0, 0, 0, 0, 1, 3, 3, 0, 3, 0, 2, 3, 2, 0, 1, 0, 3,\n",
      "        2, 2, 0, 1, 2, 3, 1, 1, 2, 2, 0, 2, 2, 0, 2, 3])\n",
      "\n",
      "Batch 17\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ..., 100,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,  99,  66,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 3, 2, 1, 3, 1, 3, 3, 2, 0, 0, 0, 1, 1, 1, 3, 2, 1, 0, 3, 0, 3, 3, 0,\n",
      "        0, 2, 0, 3, 0, 1, 3, 2, 0, 3, 2, 3, 2, 1, 2, 0])\n",
      "\n",
      "Batch 18\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 3, 3, 3, 0, 3, 3, 3, 1, 3, 3, 2, 2, 2, 2, 2, 3, 0, 0, 1, 1, 3, 3, 3,\n",
      "        1, 2, 1, 1, 1, 1, 0, 2, 0, 0, 0, 1, 3, 1, 3, 0])\n",
      "\n",
      "Batch 19\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ..., 100,  97,  66],\n",
      "        [ 69, 100, 100,  ...,  99,  99,  66],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 3, 1, 0, 3, 2, 0, 1, 0, 0, 0, 3, 2, 1, 2,\n",
      "        0, 0, 1, 2, 2, 1, 1, 0, 1, 2, 1, 3, 0, 1, 0, 2])\n",
      "\n",
      "Batch 20\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,  98,  66,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 2, 2, 2, 0, 3, 3, 1, 3, 2, 2, 0, 0, 0, 2, 2, 3, 3, 0, 3, 2, 0, 3,\n",
      "        2, 0, 2, 1, 2, 3, 3, 2, 0, 3, 1, 2, 0, 1, 3, 3])\n",
      "\n",
      "Batch 21\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 2, 3, 1, 0, 2, 2, 2, 0, 3, 1, 3, 2, 0, 1, 2, 0, 1, 2, 1, 3, 0, 3,\n",
      "        2, 3, 0, 2, 3, 2, 1, 1, 1, 2, 2, 3, 2, 3, 3, 3])\n",
      "\n",
      "Batch 22\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ..., 100, 100,  66],\n",
      "        [ 69,  98,  99,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  99,  97,  66],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 2, 3, 2, 3, 3, 0, 1, 3, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 3, 3, 3, 1, 3,\n",
      "        1, 1, 0, 3, 0, 1, 2, 1, 0, 0, 0, 0, 1, 3, 1, 3])\n",
      "\n",
      "Batch 23\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 2, 3, 2, 1, 2, 2, 2, 1, 2, 1, 2, 0, 0, 3, 1, 3, 3, 0, 1, 1, 3, 1,\n",
      "        0, 0, 3, 2, 3, 3, 2, 1, 2, 0, 2, 0, 3, 1, 3, 1])\n",
      "\n",
      "Batch 24\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ..., 100,  98,  66],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 1, 1, 2, 0, 3, 1, 0, 0, 0, 1, 3, 0, 2, 3, 0, 3, 1, 1, 1, 2, 3, 3,\n",
      "        1, 1, 0, 3, 2, 2, 3, 0, 1, 1, 3, 3, 1, 2, 0, 0])\n",
      "\n",
      "Batch 25\n",
      "Sequences:\n",
      "tensor([[69, 98, 97,  ...,  0,  0,  0],\n",
      "        [69, 99, 98,  ...,  0,  0,  0],\n",
      "        [69, 98, 98,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [69, 97, 98,  ..., 66,  0,  0],\n",
      "        [69, 99, 97,  ...,  0,  0,  0],\n",
      "        [69, 97, 97,  ...,  0,  0,  0]])\n",
      "Targets:\n",
      "tensor([0, 1, 0, 3, 3, 2, 0, 3, 3, 0, 2, 0, 3, 1, 3, 0, 0, 3, 2, 1, 3, 2, 3, 3,\n",
      "        3, 3, 0, 2, 2, 2, 1, 1, 3, 3, 1, 0, 3, 1, 0, 0])\n",
      "\n",
      "Batch 26\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 1, 3, 2, 1, 0, 2, 0, 0, 2, 1, 0, 0, 2, 3, 0, 3, 3, 0, 1, 2, 2, 2,\n",
      "        3, 2, 2, 0, 0, 3, 0, 0, 2, 0, 2, 2, 3, 3, 3, 3])\n",
      "\n",
      "Batch 27\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  97,  ...,  66,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 3, 0, 0, 0, 0, 2, 1, 1, 2, 1, 3, 3, 3, 1, 2, 3, 0, 0, 0, 2, 1, 1, 0,\n",
      "        0, 3, 3, 0, 1, 2, 3, 1, 2, 0, 1, 3, 3, 2, 0, 1])\n",
      "\n",
      "Batch 28\n",
      "Sequences:\n",
      "tensor([[ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  97,  66,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 2, 2, 2, 1, 2, 0, 2, 0, 1, 1, 0, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 0,\n",
      "        1, 1, 0, 3, 0, 3, 3, 0, 0, 0, 2, 3, 2, 1, 0, 2])\n",
      "\n",
      "Batch 29\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 0, 3, 2, 3, 1, 2, 3, 0, 3, 1, 0, 3, 2, 1, 1, 2, 1, 0, 0, 1, 2, 1, 2,\n",
      "        1, 2, 1, 3, 3, 2, 1, 0, 2, 0, 1, 1, 2, 3, 0, 3])\n",
      "\n",
      "Batch 30\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,  98,  99,  66],\n",
      "        [ 69, 100,  97,  ..., 100,  99,  66],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  99,  ...,  98,  66,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 3, 1, 0, 0, 3, 1, 3, 3, 3, 1, 1, 1, 0, 0, 3, 0, 0, 2, 3, 2, 2, 1,\n",
      "        3, 3, 2, 2, 3, 2, 3, 1, 2, 3, 0, 2, 2, 2, 0, 0])\n",
      "\n",
      "Batch 31\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ..., 100,  66,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 1, 3, 2, 2, 0, 0, 1, 3, 2, 1, 1, 2, 0, 0, 0, 1, 3, 2, 1, 1, 1, 3,\n",
      "        1, 2, 3, 1, 3, 0, 2, 1, 3, 3, 0, 3, 0, 0, 2, 2])\n",
      "\n",
      "Batch 32\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,  99,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 3, 3, 0, 0, 0, 3, 2, 1, 2, 0, 2, 3, 1, 3, 3, 0, 2, 1, 2, 1, 1, 3,\n",
      "        3, 2, 2, 1, 0, 3, 0, 0, 2, 1, 1, 2, 0, 1, 0, 0])\n",
      "\n",
      "Batch 33\n",
      "Sequences:\n",
      "tensor([[ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ..., 100,  66,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,  97,  97,  66],\n",
      "        [ 69,  98, 100,  ...,  97,  66,   0],\n",
      "        [ 69,  99,  99,  ..., 100,  99,  66]])\n",
      "Targets:\n",
      "tensor([2, 2, 2, 3, 1, 2, 1, 3, 1, 3, 2, 3, 0, 0, 3, 0, 2, 0, 3, 1, 3, 3, 1, 0,\n",
      "        2, 1, 2, 2, 1, 2, 3, 0, 3, 1, 3, 1, 3, 3, 2, 0])\n",
      "\n",
      "Batch 34\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  66,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 2, 2, 0, 2, 2, 0, 3, 2, 0, 0, 1, 1, 3, 3, 3, 2, 1, 1, 2, 3, 0, 1,\n",
      "        0, 3, 1, 0, 1, 0, 2, 1, 2, 3, 2, 3, 2, 3, 3, 1])\n",
      "\n",
      "Batch 35\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ..., 100,  66,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 3, 3, 2, 1, 1, 1, 0, 0, 0, 1, 2, 2, 3, 2, 1, 2, 0, 1, 0, 3, 2, 1,\n",
      "        1, 3, 3, 0, 0, 2, 2, 1, 3, 0, 0, 3, 1, 3, 2, 2])\n",
      "\n",
      "Batch 36\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,  98,  66,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  97,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  98,  99,  66]])\n",
      "Targets:\n",
      "tensor([2, 3, 0, 3, 3, 3, 2, 2, 2, 1, 1, 0, 1, 1, 0, 3, 0, 3, 3, 1, 1, 3, 3, 3,\n",
      "        2, 0, 3, 3, 0, 0, 3, 1, 1, 3, 1, 0, 3, 2, 1, 0])\n",
      "\n",
      "Batch 37\n",
      "Sequences:\n",
      "tensor([[ 69,  97,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ..., 100,  97,  66],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 0, 3, 1, 1, 1, 3, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2, 0, 1, 3, 2, 1, 0, 2,\n",
      "        3, 2, 2, 2, 1, 2, 2, 1, 0, 2, 0, 2, 0, 2, 0, 0])\n",
      "\n",
      "Batch 38\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ..., 100, 100,  66],\n",
      "        ...,\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  97,  ...,  99, 100,  66],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 0, 3, 3, 0, 0, 2, 1, 1, 0, 0, 2, 2, 0, 2, 1, 3, 3, 1, 0, 3, 3, 0,\n",
      "        3, 2, 3, 0, 0, 1, 3, 1, 0, 0, 1, 0, 3, 0, 2, 1])\n",
      "\n",
      "Batch 39\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  98,  66,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([1, 1, 3, 2, 1, 2, 1, 0, 3, 1, 0, 2, 2, 3, 2, 3, 2, 3, 1, 2, 0, 0, 1, 0,\n",
      "        1, 2, 2, 1, 3, 3, 3, 2, 2, 3, 3, 3, 0, 2, 0, 2])\n",
      "\n",
      "Batch 40\n",
      "Sequences:\n",
      "tensor([[69, 99, 98,  ...,  0,  0,  0],\n",
      "        [69, 97, 97,  ...,  0,  0,  0],\n",
      "        [69, 97, 97,  ..., 66,  0,  0],\n",
      "        ...,\n",
      "        [69, 98, 99,  ..., 99, 66,  0],\n",
      "        [69, 97, 97,  ..., 99, 98, 66],\n",
      "        [69, 99, 97,  ...,  0,  0,  0]])\n",
      "Targets:\n",
      "tensor([2, 1, 3, 3, 0, 1, 3, 0, 1, 3, 2, 0, 0, 0, 3, 0, 0, 3, 1, 3, 0, 3, 3, 2,\n",
      "        2, 1, 3, 2, 0, 2, 3, 3, 1, 1, 1, 3, 3, 1, 1, 0])\n",
      "\n",
      "Batch 41\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,  99,  66,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,  97,  66,   0],\n",
      "        [ 69,  97,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 1, 1, 0, 1, 1, 2, 0, 2, 0, 0, 0, 2, 3, 1, 0, 2, 3, 0, 0, 2, 0, 2, 3,\n",
      "        1, 0, 3, 2, 3, 1, 1, 2, 1, 0, 0, 0, 2, 1, 2, 0])\n",
      "\n",
      "Batch 42\n",
      "Sequences:\n",
      "tensor([[ 69,  99, 100,  ...,  99,  97,  66],\n",
      "        [ 69,  97, 100,  ...,  97,  99,  66],\n",
      "        [ 69,  99,  98,  ...,  98,  99,  66],\n",
      "        ...,\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 2, 0, 2, 1, 1, 1, 3, 2, 3, 1, 0, 1, 3, 2, 2, 2, 2, 1, 3, 0, 1, 0, 3,\n",
      "        1, 1, 0, 0, 3, 1, 0, 3, 2, 3, 0, 0, 0, 2, 1, 3])\n",
      "\n",
      "Batch 43\n",
      "Sequences:\n",
      "tensor([[ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,  99,  99,  66],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ..., 100,  66,   0]])\n",
      "Targets:\n",
      "tensor([0, 2, 2, 0, 2, 0, 0, 1, 1, 3, 2, 2, 3, 2, 2, 2, 1, 2, 2, 3, 0, 1, 1, 3,\n",
      "        2, 1, 2, 1, 3, 1, 0, 3, 1, 0, 1, 0, 0, 2, 3, 3])\n",
      "\n",
      "Batch 44\n",
      "Sequences:\n",
      "tensor([[ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  97,  ...,  99,  99,  66]])\n",
      "Targets:\n",
      "tensor([1, 3, 0, 1, 1, 2, 3, 2, 1, 0, 1, 0, 2, 3, 2, 2, 0, 3, 1, 2, 1, 1, 1, 3,\n",
      "        3, 1, 0, 3, 1, 1, 0, 2, 2, 2, 2, 0, 1, 3, 1, 0])\n",
      "\n",
      "Batch 45\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  98,  ...,  99,  98,  66],\n",
      "        [ 69,  98,  99,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100, 100,  ...,  98,  66,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 1, 1, 3, 0, 1, 2, 3, 3, 3, 3, 1, 2, 3, 3, 0, 2, 2, 0, 2, 0, 3, 1,\n",
      "        3, 1, 0, 2, 2, 0, 3, 0, 2, 2, 3, 2, 3, 2, 1, 0])\n",
      "\n",
      "Batch 46\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,  98,  97,  66],\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([2, 0, 3, 2, 0, 2, 0, 3, 1, 2, 1, 1, 3, 0, 3, 2, 3, 3, 0, 0, 0, 2, 0, 3,\n",
      "        3, 2, 1, 2, 3, 1, 0, 0, 0, 0, 1, 3, 1, 3, 3, 2])\n",
      "\n",
      "Batch 47\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  99,  ...,  66,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  99,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  97,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([3, 3, 2, 2, 1, 1, 3, 2, 0, 3, 2, 0, 1, 3, 1, 1, 1, 2, 3, 0, 3, 2, 3, 1,\n",
      "        3, 1, 0, 1, 2, 1, 1, 0, 1, 0, 1, 0, 2, 1, 1, 0])\n",
      "\n",
      "Batch 48\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,  66,   0,   0],\n",
      "        [ 69,  99,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  97,  99,  ...,  97,  66,   0]])\n",
      "Targets:\n",
      "tensor([0, 1, 2, 2, 2, 0, 0, 2, 3, 0, 0, 2, 0, 2, 2, 1, 3, 1, 2, 1, 2, 1, 1, 1,\n",
      "        1, 2, 0, 0, 3, 2, 0, 1, 0, 3, 3, 1, 1, 0, 0, 3])\n",
      "\n",
      "Batch 49\n",
      "Sequences:\n",
      "tensor([[ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99, 100,  ...,   0,   0,   0],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  99,  99,  ...,   0,   0,   0],\n",
      "        [ 69,  97, 100,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 0, 0, 3, 1, 2, 0, 0, 2, 3, 2, 0, 0, 1, 1, 2, 0, 1, 1, 3, 0, 2, 3,\n",
      "        1, 0, 2, 3, 3, 0, 2, 0, 2, 3, 0, 0, 1, 3, 1, 0])\n",
      "\n",
      "Batch 50\n",
      "Sequences:\n",
      "tensor([[ 69,  97, 100,  ...,  99,  97,  66],\n",
      "        [ 69,  98, 100,  ...,   0,   0,   0],\n",
      "        [ 69, 100,  98,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 69, 100,  97,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0],\n",
      "        [ 69,  98,  98,  ...,   0,   0,   0]])\n",
      "Targets:\n",
      "tensor([0, 0, 0, 2, 2, 0, 3, 3, 3, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 0, 3, 3,\n",
      "        2, 3, 3, 0, 0, 2, 2, 1, 0, 0, 3, 3, 0, 2, 0, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, num_sequences, min_length, max_length, train=True):\n",
    "        self.sequences = []\n",
    "        self.targets = []\n",
    "\n",
    "        for _ in range(num_sequences):\n",
    "            seq, target = self.generate_sequence(min_length, max_length)\n",
    "            self.sequences.append(seq)\n",
    "            self.targets.append(target)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        target = self.targets[idx]\n",
    "        return seq, target\n",
    "\n",
    "    def generate_sequence(self, min_length, max_length):\n",
    "        seq_length = random.randint(min_length, max_length)\n",
    "        t1 = random.randint(10, 20)\n",
    "        t2 = random.randint(50, 60)\n",
    "\n",
    "        seq = ['E']\n",
    "        for i in range(1, seq_length-1):\n",
    "            if i == t1 or i == t2:\n",
    "                seq.append(random.choice(['X', 'Y']))\n",
    "            else:\n",
    "                seq.append(random.choice(['a', 'b', 'c', 'd']))\n",
    "        seq.append('B')\n",
    "\n",
    "        if seq[t1] == 'X' and seq[t2] == 'X':\n",
    "            target = 0  # Q\n",
    "        elif seq[t1] == 'X' and seq[t2] == 'Y':\n",
    "            target = 1  # R\n",
    "        elif seq[t1] == 'Y' and seq[t2] == 'X':\n",
    "            target = 2  # S\n",
    "        else:\n",
    "            target = 3  # U\n",
    "\n",
    "        return seq, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, targets = zip(*batch)\n",
    "    sequences = [torch.tensor([ord(c) for c in seq], dtype=torch.long) for seq in sequences]\n",
    "    sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    targets = torch.tensor(targets, dtype=torch.long)\n",
    "    return sequences, targets\n",
    "\n",
    "# Generate training and testing datasets\n",
    "train_dataset = SequenceDataset(num_sequences=10000, min_length=100, max_length=110)\n",
    "test_dataset = SequenceDataset(num_sequences=2000, min_length=100, max_length=110)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=40, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=40, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Iterate over the data loaders\n",
    "for batch_idx, (sequences, targets) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx+1}\")\n",
    "    print(\"Sequences:\")\n",
    "    print(sequences)\n",
    "    print(\"Targets:\")\n",
    "    print(targets)\n",
    "    print()\n",
    "\n",
    "for batch_idx, (sequences, targets) in enumerate(test_loader):\n",
    "    print(f\"Batch {batch_idx+1}\")\n",
    "    print(\"Sequences:\")\n",
    "    print(sequences)\n",
    "    print(\"Targets:\")\n",
    "    print(targets)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "0\n",
      "1\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "torch.Size([40, 110])\n",
      "torch.Size([40])\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# get index of currently selected device\n",
    "print(torch.cuda.current_device())  # returns 0 in my case\n",
    "\n",
    "# get number of GPUs available\n",
    "print(torch.cuda.device_count())  # returns 1 in my case\n",
    "\n",
    "# get the name of the device\n",
    "print(torch.cuda.get_device_name(0))  # good old Tesla K80\n",
    "\n",
    "def stride(input_data, stride):\n",
    "    'turn [batch_size, sequence_length, input_size] into [batch_size, sequence_length*input_size/stride, input_size]'\n",
    "    batch_size, sequence_length, input_size = input_data.shape\n",
    "    # flatten the input data to put sequence and input size together\n",
    "    input_data = input_data.reshape(batch_size, -1)\n",
    "    # append zeros to make sure the last pixel can be fed as the first pixel of the next sequence\n",
    "    n = input_size - (sequence_length * input_size) % stride\n",
    "\n",
    "    input_data = input_data.cpu()\n",
    "    input_data = input_data.numpy()\n",
    "    input_data = np.append(input_data, np.zeros((batch_size, n)), axis=1)\n",
    "    input_data = torch.tensor(input_data)\n",
    "    # print(input_data.shape)\n",
    "    output_data = torch.zeros(batch_size, sequence_length * input_size // stride, input_size)\n",
    "    for i in range(sequence_length * input_size // stride):\n",
    "        # if stride = input size, then the output data is the same as input data\n",
    "        # print(i)\n",
    "\n",
    "        output_data[:, i, :] = input_data[:, i * stride:i * stride + input_size]\n",
    "        # print(output_data[batch,i,:])\n",
    "\n",
    "    return output_data\n",
    "\n",
    "# Generate training and testing datasets\n",
    "train_dataset = SequenceDataset(num_sequences=1000, min_length=100, max_length=110)\n",
    "test_dataset = SequenceDataset(num_sequences=200, min_length=100, max_length=110)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=40, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=40, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "for i, (sequences, labels) in enumerate(loaders['train']):\n",
    "    sequences = sequences.to(device)\n",
    "    labels = labels.to(device)\n",
    "    print(sequences.shape)\n",
    "    print(labels.shape)\n",
    "    print(len(loaders['train']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "sequence_length =110//input_size\n",
    "hidden_size = 48\n",
    "num_layers = 1\n",
    "num_classes = 4\n",
    "batch_size = 40\n",
    "num_epochs = 10\n",
    "learning_rate = 0.5\n",
    "stride_number = 1\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class simple_GRU_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(simple_GRU_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # Wz is defined in the forward function\n",
    "        self.W_z = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))         \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.uniform_(param, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = self.Sigmoid(torch.matmul(self.W_z, self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class simple_GRU_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(simple_GRU_batch, self).__init__()\n",
    "        self.rnncell = simple_GRU_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class simple_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(simple_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = simple_GRU_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden state\n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Pass the input through the LSTM\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        \n",
    "        # Apply output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:, 0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        # Pass the output through the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = simple_GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 1.7692, Train Acc: 0.2620, Test Loss: 1.7873, Test Acc: 0.2550\n",
      "Epoch [2/10], Train Loss: 1.5314, Train Acc: 0.2680, Test Loss: 1.7025, Test Acc: 0.2450\n",
      "Epoch [3/10], Train Loss: 1.5129, Train Acc: 0.2630, Test Loss: 1.4633, Test Acc: 0.2450\n",
      "Epoch [4/10], Train Loss: 1.4856, Train Acc: 0.2530, Test Loss: 1.4204, Test Acc: 0.2500\n",
      "modified torch.Size([4400])\n",
      "Epoch [5/10], Train Loss: 1.5091, Train Acc: 0.2600, Test Loss: 1.4019, Test Acc: 0.2450\n",
      "Epoch [6/10], Train Loss: 1.5248, Train Acc: 0.2560, Test Loss: 1.5414, Test Acc: 0.2500\n",
      "modified torch.Size([4400])\n",
      "Epoch [7/10], Train Loss: 1.5476, Train Acc: 0.2340, Test Loss: 1.4268, Test Acc: 0.2400\n",
      "modified torch.Size([4400])\n",
      "Epoch [8/10], Train Loss: 1.9111, Train Acc: 0.2380, Test Loss: 1.8025, Test Acc: 0.2550\n",
      "Epoch [9/10], Train Loss: 1.5774, Train Acc: 0.2610, Test Loss: 1.5601, Test Acc: 0.2500\n",
      "Epoch [10/10], Train Loss: 1.5038, Train Acc: 0.2450, Test Loss: 1.5103, Test Acc: 0.2450\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Training loop\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (sequences, targets) in enumerate(train_loader):\n",
    "        sequences, targets = sequences.to(device), targets.to(device)\n",
    "        if sequences.shape[1] != 110:\n",
    "            n = 110-sequences.shape[1]\n",
    "            sequences = sequences.flatten()\n",
    "            sequences = torch.cat((sequences, (torch.zeros(batch_size, n)).flatten().to(device)))\n",
    "            print('modified', sequences.shape)\n",
    "            sequences = sequences.reshape(batch_size, 110).to(device)\n",
    "        sequences = sequences.reshape(-1, sequence_length, input_size)\n",
    "        sequences = stride(sequences, stride_number).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Testing loop\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (sequences, targets) in enumerate(test_loader):\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            if sequences.shape[1] != 110:\n",
    "                n = 110-sequences.shape[1]\n",
    "                sequences = sequences.flatten()\n",
    "                sequences = torch.cat((sequences, (torch.zeros(batch_size, n)).flatten().to(device)))\n",
    "                print('modified', sequences.shape)\n",
    "                sequences = sequences.reshape(batch_size, 110).to(device)\n",
    "            sequences = sequences.reshape(-1, sequence_length, input_size)\n",
    "            sequences = stride(sequences, stride_number).to(device)\n",
    "            outputs = model(sequences)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Timescale RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonlinearity: Sigmoid\n",
    "\n",
    "$z_t = \\sigma (W_z r_t + P_zx_t + b_z)$ with $W_z = P_z = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class multiscale_RNN_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(multiscale_RNN_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # Wz is defined in the forward function\n",
    "        self.W_z = torch.nn.Parameter(torch.zeros(self.hidden_size, self.hidden_size), requires_grad=False)\n",
    "        self.P_z = torch.nn.Parameter(torch.zeros(self.hidden_size, input_size), requires_grad=False)\n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))         \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "        self.z_low = torch.tensor(0.1)\n",
    "        self.z_high = torch.tensor(0.9)\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)*self.Sigmoid(torch.matmul(self.W_z, self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class multiscale_RNN_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(multiscale_RNN_batch, self).__init__()\n",
    "        self.rnncell = multiscale_RNN_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class multiscale_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(multiscale_RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = multiscale_RNN_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = multiscale_RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified torch.Size([4400])\n",
      "Epoch [1/10], Train Loss: 2.0440, Train Acc: 0.2380, Test Loss: 1.8944, Test Acc: 0.2550\n",
      "modified torch.Size([4400])\n",
      "Epoch [2/10], Train Loss: 1.6828, Train Acc: 0.2540, Test Loss: 1.4077, Test Acc: 0.2550\n",
      "Epoch [3/10], Train Loss: 1.4538, Train Acc: 0.2720, Test Loss: 1.5501, Test Acc: 0.2500\n",
      "Epoch [4/10], Train Loss: 1.6372, Train Acc: 0.2460, Test Loss: 1.5543, Test Acc: 0.2500\n",
      "Epoch [5/10], Train Loss: 1.6491, Train Acc: 0.2490, Test Loss: 1.4746, Test Acc: 0.2450\n",
      "Epoch [6/10], Train Loss: 1.6384, Train Acc: 0.2450, Test Loss: 1.4840, Test Acc: 0.2500\n",
      "Epoch [7/10], Train Loss: 1.6253, Train Acc: 0.2600, Test Loss: 1.6649, Test Acc: 0.2450\n",
      "modified torch.Size([4400])\n",
      "Epoch [8/10], Train Loss: 1.5988, Train Acc: 0.2640, Test Loss: 1.4518, Test Acc: 0.2500\n",
      "modified torch.Size([4400])\n",
      "Epoch [9/10], Train Loss: 1.7128, Train Acc: 0.2460, Test Loss: 1.4182, Test Acc: 0.2500\n",
      "modified torch.Size([4400])\n",
      "Epoch [10/10], Train Loss: 1.5148, Train Acc: 0.2510, Test Loss: 1.4296, Test Acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Training loop\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (sequences, targets) in enumerate(train_loader):\n",
    "        sequences, targets = sequences.to(device), targets.to(device)\n",
    "        if sequences.shape[1] != 110:\n",
    "            n = 110-sequences.shape[1]\n",
    "            sequences = sequences.flatten()\n",
    "            sequences = torch.cat((sequences, (torch.zeros(batch_size, n)).flatten().to(device)))\n",
    "            print('modified', sequences.shape)\n",
    "            sequences = sequences.reshape(batch_size, 110).to(device)\n",
    "        sequences = sequences.reshape(-1, sequence_length, input_size)\n",
    "        sequences = stride(sequences, stride_number).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Testing loop\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (sequences, targets) in enumerate(test_loader):\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            if sequences.shape[1] != 110:\n",
    "                n = 110-sequences.shape[1]\n",
    "                sequences = sequences.flatten()\n",
    "                sequences = torch.cat((sequences, (torch.zeros(batch_size, n)).flatten().to(device)))\n",
    "                print('modified', sequences.shape)\n",
    "                sequences = sequences.reshape(batch_size, 110).to(device)\n",
    "            sequences = sequences.reshape(-1, sequence_length, input_size)\n",
    "            sequences = stride(sequences, stride_number).to(device)\n",
    "            outputs = model(sequences)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 10\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 4\n",
    "\n",
    "# Create an instance of the model\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified torch.Size([4400])\n",
      "Epoch [1/10], Train Loss: 2.1950, Train Acc: 0.2620, Test Loss: 2.0068, Test Acc: 0.2500\n",
      "modified torch.Size([4400])\n",
      "Epoch [2/10], Train Loss: 1.6831, Train Acc: 0.2740, Test Loss: 1.5086, Test Acc: 0.2500\n",
      "Epoch [3/10], Train Loss: 1.5191, Train Acc: 0.2370, Test Loss: 1.4190, Test Acc: 0.2500\n",
      "modified torch.Size([4400])\n",
      "Epoch [4/10], Train Loss: 1.4732, Train Acc: 0.2320, Test Loss: 1.4211, Test Acc: 0.2500\n",
      "Epoch [5/10], Train Loss: 1.4319, Train Acc: 0.2470, Test Loss: 1.4119, Test Acc: 0.2450\n",
      "Epoch [6/10], Train Loss: 1.3931, Train Acc: 0.2500, Test Loss: 1.3869, Test Acc: 0.2500\n",
      "modified torch.Size([4400])\n",
      "Epoch [7/10], Train Loss: 1.3985, Train Acc: 0.2430, Test Loss: 1.3999, Test Acc: 0.2450\n",
      "Epoch [8/10], Train Loss: 1.4046, Train Acc: 0.2410, Test Loss: 1.3929, Test Acc: 0.2500\n",
      "Epoch [9/10], Train Loss: 1.4139, Train Acc: 0.2550, Test Loss: 1.4551, Test Acc: 0.2500\n",
      "modified torch.Size([4400])\n",
      "modified torch.Size([4400])\n",
      "modified torch.Size([4400])\n",
      "Epoch [10/10], Train Loss: 1.4079, Train Acc: 0.2590, Test Loss: 1.3938, Test Acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Training loop\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (sequences, targets) in enumerate(train_loader):\n",
    "        sequences, targets = sequences.to(device), targets.to(device)\n",
    "        if sequences.shape[1] != 110:\n",
    "            n = 110-sequences.shape[1]\n",
    "            sequences = sequences.flatten()\n",
    "            sequences = torch.cat((sequences, (torch.zeros(batch_size, n)).flatten().to(device)))\n",
    "            print('modified', sequences.shape)\n",
    "            sequences = sequences.reshape(batch_size, 110).to(device)\n",
    "        sequences = sequences.reshape(-1, sequence_length, input_size)\n",
    "        sequences = stride(sequences, stride_number).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Testing loop\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (sequences, targets) in enumerate(test_loader):\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            if sequences.shape[1] != 110:\n",
    "                n = 110-sequences.shape[1]\n",
    "                sequences = sequences.flatten()\n",
    "                sequences = torch.cat((sequences, (torch.zeros(batch_size, n)).flatten().to(device)))\n",
    "                print('modified', sequences.shape)\n",
    "                sequences = sequences.reshape(batch_size, 110).to(device)\n",
    "            sequences = sequences.reshape(-1, sequence_length, input_size)\n",
    "            sequences = stride(sequences, stride_number).to(device)\n",
    "            outputs = model(sequences)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_1_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_1_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(1.0)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_1_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_1_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_1_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_1(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_1, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_1_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_1(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a lstm model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified torch.Size([4400])\n",
      "Epoch [1/10], Train Loss: 1.4336, Train Acc: 0.2300, Test Loss: 1.3892, Test Acc: 0.2450\n",
      "Epoch [2/10], Train Loss: 1.4183, Train Acc: 0.2140, Test Loss: 1.4004, Test Acc: 0.2500\n",
      "Epoch [3/10], Train Loss: 1.4094, Train Acc: 0.2570, Test Loss: 1.4231, Test Acc: 0.2550\n",
      "Epoch [4/10], Train Loss: 1.4110, Train Acc: 0.2610, Test Loss: 1.4464, Test Acc: 0.2500\n",
      "Epoch [5/10], Train Loss: 1.4089, Train Acc: 0.2610, Test Loss: 1.4010, Test Acc: 0.2450\n",
      "Epoch [6/10], Train Loss: 1.4085, Train Acc: 0.2500, Test Loss: 1.3902, Test Acc: 0.2550\n",
      "Epoch [7/10], Train Loss: 1.4153, Train Acc: 0.2430, Test Loss: 1.4219, Test Acc: 0.2550\n",
      "Epoch [8/10], Train Loss: 1.4037, Train Acc: 0.2360, Test Loss: 1.4079, Test Acc: 0.2550\n",
      "Epoch [9/10], Train Loss: 1.4149, Train Acc: 0.2390, Test Loss: 1.4076, Test Acc: 0.2500\n",
      "Epoch [10/10], Train Loss: 1.4150, Train Acc: 0.2560, Test Loss: 1.4085, Test Acc: 0.2550\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Training loop\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (sequences, targets) in enumerate(train_loader):\n",
    "        sequences, targets = sequences.to(device), targets.to(device)\n",
    "        if sequences.shape[1] != 110:\n",
    "            n = 110-sequences.shape[1]\n",
    "            sequences = sequences.flatten()\n",
    "            sequences = torch.cat((sequences, (torch.zeros(batch_size, n)).flatten().to(device)))\n",
    "            print('modified', sequences.shape)\n",
    "            sequences = sequences.reshape(batch_size, 110).to(device)\n",
    "        sequences = sequences.reshape(-1, sequence_length, input_size)\n",
    "        sequences = stride(sequences, stride_number).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Testing loop\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (sequences, targets) in enumerate(test_loader):\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            if sequences.shape[1] != 110:\n",
    "                n = 110-sequences.shape[1]\n",
    "                sequences = sequences.flatten()\n",
    "                sequences = torch.cat((sequences, (torch.zeros(batch_size, n)).flatten().to(device)))\n",
    "                print('modified', sequences.shape)\n",
    "                sequences = sequences.reshape(batch_size, 110).to(device)\n",
    "            sequences = sequences.reshape(-1, sequence_length, input_size)\n",
    "            sequences = stride(sequences, stride_number).to(device)\n",
    "            outputs = model(sequences)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "W_z = model.lstm.rnncell.W_z.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/multiscale_RNN_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/multiscale_RNN_48.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_2_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_2_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(0.5)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_2_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_2_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_2_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_2(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_2_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_2(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_2(\n",
      "  (lstm): vanilla_RNN_2_batch(\n",
      "    (rnncell): vanilla_RNN_2_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 11.40\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 11.40\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 11.40\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:11.35%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "W_z = model.lstm.rnncell.W_z.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/multiscale_RNN_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/multiscale_RNN_48.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_3_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_3_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(0.1)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_3_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_3_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_3_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_3(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_3_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_3(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_3(\n",
      "  (lstm): vanilla_RNN_3_batch(\n",
      "    (rnncell): vanilla_RNN_3_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 9.80\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 47.40\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 64.40\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 72.00\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 75.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 77.00\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 75.70\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 78.80\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 78.60\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 80.90\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 80.60\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 81.30\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 82.10\n",
      "Epoch [7/10], Step [1500/1500], Training Accuracy: 81.70\n",
      "Epoch [8/10], Step [750/1500], Training Accuracy: 84.50\n",
      "Epoch [8/10], Step [1500/1500], Training Accuracy: 84.80\n",
      "Epoch [9/10], Step [750/1500], Training Accuracy: 83.70\n",
      "Epoch [9/10], Step [1500/1500], Training Accuracy: 85.30\n",
      "Epoch [10/10], Step [750/1500], Training Accuracy: 85.50\n",
      "Epoch [10/10], Step [1500/1500], Training Accuracy: 85.50\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:86.61%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/multiscale_RNN_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, W_z, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/multiscale_RNN_48.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train GRU on the dataset\n",
    "class GRU_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(GRU_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass\n",
    "\n",
    "model = GRU_cell(input_size, hidden_size, num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_cell(\n",
      "  (gru): GRU(8, 48, batch_first=True)\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [40, 10], got [40]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 94\u001b[0m\n\u001b[0;32m     90\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m train_acc\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_acc\n\u001b[1;32m---> 94\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[81], line 68\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(num_epochs, model, loaders, patience, min_delta)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     67\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m---> 68\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[0;32m     71\u001b[0m model_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\yawen cheng\\Python_3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\yawen cheng\\Python_3.11\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yawen cheng\\Python_3.11\\Lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected target size [40, 10], got [40]"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "\n",
    "class CB_GRU_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_GRU_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K is always positive            \n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))     \n",
    "        self.K = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))\n",
    "        self.z_high = torch.tensor(0.005)\n",
    "        self.z_low = torch.tensor(1.0)\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.uniform_(param, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.Sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "        # No sign constraint on K and W\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "        \n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = (self.z_high-self.z_low)* self.Sigmoid(torch.matmul(self.K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z) + self.z_low\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)                \n",
    "\n",
    "class CB_GRU_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_GRU_batch, self).__init__()\n",
    "        self.rnncell = CB_GRU_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_GRU_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = CB_GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_GRU(\n",
      "  (lstm): CB_GRU_batch(\n",
      "    (rnncell): CB_GRU_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 62.50\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 71.00\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 74.30\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 78.30\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 80.80\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 81.10\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 79.40\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 83.10\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 81.50\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 84.30\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 84.80\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 78.10\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 83.40\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:84.53%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n",
    "\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/03_CB_GRU_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained modellent_workspace/week09/permuted_MNIST_models.ipynb\n",
    "torch.save(model.state_dict(), 'weights/03_CB_GRU_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-RNN-tied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CB_RNN_tiedcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_RNN_tiedcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.W = torch.nn.Parameter(torch.empty(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and P_z become tied          \n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # initialise e as a random float between 0 and 1\n",
    "        self.e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_p = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "        # Voltage rate\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        for w in self.W, self.P:\n",
    "            glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        e = self.softplus(self.e)\n",
    "        e_p = self.softplus(self.e_p)\n",
    "        K = e * self.softplus(self.W)\n",
    "        P_z = e_p * self.softplus(self.P)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low) * self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)                \n",
    "\n",
    "class CB_RNN_tied_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_RNN_tied_batch, self).__init__()\n",
    "        self.rnncell = CB_RNN_tiedcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_RNN_tied(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_RNN_tied, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_RNN_tied_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = CB_RNN_tied(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_RNN_tied(\n",
      "  (lstm): CB_RNN_tied_batch(\n",
      "    (rnncell): CB_RNN_tiedcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 55.10\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 67.90\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 73.00\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 75.90\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 79.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 79.30\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 80.40\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 80.30\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 81.80\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 80.80\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 83.40\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 83.70\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 83.10\n",
      "Epoch [7/10], Step [1500/1500], Training Accuracy: 84.00\n",
      "Epoch [8/10], Step [750/1500], Training Accuracy: 83.50\n",
      "Epoch [8/10], Step [1500/1500], Training Accuracy: 84.90\n",
      "Epoch [9/10], Step [750/1500], Training Accuracy: 81.60\n",
      "Epoch [9/10], Step [1500/1500], Training Accuracy: 83.90\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:85.55%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dale-CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dale_CBcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Dale_CBcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "        self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        #values, _ = torch.linalg.eig(weights @ weights.T)\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)* self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(W, self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)   \n",
    "\n",
    "class Dale_CB_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(Dale_CB_batch, self).__init__()\n",
    "        self.rnncell = Dale_CBcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class Dale_CB(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(Dale_CB, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = Dale_CB_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = Dale_CB(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dale_CB(\n",
      "  (lstm): Dale_CB_batch(\n",
      "    (rnncell): Dale_CBcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 10.30\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 9.60\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:80.93%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-RNN-tied-STP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "\n",
    "class CB_RNN_tiedcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_RNN_tiedcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.W = torch.nn.Parameter(torch.empty(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and P_z become tied          \n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # initialise e as a random float between 0 and 1\n",
    "        self.e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_p = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "        # Voltage rate\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        for w in self.W, self.P:\n",
    "            glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.full((self.hidden_size, 1), 0.9, dtype=torch.float32).to(device)\n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        e = self.softplus(self.e)\n",
    "        e_p = self.softplus(self.e_p)\n",
    "        K = e * self.softplus(self.W)\n",
    "        P_z = e_p * self.softplus(self.P)\n",
    "\n",
    "        ### STP model ###\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)* self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(P_z, x) + self.b_z)\n",
    "        # mask p with second half of the neuron not receiving input\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(self.W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())       \n",
    "\n",
    "class CB_RNN_tied_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_RNN_tied_batch, self).__init__()\n",
    "        self.rnncell = CB_RNN_tiedcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_RNN_tied(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_RNN_tied, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_RNN_tied_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        # mask only the second half giving output\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = CB_RNN_tied(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_RNN_tied(\n",
      "  (lstm): CB_RNN_tied_batch(\n",
      "    (rnncell): CB_RNN_tiedcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 29.20\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 44.90\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 51.60\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 62.90\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 68.40\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 74.80\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 73.20\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 74.90\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 77.70\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 77.60\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 76.70\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:77.93%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "# Retrieve weights\n",
    "K = model.lstm.rnncell.e * nn.Softplus()(model.lstm.rnncell.W)\n",
    "P_z = model.lstm.rnncell.e_p * nn.Softplus()(model.lstm.rnncell.P)\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "Ucap = model.lstm.rnncell.Ucap.detach().cpu().numpy()\n",
    "c_U = model.lstm.rnncell.c_U.detach().cpu().numpy()\n",
    "c_u = model.lstm.rnncell.c_u.detach().cpu().numpy()\n",
    "c_x = model.lstm.rnncell.c_x.detach().cpu().numpy()\n",
    "e = model.lstm.rnncell.e.detach().cpu().numpy()\n",
    "e_p = model.lstm.rnncell.e_p.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/06_CB-RNN-tied-STP_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, P_z, b_v, Ucap, c_U, c_u, c_x, e, e_p], f)\n",
    "    #pickle.dump([X_history, U_history, v_t_history, z_t_history, labelslist], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/06_CB-RNN-tied-STP_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dale-CB-STP\n",
    "Accuracy of the model:55.56% (doubled neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9006, grad_fn=<MulBackward0>)\n",
      "tensor(0.9000, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Dale_CB_STPcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Dale_CB_STPcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        while True:\n",
    "            self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            nse_K = self.NSE(self.K)\n",
    "            nse_C = self.NSE(self.C)\n",
    "            if nse_K > 0.87 and nse_C > 0.87:\n",
    "                break\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.full((self.hidden_size, 1), 0.9, dtype=torch.float32).to(device)\n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        values= torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "    \n",
    "    def NSE(self, weights):\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        normalised_v = values/sum(values)\n",
    "        H = -1/torch.log(torch.tensor(self.hidden_size)) * torch.sum(normalised_v * torch.log(normalised_v))\n",
    "        print(H)\n",
    "        return H\n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        # first half of neurons are excitatory and second half are inhibitory\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### STP model ###\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low) * self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        \n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)    \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())   \n",
    "\n",
    "\n",
    "class Dale_CB_STP_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(Dale_CB_STP_batch, self).__init__()\n",
    "        self.rnncell = Dale_CB_STPcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class Dale_CB_STP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(Dale_CB_STP, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = Dale_CB_STP_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = Dale_CB_STP(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dale_CB_STP(\n",
      "  (lstm): Dale_CB_STP_batch(\n",
      "    (rnncell): Dale_CB_STPcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 21.10\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 36.20\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 39.90\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 53.30\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 58.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 60.40\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 65.50\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 65.90\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 67.00\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 68.00\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 69.60\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 67.90\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 69.10\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:71.63%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "C = model.lstm.rnncell.C.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "e_e = model.lstm.rnncell.e_e.detach().cpu().numpy()\n",
    "e_i = model.lstm.rnncell.e_i.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "Ucap = model.lstm.rnncell.Ucap.detach().cpu().numpy()\n",
    "c_U = model.lstm.rnncell.c_U.detach().cpu().numpy()\n",
    "c_u = model.lstm.rnncell.c_u.detach().cpu().numpy()\n",
    "c_x = model.lstm.rnncell.c_x.detach().cpu().numpy()\n",
    "\n",
    "import pickle\n",
    "with open('weights/07_Dale-CB-STP_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap, c_U, c_u, c_x], f)\n",
    "    pickle.dump([X_history, U_history, v_t_history, z_t_history, labelslist], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/07_Dale-CB-STP_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting STP features after Dale-CB is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from Dale-CB\n",
    "import pickle\n",
    "with open('weights/05_Dale-CB_48.pkl', 'rb') as f:\n",
    "    P, W, read_out, K, C, P_z, b_z, e_e, e_i, b_v = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9013, grad_fn=<MulBackward0>)\n",
      "tensor(0.9003, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class new_Dale_CB_STPcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(new_Dale_CB_STPcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        while True:\n",
    "            self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            nse_K = self.NSE(self.K)\n",
    "            nse_C = self.NSE(self.C)\n",
    "            if nse_K > 0.87 and nse_C > 0.87:\n",
    "                break\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        self.z_high = nn.Parameter(torch.repeat_interleave(torch.tensor(0.2), self.hidden_size).reshape(self.hidden_size,1), requires_grad = False)\n",
    "        self.z_low = torch.nn.Parameter(torch.zeros(self.hidden_size, 1, dtype=torch.float32), requires_grad = False)\n",
    "        self.z_low[self.hidden_size//2:,:] = 0.1\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.Ucap = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "        self.A = torch.tensor(0.0, dtype=torch.float32).to(device)\n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        values= torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "    \n",
    "    def NSE(self, weights):\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        normalised_v = values/sum(values)\n",
    "        H = -1/torch.log(torch.tensor(self.hidden_size)) * torch.sum(normalised_v * torch.log(normalised_v))\n",
    "        print(H)\n",
    "        return H\n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        # first half of neurons are excitatory and second half are inhibitory\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### STP model ###\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.A * self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)*self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        \n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)    \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())   \n",
    "\n",
    "\n",
    "class new_Dale_CB_STP_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(new_Dale_CB_STP_batch, self).__init__()\n",
    "        self.rnncell = new_Dale_CB_STPcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class new_Dale_CB_STP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(new_Dale_CB_STP, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = new_Dale_CB_STP_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = new_Dale_CB_STP(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_Dale_CB_STP(\n",
       "  (lstm): new_Dale_CB_STP_batch(\n",
       "    (rnncell): new_Dale_CB_STPcell(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.lstm.rnncell.P = torch.nn.Parameter(torch.tensor(P))\n",
    "model.fc.weight = torch.nn.Parameter(torch.tensor(read_out))\n",
    "model.lstm.rnncell.K = torch.nn.Parameter(torch.tensor(K))\n",
    "model.lstm.rnncell.C = torch.nn.Parameter(torch.tensor(C))\n",
    "model.lstm.rnncell.P_z = torch.nn.Parameter(torch.tensor(P_z))\n",
    "model.lstm.rnncell.b_z = torch.nn.Parameter(torch.tensor(b_z))\n",
    "model.lstm.rnncell.e_e = torch.nn.Parameter(torch.tensor(e_e))\n",
    "model.lstm.rnncell.e_i = torch.nn.Parameter(torch.tensor(e_i))\n",
    "model.lstm.rnncell.b_v = torch.nn.Parameter(torch.tensor(b_v))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_Dale_CB_STP(\n",
      "  (lstm): new_Dale_CB_STP_batch(\n",
      "    (rnncell): new_Dale_CB_STPcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [750/1500], Training Accuracy: 44.00\n",
      "Epoch [1/10], Step [1500/1500], Training Accuracy: 49.50\n",
      "Epoch [2/10], Step [750/1500], Training Accuracy: 51.60\n",
      "Epoch [2/10], Step [1500/1500], Training Accuracy: 53.40\n",
      "Epoch [3/10], Step [750/1500], Training Accuracy: 66.00\n",
      "Epoch [3/10], Step [1500/1500], Training Accuracy: 65.10\n",
      "Epoch [4/10], Step [750/1500], Training Accuracy: 68.50\n",
      "Epoch [4/10], Step [1500/1500], Training Accuracy: 71.40\n",
      "Epoch [5/10], Step [750/1500], Training Accuracy: 72.90\n",
      "Epoch [5/10], Step [1500/1500], Training Accuracy: 74.50\n",
      "Epoch [6/10], Step [750/1500], Training Accuracy: 75.30\n",
      "Epoch [6/10], Step [1500/1500], Training Accuracy: 73.40\n",
      "Epoch [7/10], Step [750/1500], Training Accuracy: 74.30\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            if model.lstm.rnncell.A != 1.0:\n",
    "                model.lstm.rnncell.A += 0.2\n",
    "            #print(model.lstm.rnncell.A)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 750 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:77.46%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "C = model.lstm.rnncell.C.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "e_e = model.lstm.rnncell.e_e.detach().cpu().numpy()\n",
    "e_i = model.lstm.rnncell.e_i.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "Ucap = model.lstm.rnncell.Ucap.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/pretrained_Dale-CB-STP.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap], f)\n",
    "    #pickle.dump([X_history, U_history, v_t_history, z_t_history, labelslist], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/pretrained_Dale-CB-STP.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# W1 is the weight from Dale-CB\n",
    "# W2 is the weight from Dale-CB-STP after pretraining\n",
    "# W3 is the weight from Dale-CB-STP without pretraining\n",
    "with open('weights/05_Dale-CB_48.pkl', 'rb') as f:\n",
    "    P, W1, read_out, K, C, P_z, b_z, e_e, e_i, b_v = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "with open('weights/pretrained_Dale-CB-STP.pkl', 'rb') as f:\n",
    "    P, W2, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap= pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "with open('weights/07_Dale-CB-STP_48.pkl', 'rb') as f:\n",
    "    P, W3, read_out, K, C, P_z, b_z, e_e, e_i, b_v, Ucap, c_U, c_u, c_x= pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "# plot heatmap of W1 and W2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 3, figsize=(25, 6))\n",
    "sns.heatmap(W1, ax=ax[0])\n",
    "ax[0].set_title('Dale-CB')\n",
    "sns.heatmap(W2, ax=ax[1])\n",
    "ax[1].set_title('Dale-CB-STP after pretraining')\n",
    "sns.heatmap(W3, ax=ax[2])\n",
    "ax[2].set_title('Dale-CB-STP without pretraining')\n",
    "\n",
    "# compare their performance\n",
    "perf = [80.93 ,77.46, 71.63]\n",
    "labels = ['Dale-CB', 'pretrained Dale-CB-STP', 'Dale-CB-STP']\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(labels, perf)\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Performance of permuted MNIST')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Performance bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# rotate model name\n",
    "\n",
    "model_name = ['simple GRU', 'CB-GRU', 'CB-RNN-tied', 'Dale-CB', 'CB-RNN-tied STP', 'Dale-CB STP', 'multiscale-Vanilla RNN', 'Vanilla RNN $z=1.0$', 'Vanilla RNN $z=0.5$', 'Vanilla RNN $z=0.1$']\n",
    "perf1 = [0, 84.53, 85.55, 0, 0, 0, 77.38, 0, 0, 0]\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.bar(model_name, perf1, bar_width, label='48 Neurons')\n",
    "index = np.arange(len(model_name))\n",
    "# text bar to show input size, stride number, and hidden size\n",
    "plt.text(4.5, 80, f'Input size: {input_size}\\nStride number: {stride_number}'.format(input_size=input_size, stride_number=stride_number, hidden_size=hidden_size), ha='center', va='bottom')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Performance of permuted MNIST')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
