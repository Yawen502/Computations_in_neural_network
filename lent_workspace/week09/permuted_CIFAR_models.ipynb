{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list of models\n",
    "- Full GRU\n",
    "- Simple GRU\n",
    "- CB-GRU\n",
    "- CB-RNN-tied\n",
    "- Dale-CB\n",
    "- CB-RNN-tied-STP /\n",
    "- Dale-CB-STP /\n",
    "- Vanilla RNN\n",
    "\n",
    "### Variants\n",
    "With 24 neurons / with 48 neurons (let's do 48 first)\n",
    "\n",
    "### Check Features\n",
    "Input/ Ouput neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3*8\n",
    "sequence_length = 3*32*32//input_size\n",
    "hidden_size = 48\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 40\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "stride_number = 3*4\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "per = np.random.permutation(32*32)\n",
    "\n",
    "def permuted(img, per):\n",
    "    'transform a 28*28 image to a 28*28 permuted image'\n",
    "    channels, rows, cols = img.shape\n",
    "    permuted = np.zeros((channels, rows, cols), dtype=img.dtype)\n",
    "    for c in range(channels):\n",
    "        permuted[c, :, :] = img[c, :, :].flatten()[per-1].reshape(rows, cols)\n",
    "    # flatten first dimension\n",
    "    permuted = permuted.reshape(-1)\n",
    "    permuted = permuted.reshape(rows*channels, cols)\n",
    "    return permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "0\n",
      "1\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i, (images, labels) in enumerate(loaders['train']):\\n    images = images.reshape(-1, sequence_length, input_size).to(device)\\n    images = stride(images, stride_number).to(device)\\n    print(images.shape)\\n    print(labels.shape)\\n    print(len(loaders['train']))\\n    break\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'CIFAR Data Preprocessing'\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# get index of currently selected device\n",
    "print(torch.cuda.current_device()) # returns 0 in my case\n",
    "\n",
    "# get number of GPUs available\n",
    "print(torch.cuda.device_count()) # returns 1 in my case\n",
    "\n",
    "# get the name of the device\n",
    "print(torch.cuda.get_device_name(0)) # good old Tesla K80\n",
    "\n",
    "def snake_scan(img):\n",
    "    'Converts a 32x32 image to a 32x96 array with snake-like row ordering'\n",
    "    if len(img.shape) != 3:\n",
    "        raise ValueError('Input image must be a 3D array')\n",
    "    print(img.shape)\n",
    "    channels, rows, cols = img.shape\n",
    "    snake = np.zeros((rows, cols * channels), dtype=img.dtype)\n",
    "    for r in range(rows):\n",
    "        row_data = img[:, r, :].flatten()  # Flattening each row into a 1D array of 96 elements\n",
    "        if r % 2 == 1:\n",
    "            row_data = row_data[::-1]  # Reversing the order for alternate rows\n",
    "        snake[r] = row_data\n",
    "    return snake\n",
    "\n",
    "def stride(input_data, stride):\n",
    "    'turn [batch_size, sequence_length, input_size] into [batch_size, sequence_length*input_size/stride, input_size]'\n",
    "    batch_size, sequence_length, input_size = input_data.shape\n",
    "    # flatten the input data to put sequence and input size together\n",
    "    input_data = input_data.reshape(batch_size, -1)\n",
    "    # append zeros to make sure the last pixel can be fed as the first pixel of the next sequence\n",
    "    n = input_size - (sequence_length*input_size)%stride\n",
    "\n",
    "    input_data = input_data.cpu()\n",
    "    input_data = input_data.numpy()\n",
    "    input_data = np.append(input_data, np.zeros((batch_size, n)), axis=1)\n",
    "    input_data = torch.tensor(input_data)\n",
    "    #print(input_data.shape)\n",
    "    output_data = torch.zeros(batch_size, sequence_length*input_size//stride, input_size)\n",
    "    for i in range(sequence_length*input_size//stride):\n",
    "        # if stride = input size, then the output data is the same as input data\n",
    "        #print(i)\n",
    "\n",
    "        output_data[:,i,:] = input_data[:,i*stride:i*stride+input_size]\n",
    "        #print(output_data[batch,i,:])\n",
    "\n",
    "    return output_data\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: torch.tensor(permuted(x.numpy(), per)))\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=0),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False, \n",
    "                                          num_workers=0),\n",
    "}\n",
    "loaders\n",
    "'''\n",
    "for i, (images, labels) in enumerate(loaders['train']):\n",
    "    images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "    images = stride(images, stride_number).to(device)\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    print(len(loaders['train']))\n",
    "    break\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 32)\n",
      "torch.Size([96, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.random.rand(3, 32, 32)\n",
    "print(permuted(a, per).shape)\n",
    "# plot a sample image\n",
    "import matplotlib.pyplot as plt\n",
    "image, label = train_data[2]\n",
    "print(image.shape)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUll GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "model = GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (gru): GRU(24, 48, batch_first=True)\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 30.60\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 34.20\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 36.80\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 36.50\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 38.20\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 37.60\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 38.10\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:20.01%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class simple_GRU_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(simple_GRU_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # Wz is defined in the forward function\n",
    "        self.W_z = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))         \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.uniform_(param, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = self.Sigmoid(torch.matmul(self.W_z, self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class simple_GRU_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(simple_GRU_batch, self).__init__()\n",
    "        self.rnncell = simple_GRU_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class simple_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(simple_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = simple_GRU_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = simple_GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_GRU(\n",
      "  (lstm): simple_GRU_batch(\n",
      "    (rnncell): simple_GRU_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 22.30\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 27.20\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 27.80\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 32.30\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 35.00\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 35.20\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 35.90\n",
      "Epoch [4/10], Step [500/500], Training Accuracy: 35.70\n",
      "Epoch [5/10], Step [250/500], Training Accuracy: 36.80\n",
      "Epoch [5/10], Step [500/500], Training Accuracy: 36.40\n",
      "Epoch [6/10], Step [250/500], Training Accuracy: 35.90\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:23.22%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Timescale RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonlinearity: Sigmoid\n",
    "\n",
    "$z_t = \\sigma (W_z r_t + P_zx_t + b_z)$ with $W_z = P_z = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class multiscale_RNN_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(multiscale_RNN_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # Wz is defined in the forward function\n",
    "        self.W_z = torch.nn.Parameter(torch.zeros(self.hidden_size, self.hidden_size), requires_grad=False)\n",
    "        self.P_z = torch.nn.Parameter(torch.zeros(self.hidden_size, input_size), requires_grad=False)\n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))         \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)*self.Sigmoid(torch.matmul(self.W_z, self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class multiscale_RNN_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(multiscale_RNN_batch, self).__init__()\n",
    "        self.rnncell = multiscale_RNN_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class multiscale_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(multiscale_RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = multiscale_RNN_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = multiscale_RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiscale_RNN(\n",
      "  (lstm): multiscale_RNN_batch(\n",
      "    (rnncell): multiscale_RNN_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 19.20\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 21.40\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 23.90\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 22.30\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 23.40\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:24.99%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_1_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_1_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(1.0)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_1_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_1_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_1_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_1(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_1, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_1_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_1(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_1(\n",
      "  (lstm): vanilla_RNN_1_batch(\n",
      "    (rnncell): vanilla_RNN_1_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 21.40\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 22.10\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 25.60\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 29.60\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 30.50\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 28.30\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 30.40\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:32.77%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_2_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_2_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(0.5)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_2_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_2_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_2_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_2(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_2_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_2(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_2(\n",
      "  (lstm): vanilla_RNN_2_batch(\n",
      "    (rnncell): vanilla_RNN_2_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 18.30\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 22.10\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 24.40\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 22.10\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 23.50\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:25.59%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_3_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_3_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(0.1)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_3_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_3_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_3_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_3(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_3_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_3(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_3(\n",
      "  (lstm): vanilla_RNN_3_batch(\n",
      "    (rnncell): vanilla_RNN_3_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 18.50\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 19.50\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 19.30\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 19.80\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 22.80\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 22.00\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 24.60\n",
      "Epoch [4/10], Step [500/500], Training Accuracy: 26.60\n",
      "Epoch [5/10], Step [250/500], Training Accuracy: 25.60\n",
      "Epoch [5/10], Step [500/500], Training Accuracy: 26.20\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:26.75%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "\n",
    "class CB_GRU_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_GRU_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K is always positive            \n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))     \n",
    "        self.K = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))\n",
    "        self.z_high = torch.tensor(0.005)\n",
    "        self.z_low = torch.tensor(1.0)\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.uniform_(param, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.Sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "        # No sign constraint on K and W\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "        \n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = (self.z_high-self.z_low)* self.Sigmoid(torch.matmul(self.K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z) + self.z_low\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)                \n",
    "\n",
    "class CB_GRU_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_GRU_batch, self).__init__()\n",
    "        self.rnncell = CB_GRU_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_GRU_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = CB_GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_GRU(\n",
      "  (lstm): CB_GRU_batch(\n",
      "    (rnncell): CB_GRU_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 20.70\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 25.30\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 25.70\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 26.00\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 27.80\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 27.80\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 27.90\n",
      "Epoch [4/10], Step [500/500], Training Accuracy: 29.00\n",
      "Epoch [5/10], Step [250/500], Training Accuracy: 28.40\n",
      "Epoch [5/10], Step [500/500], Training Accuracy: 30.40\n",
      "Epoch [6/10], Step [250/500], Training Accuracy: 30.20\n",
      "Epoch [6/10], Step [500/500], Training Accuracy: 29.80\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:33.16%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n",
    "\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/03_CB_GRU_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/03_CB_GRU_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-RNN-tied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CB_RNN_tiedcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_RNN_tiedcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.W = torch.nn.Parameter(torch.empty(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and P_z become tied          \n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # initialise e as a random float between 0 and 1\n",
    "        self.e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_p = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "        # Voltage rate\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        for w in self.W, self.P:\n",
    "            glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        e = self.softplus(self.e)\n",
    "        e_p = self.softplus(self.e_p)\n",
    "        K = e * self.softplus(self.W)\n",
    "        P_z = e_p * self.softplus(self.P)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low) * self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)                \n",
    "\n",
    "class CB_RNN_tied_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_RNN_tied_batch, self).__init__()\n",
    "        self.rnncell = CB_RNN_tiedcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_RNN_tied(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_RNN_tied, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_RNN_tied_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = CB_RNN_tied(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_RNN_tied(\n",
      "  (lstm): CB_RNN_tied_batch(\n",
      "    (rnncell): CB_RNN_tiedcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 22.30\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 26.70\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 26.60\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 29.50\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 28.90\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 29.00\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:30.6%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dale-CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dale_CBcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Dale_CBcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "        self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        #values, _ = torch.linalg.eig(weights @ weights.T)\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)* self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(W, self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)   \n",
    "\n",
    "class Dale_CB_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(Dale_CB_batch, self).__init__()\n",
    "        self.rnncell = Dale_CBcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class Dale_CB(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(Dale_CB, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = Dale_CB_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = Dale_CB(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dale_CB(\n",
      "  (lstm): Dale_CB_batch(\n",
      "    (rnncell): Dale_CBcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 17.20\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 20.90\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 23.30\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 24.10\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 23.60\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 23.50\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:25.13%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-RNN-tied-STP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "\n",
    "class CB_RNN_tiedcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_RNN_tiedcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.W = torch.nn.Parameter(torch.empty(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and P_z become tied          \n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # initialise e as a random float between 0 and 1\n",
    "        self.e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_p = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "        # Voltage rate\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        for w in self.W, self.P:\n",
    "            glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.full((self.hidden_size, 1), 0.9, dtype=torch.float32).to(device)\n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        e = self.softplus(self.e)\n",
    "        e_p = self.softplus(self.e_p)\n",
    "        K = e * self.softplus(self.W)\n",
    "        P_z = e_p * self.softplus(self.P)\n",
    "\n",
    "        ### STP model ###\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)* self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(P_z, x) + self.b_z)\n",
    "        # mask p with second half of the neuron not receiving input\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(self.W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())       \n",
    "\n",
    "class CB_RNN_tied_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_RNN_tied_batch, self).__init__()\n",
    "        self.rnncell = CB_RNN_tiedcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_RNN_tied(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_RNN_tied, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_RNN_tied_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        # mask only the second half giving output\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = CB_RNN_tied(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_RNN_tied(\n",
      "  (lstm): CB_RNN_tied_batch(\n",
      "    (rnncell): CB_RNN_tiedcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 23.70\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 23.70\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 26.20\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 27.70\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 27.10\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 28.60\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 30.40\n",
      "Epoch [4/10], Step [500/500], Training Accuracy: 31.40\n",
      "Epoch [5/10], Step [250/500], Training Accuracy: 29.40\n",
      "Epoch [5/10], Step [500/500], Training Accuracy: 30.50\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:33.57%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dale-CB-STP\n",
    "Accuracy of the model:55.56% (doubled neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9008, grad_fn=<MulBackward0>)\n",
      "tensor(0.9009, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Dale_CB_STPcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Dale_CB_STPcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        while True:\n",
    "            self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            nse_K = self.NSE(self.K)\n",
    "            nse_C = self.NSE(self.C)\n",
    "            if nse_K > 0.87 and nse_C > 0.87:\n",
    "                break\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.full((self.hidden_size, 1), 0.9, dtype=torch.float32).to(device)\n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        values= torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "    \n",
    "    def NSE(self, weights):\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        normalised_v = values/sum(values)\n",
    "        H = -1/torch.log(torch.tensor(self.hidden_size)) * torch.sum(normalised_v * torch.log(normalised_v))\n",
    "        print(H)\n",
    "        return H\n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        # first half of neurons are excitatory and second half are inhibitory\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### STP model ###\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low) * self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        \n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)    \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())   \n",
    "\n",
    "\n",
    "class Dale_CB_STP_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(Dale_CB_STP_batch, self).__init__()\n",
    "        self.rnncell = Dale_CB_STPcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class Dale_CB_STP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(Dale_CB_STP, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = Dale_CB_STP_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = Dale_CB_STP(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dale_CB_STP(\n",
      "  (lstm): Dale_CB_STP_batch(\n",
      "    (rnncell): Dale_CB_STPcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 20.20\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 21.90\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 23.80\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 26.80\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 27.20\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 27.10\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 24.70\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:27.93%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Performance of permuted CIFAR-10')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Performance bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# rotate model name\n",
    "\n",
    "model_name = ['full GRU', 'simple GRU', 'CB-GRU', 'CB-RNN-tied', 'Dale-CB', 'CB-RNN-tied STP', 'Dale-CB STP', 'multiscale-Vanilla RNN', 'Vanilla RNN $z=1.0$', 'Vanilla RNN $z=0.5$', 'Vanilla RNN $z=0.1$']\n",
    "perf1 = [20.01, 23.22, 33.16, 30.6, 25.13, 33.57, 27.93, 24.99, 32.77, 25.59, 26.75]\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.bar(model_name, perf1, bar_width, label='48 Neurons')\n",
    "index = np.arange(len(model_name))\n",
    "# text bar to show input size, stride number, and hidden size\n",
    "plt.text(3.5, 31, f'Input size: {input_size}\\nStride number: {stride_number}'.format(input_size=input_size, stride_number=stride_number, hidden_size=hidden_size), ha='center', va='bottom')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Performance of permuted CIFAR-10')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
