{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list of models\n",
    "- Full GRU\n",
    "- Simple GRU\n",
    "- CB-GRU\n",
    "- CB-RNN-tied\n",
    "- Dale-CB\n",
    "- CB-RNN-tied-STP /\n",
    "- Dale-CB-STP /\n",
    "- Vanilla RNN\n",
    "\n",
    "### Variants\n",
    "With 24 neurons / with 48 neurons (let's do 48 first)\n",
    "\n",
    "### Check Features\n",
    "Input/ Ouput neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3*8\n",
    "sequence_length = 3*32*32//input_size\n",
    "hidden_size = 48\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 40\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "stride_number = 3*4\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "per = np.random.permutation(32*32)\n",
    "\n",
    "def permuted(img, per):\n",
    "    'transform a 28*28 image to a 28*28 permuted image'\n",
    "    channels, rows, cols = img.shape\n",
    "    permuted = np.zeros((channels, rows, cols), dtype=img.dtype)\n",
    "    for c in range(channels):\n",
    "        permuted[c, :, :] = img[c, :, :].flatten()[per-1].reshape(rows, cols)\n",
    "    # flatten first dimension\n",
    "    permuted = permuted.reshape(-1)\n",
    "    permuted = permuted.reshape(rows*channels, cols)\n",
    "    return permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "0\n",
      "1\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i, (images, labels) in enumerate(loaders['train']):\\n    images = images.reshape(-1, sequence_length, input_size).to(device)\\n    images = stride(images, stride_number).to(device)\\n    print(images.shape)\\n    print(labels.shape)\\n    print(len(loaders['train']))\\n    break\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'CIFAR Data Preprocessing'\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# get index of currently selected device\n",
    "print(torch.cuda.current_device()) # returns 0 in my case\n",
    "\n",
    "# get number of GPUs available\n",
    "print(torch.cuda.device_count()) # returns 1 in my case\n",
    "\n",
    "# get the name of the device\n",
    "print(torch.cuda.get_device_name(0)) # good old Tesla K80\n",
    "\n",
    "def snake_scan(img):\n",
    "    'Converts a 32x32 image to a 32x96 array with snake-like row ordering'\n",
    "    if len(img.shape) != 3:\n",
    "        raise ValueError('Input image must be a 3D array')\n",
    "    print(img.shape)\n",
    "    channels, rows, cols = img.shape\n",
    "    snake = np.zeros((rows, cols * channels), dtype=img.dtype)\n",
    "    for r in range(rows):\n",
    "        row_data = img[:, r, :].flatten()  # Flattening each row into a 1D array of 96 elements\n",
    "        if r % 2 == 1:\n",
    "            row_data = row_data[::-1]  # Reversing the order for alternate rows\n",
    "        snake[r] = row_data\n",
    "    return snake\n",
    "\n",
    "def stride(input_data, stride):\n",
    "    'turn [batch_size, sequence_length, input_size] into [batch_size, sequence_length*input_size/stride, input_size]'\n",
    "    batch_size, sequence_length, input_size = input_data.shape\n",
    "    # flatten the input data to put sequence and input size together\n",
    "    input_data = input_data.reshape(batch_size, -1)\n",
    "    # append zeros to make sure the last pixel can be fed as the first pixel of the next sequence\n",
    "    n = input_size - (sequence_length*input_size)%stride\n",
    "\n",
    "    input_data = input_data.cpu()\n",
    "    input_data = input_data.numpy()\n",
    "    input_data = np.append(input_data, np.zeros((batch_size, n)), axis=1)\n",
    "    input_data = torch.tensor(input_data)\n",
    "    #print(input_data.shape)\n",
    "    output_data = torch.zeros(batch_size, sequence_length*input_size//stride, input_size)\n",
    "    for i in range(sequence_length*input_size//stride):\n",
    "        # if stride = input size, then the output data is the same as input data\n",
    "        #print(i)\n",
    "\n",
    "        output_data[:,i,:] = input_data[:,i*stride:i*stride+input_size]\n",
    "        #print(output_data[batch,i,:])\n",
    "\n",
    "    return output_data\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: torch.tensor(permuted(x.numpy(), per)))\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=0),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False, \n",
    "                                          num_workers=0),\n",
    "}\n",
    "loaders\n",
    "'''\n",
    "for i, (images, labels) in enumerate(loaders['train']):\n",
    "    images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "    images = stride(images, stride_number).to(device)\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    print(len(loaders['train']))\n",
    "    break\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 32)\n",
      "torch.Size([96, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.random.rand(3, 32, 32)\n",
    "print(permuted(a, per).shape)\n",
    "# plot a sample image\n",
    "import matplotlib.pyplot as plt\n",
    "image, label = train_data[1]\n",
    "print(image.shape)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUll GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "model = GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (gru): GRU(24, 48, batch_first=True)\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 30.60\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 34.20\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 36.80\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 36.50\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 38.20\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 37.60\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 38.10\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:20.01%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class simple_GRU_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(simple_GRU_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # Wz is defined in the forward function\n",
    "        self.W_z = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))         \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.uniform_(param, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = self.Sigmoid(torch.matmul(self.W_z, self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class simple_GRU_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(simple_GRU_batch, self).__init__()\n",
    "        self.rnncell = simple_GRU_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class simple_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(simple_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = simple_GRU_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = simple_GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_GRU(\n",
      "  (lstm): simple_GRU_batch(\n",
      "    (rnncell): simple_GRU_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 22.30\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 27.20\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 27.80\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 32.30\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 35.00\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 35.20\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 35.90\n",
      "Epoch [4/10], Step [500/500], Training Accuracy: 35.70\n",
      "Epoch [5/10], Step [250/500], Training Accuracy: 36.80\n",
      "Epoch [5/10], Step [500/500], Training Accuracy: 36.40\n",
      "Epoch [6/10], Step [250/500], Training Accuracy: 35.90\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:23.22%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Timescale RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonlinearity: Sigmoid\n",
    "\n",
    "$z_t = \\sigma (W_z r_t + P_zx_t + b_z)$ with $W_z = P_z = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class multiscale_RNN_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(multiscale_RNN_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # Wz is defined in the forward function\n",
    "        self.W_z = torch.nn.Parameter(torch.zeros(self.hidden_size, self.hidden_size), requires_grad=False)\n",
    "        self.P_z = torch.nn.Parameter(torch.zeros(self.hidden_size, input_size), requires_grad=False)\n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))         \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)*self.Sigmoid(torch.matmul(self.W_z, self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class multiscale_RNN_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(multiscale_RNN_batch, self).__init__()\n",
    "        self.rnncell = multiscale_RNN_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class multiscale_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(multiscale_RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = multiscale_RNN_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = multiscale_RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiscale_RNN(\n",
      "  (lstm): multiscale_RNN_batch(\n",
      "    (rnncell): multiscale_RNN_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 19.20\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 21.40\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 23.90\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 22.30\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 23.40\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:24.99%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_1_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_1_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(1.0)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_1_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_1_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_1_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_1(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_1, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_1_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_1(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_1(\n",
      "  (lstm): vanilla_RNN_1_batch(\n",
      "    (rnncell): vanilla_RNN_1_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 21.40\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 22.10\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 25.60\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 29.60\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 30.50\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 28.30\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 30.40\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:32.77%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_2_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_2_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(0.5)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_2_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_2_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_2_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_2(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_2_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_2(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_2(\n",
      "  (lstm): vanilla_RNN_2_batch(\n",
      "    (rnncell): vanilla_RNN_2_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 18.30\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 22.10\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 24.40\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 22.10\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 23.50\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:25.59%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "class vanilla_RNN_3_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(vanilla_RNN_3_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.r_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        for W in [self.W, self.P]:\n",
    "            glorot_init(W)\n",
    "            \n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.r_t.dim() == 3:           \n",
    "            self.r_t = self.r_t[0]\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)\n",
    "        self.z_t = torch.tensor(0.1)\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.r_t = (1 - self.z_t) * self.r_t + self.z_t * self.Sigmoid(torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v)\n",
    "        self.r_t = torch.transpose(self.r_t, 0, 1)                \n",
    "\n",
    "class vanilla_RNN_3_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(vanilla_RNN_3_batch, self).__init__()\n",
    "        self.rnncell = vanilla_RNN_3_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.r_t             \n",
    "            \n",
    "class vanilla_RNN_3(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(vanilla_RNN_3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = vanilla_RNN_3_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.r_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = vanilla_RNN_3(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla_RNN_3(\n",
      "  (lstm): vanilla_RNN_3_batch(\n",
      "    (rnncell): vanilla_RNN_3_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 18.50\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 19.50\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 19.30\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 19.80\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 22.80\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 22.00\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 24.60\n",
      "Epoch [4/10], Step [500/500], Training Accuracy: 26.60\n",
      "Epoch [5/10], Step [250/500], Training Accuracy: 25.60\n",
      "Epoch [5/10], Step [500/500], Training Accuracy: 26.20\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:26.75%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "\n",
    "class CB_GRU_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_GRU_cell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        # Rest gate r_t \n",
    "        self.W = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.rand(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K is always positive            \n",
    "        self.b_z = torch.nn.Parameter(torch.rand(self.hidden_size, 1))     \n",
    "        self.K = torch.nn.Parameter(torch.rand(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.rand(self.hidden_size, input_size))\n",
    "        self.z_high = torch.tensor(0.005)\n",
    "        self.z_low = torch.tensor(1.0)\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        # Nonlinear functions\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.uniform_(param, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.Sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "        # No sign constraint on K and W\n",
    "\n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "        \n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = (self.z_high-self.z_low)* self.Sigmoid(torch.matmul(self.K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z) + self.z_low\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)                \n",
    "\n",
    "class CB_GRU_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_GRU_batch, self).__init__()\n",
    "        self.rnncell = CB_GRU_cell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_GRU_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "model = CB_GRU(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_GRU(\n",
      "  (lstm): CB_GRU_batch(\n",
      "    (rnncell): CB_GRU_cell(\n",
      "      (Sigmoid): Sigmoid()\n",
      "      (Tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 20.70\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 25.30\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 25.70\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 26.00\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 27.80\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 27.80\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 27.90\n",
      "Epoch [4/10], Step [500/500], Training Accuracy: 29.00\n",
      "Epoch [5/10], Step [250/500], Training Accuracy: 28.40\n",
      "Epoch [5/10], Step [500/500], Training Accuracy: 30.40\n",
      "Epoch [6/10], Step [250/500], Training Accuracy: 30.20\n",
      "Epoch [6/10], Step [500/500], Training Accuracy: 29.80\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:33.16%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n",
    "\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Save Model'\n",
    "# Retrieve weights\n",
    "P = model.lstm.rnncell.P.detach().cpu().numpy()\n",
    "W = model.lstm.rnncell.W.detach().cpu().numpy()\n",
    "read_out = model.fc.weight.detach().cpu().numpy()\n",
    "K = model.lstm.rnncell.K.detach().cpu().numpy()\n",
    "P_z = model.lstm.rnncell.P_z.detach().cpu().numpy()\n",
    "b_z = model.lstm.rnncell.b_z.detach().cpu().numpy()\n",
    "b_v = model.lstm.rnncell.b_v.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('weights/03_CB_GRU_48.pkl', 'wb') as f:\n",
    "    pickle.dump([P, W, read_out, K, P_z, b_z, b_v], f)\n",
    "    pickle.dump([input_size, hidden_size, num_layers, num_classes, batch_size, num_epochs, learning_rate, stride_number], f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'weights/03_CB_GRU_48.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-RNN-tied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CB_RNN_tiedcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_RNN_tiedcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.W = torch.nn.Parameter(torch.empty(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and P_z become tied          \n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # initialise e as a random float between 0 and 1\n",
    "        self.e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_p = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "        # Voltage rate\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        for w in self.W, self.P:\n",
    "            glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        e = self.softplus(self.e)\n",
    "        e_p = self.softplus(self.e_p)\n",
    "        K = e * self.softplus(self.W)\n",
    "        P_z = e_p * self.softplus(self.P)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low) * self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(self.W, self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)                \n",
    "\n",
    "class CB_RNN_tied_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_RNN_tied_batch, self).__init__()\n",
    "        self.rnncell = CB_RNN_tiedcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_RNN_tied(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_RNN_tied, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_RNN_tied_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = CB_RNN_tied(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_RNN_tied(\n",
      "  (lstm): CB_RNN_tied_batch(\n",
      "    (rnncell): CB_RNN_tiedcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 22.30\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 26.70\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 26.60\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 29.50\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 28.90\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 29.00\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:30.6%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "labelslist = []\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dale-CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dale_CBcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Dale_CBcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "        self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        #values, _ = torch.linalg.eig(weights @ weights.T)\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)* self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(W, self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)   \n",
    "\n",
    "class Dale_CB_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(Dale_CB_batch, self).__init__()\n",
    "        self.rnncell = Dale_CBcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class Dale_CB(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(Dale_CB, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = Dale_CB_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # output mask\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = Dale_CB(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dale_CB(\n",
      "  (lstm): Dale_CB_batch(\n",
      "    (rnncell): Dale_CBcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 17.20\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 20.90\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 23.30\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 24.10\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 23.60\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 23.50\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:25.13%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB-RNN-tied-STP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Definition'\n",
    "\n",
    "class CB_RNN_tiedcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CB_RNN_tiedcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.W = torch.nn.Parameter(torch.empty(self.hidden_size, self.hidden_size))\n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and P_z become tied          \n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # initialise e as a random float between 0 and 1\n",
    "        self.e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_p = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "        # Voltage rate\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        for w in self.W, self.P:\n",
    "            glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.full((self.hidden_size, 1), 0.9, dtype=torch.float32).to(device)\n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        e = self.softplus(self.e)\n",
    "        e_p = self.softplus(self.e_p)\n",
    "        K = e * self.softplus(self.W)\n",
    "        P_z = e_p * self.softplus(self.P)\n",
    "\n",
    "        ### STP model ###\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "        ### Update Equations ###\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//2:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low)* self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(P_z, x) + self.b_z)\n",
    "        # mask p with second half of the neuron not receiving input\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(self.W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())       \n",
    "\n",
    "class CB_RNN_tied_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(CB_RNN_tied_batch, self).__init__()\n",
    "        self.rnncell = CB_RNN_tiedcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.v_t             \n",
    "            \n",
    "class CB_RNN_tied(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CB_RNN_tied, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = CB_RNN_tied_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        # mask only the second half giving output\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,0:self.hidden_size//2] = 0\n",
    "        out = out * output_mask\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = CB_RNN_tied(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB_RNN_tied(\n",
      "  (lstm): CB_RNN_tied_batch(\n",
      "    (rnncell): CB_RNN_tiedcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 23.70\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 23.70\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 26.20\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 27.70\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 27.10\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 28.60\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 30.40\n",
      "Epoch [4/10], Step [500/500], Training Accuracy: 31.40\n",
      "Epoch [5/10], Step [250/500], Training Accuracy: 29.40\n",
      "Epoch [5/10], Step [500/500], Training Accuracy: 30.50\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:33.57%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dale-CB-STP\n",
    "Accuracy of the model:55.56% (doubled neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9008, grad_fn=<MulBackward0>)\n",
      "tensor(0.9009, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Dale_CB_STPcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Dale_CB_STPcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "        ### Parameters ###\n",
    "        # voltage gate v_t \n",
    "        self.P = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))           \n",
    "        self.b_v = torch.nn.Parameter(torch.zeros(self.hidden_size, 1))   \n",
    "\n",
    "        # Update gate z_t\n",
    "        # K and W are unbounded free parameters   \n",
    "        # C represents  current based portion of connectivity       \n",
    "        while True:\n",
    "            self.K = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            self.C = torch.nn.Parameter(self.init_dale(self.hidden_size, self.hidden_size))\n",
    "            nse_K = self.NSE(self.K)\n",
    "            nse_C = self.NSE(self.C)\n",
    "            if nse_K > 0.87 and nse_C > 0.87:\n",
    "                break\n",
    "        self.P_z = torch.nn.Parameter(torch.empty(self.hidden_size, input_size))\n",
    "        self.b_z = torch.nn.Parameter(torch.empty(self.hidden_size, 1))   \n",
    "        # Potentials are initialised with right signs\n",
    "        self.e_e = torch.nn.Parameter(torch.rand(1))\n",
    "        self.e_i = torch.nn.Parameter(-torch.rand(1))\n",
    "\n",
    "        # Firing rate, Scaling factor and time step initialization\n",
    "        self.v_t = torch.zeros(1, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        self.z_low = torch.tensor(0.005)\n",
    "        self.z_high = torch.tensor(1.0)\n",
    "\n",
    "        ### Nonlinear functions ###\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### Initialisation ###\n",
    "        glorot_init = lambda w: nn.init.uniform_(w, a=-(1/math.sqrt(hidden_size)), b=(1/math.sqrt(hidden_size)))\n",
    "        positive_glorot_init = lambda w: nn.init.uniform_(w, a=0, b=(1/math.sqrt(hidden_size)))\n",
    "\n",
    "        # initialise matrices\n",
    "        # P and P_z are unconstrained\n",
    "        for w in self.P_z, self.P:\n",
    "            glorot_init(w)\n",
    "        for w in self.K, self.C:\n",
    "            positive_glorot_init(w)\n",
    "        # init b_z to be log 1/99\n",
    "        nn.init.constant_(self.b_z, torch.log(torch.tensor(1/99)))\n",
    "\n",
    "        ### STP Model ###\n",
    "        self.delta_t = 1\n",
    "        self.z_min = 0.001\n",
    "        self.z_max = 0.1\n",
    "\n",
    "        # Short term Depression parameters  \n",
    "        self.c_x = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "\n",
    "        # Short term Facilitation parameters\n",
    "        self.c_u = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.c_U = torch.nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        \n",
    "        # State initialisations\n",
    "        self.X = torch.ones(self.hidden_size, 1, dtype=torch.float32).to(device)\n",
    "        self.U = torch.full((self.hidden_size, 1), 0.9, dtype=torch.float32).to(device)\n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.Ucapclone = self.Ucap.clone().detach() \n",
    "\n",
    "        #self.X_history = []\n",
    "        #self.U_history = []\n",
    "        #self.v_t_history = []\n",
    "        #self.z_t_history = []\n",
    "\n",
    "    def init_dale(self, rows, cols):\n",
    "        # Dale's law with equal excitatory and inhibitory neurons\n",
    "        exci = torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        inhi = -torch.empty((rows, cols//2)).exponential_(1.0)\n",
    "        weights = torch.cat((exci, inhi), dim=1)\n",
    "        weights = self.adjust_spectral(weights)\n",
    "        return weights\n",
    "\n",
    "    def adjust_spectral(self, weights, desired_radius=1.5):\n",
    "        values= torch.linalg.svdvals(weights)\n",
    "        radius = values.abs().max()\n",
    "        return weights * (desired_radius / radius)\n",
    "    \n",
    "    def NSE(self, weights):\n",
    "        values = torch.linalg.svdvals(weights)\n",
    "        normalised_v = values/sum(values)\n",
    "        H = -1/torch.log(torch.tensor(self.hidden_size)) * torch.sum(normalised_v * torch.log(normalised_v))\n",
    "        print(H)\n",
    "        return H\n",
    "\n",
    "    @property\n",
    "    def r_t(self):\n",
    "        return self.sigmoid(self.v_t)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        if self.v_t.dim() == 3:           \n",
    "            self.v_t = self.v_t[0]\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)\n",
    "\n",
    "        ### Constraints###\n",
    "        K = self.softplus(self.K)\n",
    "        C = self.softplus(self.C)\n",
    "        # W is constructed using e*(K+C)\n",
    "        # first half of neurons are excitatory and second half are inhibitory\n",
    "        W_E = self.e_e * (K[:, :self.hidden_size//2] + C[:, :self.hidden_size//2])\n",
    "        W_I = self.e_i * (K[:, self.hidden_size//2:] + C[:, self.hidden_size//2:])\n",
    "        # print to see which device the tensor is on\n",
    "        # If sign of W do not obey Dale's law, then these terms to be 0\n",
    "        W_E = self.relu(W_E)\n",
    "        W_I = -self.relu(-W_I)\n",
    "        W = torch.cat((W_E, W_I), 1)\n",
    "        self.W = W\n",
    "\n",
    "        ### STP model ###\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        \n",
    "        # Short term Depression \n",
    "        self.z_x = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_x)\n",
    "        self.X = self.z_x + torch.mul((1 - self.z_x), self.X) - self.delta_t * self.U * self.X * self.r_t\n",
    "\n",
    "        # Short term Facilitation \n",
    "        self.z_u = self.z_min + (self.z_max - self.z_min) * self.sigmoid(self.c_u)    \n",
    "        self.Ucap = 0.9 * self.sigmoid(self.c_U)\n",
    "        self.U = self.Ucap * self.z_u + torch.mul((1 - self.z_u), self.U) + self.delta_t * self.Ucap * (1 - self.U) * self.r_t\n",
    "        self.Ucapclone = self.Ucap.clone().detach()\n",
    "        self.U = torch.clamp(self.U, min=self.Ucapclone.repeat(1, x.size(0)).to(device), max=torch.ones_like(self.Ucapclone.repeat(1, x.size(0)).to(device)))\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "\n",
    "        ### Update Equations ###\n",
    "        self.z_t = torch.zeros(self.hidden_size, 1)\n",
    "        self.z_t = self.z_low + (self.z_high - self.z_low) * self.sigmoid(torch.matmul(K , self.r_t) + torch.matmul(self.P_z, x) + self.b_z)\n",
    "        \n",
    "        # input mask\n",
    "        # we want this to be orthogonal to the E/I split, so zero out half of excitatory neurons and half of inhibitory neurons\n",
    "        input_mask = torch.ones_like(self.P)\n",
    "        input_mask[self.hidden_size//4:self.hidden_size//2,:] = 0\n",
    "        input_mask[3*self.hidden_size//4:,:] = 0\n",
    "        P = self.P * input_mask\n",
    "\n",
    "        self.v_t = (1 - self.z_t) * self.v_t + torch.matmul(W, self.U*self.X*self.r_t) + torch.matmul(P, x) + self.b_v\n",
    "        self.v_t = torch.transpose(self.v_t, 0, 1)      \n",
    "        excitatory = self.v_t[:, :self.hidden_size//2]\n",
    "        self.excitatory = torch.cat((excitatory, torch.zeros_like(excitatory)), 1)    \n",
    "\n",
    "        #self.X_history.append(self.X.clone().detach())\n",
    "        #self.U_history.append(self.U.clone().detach())\n",
    "        #self.v_t_history.append(self.v_t.clone().detach())\n",
    "        #self.z_t_history.append(self.z_t.clone().detach())   \n",
    "\n",
    "\n",
    "class Dale_CB_STP_batch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=True):\n",
    "        super(Dale_CB_STP_batch, self).__init__()\n",
    "        self.rnncell = Dale_CB_STPcell(input_size, hidden_size, num_layers).to(device)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_first == True:\n",
    "            for n in range(x.size(1)):\n",
    "                #print(x.shape)\n",
    "                x_slice = torch.transpose(x[:,n,:], 0, 1)\n",
    "                self.rnncell(x_slice)\n",
    "        return self.rnncell.excitatory            \n",
    "            \n",
    "class Dale_CB_STP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(Dale_CB_STP, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = Dale_CB_STP_batch(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        self.lstm.rnncell.X = torch.ones(self.hidden_size, x.size(0), dtype=torch.float32).to(device)\n",
    "        self.lstm.rnncell.U = (self.lstm.rnncell.Ucapclone.repeat(1, x.size(0))).to(device)\n",
    "        self.lstm.rnncell.v_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out = self.lstm(x)  # out: tensor of shape (batch_size, hidden_size)\n",
    "        output_mask = torch.ones_like(out)\n",
    "        output_mask[:,:self.hidden_size//4] = 0\n",
    "        output_mask[:,3*self.hidden_size//4:] = 0        \n",
    "        out = out * output_mask\n",
    "\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(-1)\n",
    "        \n",
    "        pass                                    \n",
    "pass\n",
    "\n",
    "model = Dale_CB_STP(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dale_CB_STP(\n",
      "  (lstm): Dale_CB_STP_batch(\n",
      "    (rnncell): Dale_CB_STPcell(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus): Softplus(beta=1, threshold=20)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=48, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10], Step [250/500], Training Accuracy: 20.20\n",
      "Epoch [1/10], Step [500/500], Training Accuracy: 21.90\n",
      "Epoch [2/10], Step [250/500], Training Accuracy: 23.80\n",
      "Epoch [2/10], Step [500/500], Training Accuracy: 26.80\n",
      "Epoch [3/10], Step [250/500], Training Accuracy: 27.20\n",
      "Epoch [3/10], Step [500/500], Training Accuracy: 27.10\n",
      "Epoch [4/10], Step [250/500], Training Accuracy: 24.70\n",
      "No improvement in validation accuracy for 2 epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "'Trajactory Tracking and Training'\n",
    "from torch import optim\n",
    "model_optimizer = optim.Adam(model.parameters(), lr = learning_rate)   \n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def subset_loader(full_dataset, batch_size, subset_ratio=0.1):\n",
    "    # Generate labels array to use in stratified split\n",
    "    labels = []\n",
    "    for _, label in full_dataset:\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Perform a stratified shuffle split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=subset_ratio, random_state=0)\n",
    "    for train_index, test_index in sss.split(np.zeros(len(labels)), labels):\n",
    "        stratified_subset_indices = test_index\n",
    "\n",
    "    # Create a Subset instance with the stratified subset indices\n",
    "    stratified_subset = Subset(full_dataset, stratified_subset_indices)\n",
    "\n",
    "    # Create DataLoader from the subset\n",
    "    subset_loader = DataLoader(\n",
    "        stratified_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No need to shuffle as we already have a random subset\n",
    "    )\n",
    "\n",
    "    return subset_loader\n",
    "subtest = subset_loader(test_data, batch_size)\n",
    "\n",
    "def evaluate_while_training(model, loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in subtest:\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(num_epochs, model, loaders, patience=2, min_delta=0.01):\n",
    "    model.train()\n",
    "    total_step = len(loaders['train'])\n",
    "    train_acc = []\n",
    "    best_acc = 0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "            images = stride(images, stride_number).to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.train()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            model_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 250 == 0:\n",
    "                accuracy = evaluate_while_training(model, loaders)\n",
    "                train_acc.append(accuracy)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.2f}' \n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, accuracy))\n",
    "\n",
    "                # Check for improvement\n",
    "                if accuracy - best_acc > min_delta:\n",
    "                    best_acc = accuracy\n",
    "                    no_improve_epochs = 0\n",
    "                else:\n",
    "                    no_improve_epochs += 1\n",
    "\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"No improvement in validation accuracy for {} epochs. Stopping training.\".format(patience))\n",
    "                    return train_acc\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "train_acc = train(num_epochs, model, loaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:27.93%\n"
     ]
    }
   ],
   "source": [
    "'Testing Accuracy'\n",
    "# Test the model\n",
    "model.eval()\n",
    "X_history = []\n",
    "U_history = []\n",
    "v_t_history = []\n",
    "z_t_history = []\n",
    "labelslist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        model.lstm.rnncell.X_history = []\n",
    "        model.lstm.rnncell.U_history = []\n",
    "        model.lstm.rnncell.v_t_history = []\n",
    "        model.lstm.rnncell.z_t_history = []\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        images = stride(images, stride_number).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted ==labels).sum().item()\n",
    "        X_history.append(model.lstm.rnncell.X_history)\n",
    "        U_history.append(model.lstm.rnncell.U_history)\n",
    "        v_t_history.append(model.lstm.rnncell.v_t_history)\n",
    "        z_t_history.append(model.lstm.rnncell.z_t_history)\n",
    "        labelslist.append(labels)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print('Accuracy of the model:{}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Performance of permuted CIFAR-10')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Performance bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# rotate model name\n",
    "\n",
    "model_name = ['full GRU', 'simple GRU', 'CB-GRU', 'CB-RNN-tied', 'Dale-CB', 'CB-RNN-tied STP', 'Dale-CB STP', 'multiscale-Vanilla RNN', 'Vanilla RNN $z=1.0$', 'Vanilla RNN $z=0.5$', 'Vanilla RNN $z=0.1$']\n",
    "perf1 = [20.01, 23.22, 33.16, 30.6, 25.13, 33.57, 27.93, 24.99, 32.77, 25.59, 26.75]\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.bar(model_name, perf1, bar_width, label='48 Neurons')\n",
    "index = np.arange(len(model_name))\n",
    "# text bar to show input size, stride number, and hidden size\n",
    "plt.text(3.5, 31, f'Input size: {input_size}\\nStride number: {stride_number}'.format(input_size=input_size, stride_number=stride_number, hidden_size=hidden_size), ha='center', va='bottom')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Performance of permuted CIFAR-10')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
